\input{../preamble_appunti.tex}
\title{Appunti di Analisi 3 \-- Equazioni Differenziali}
\author{Github Repository:
\href{https://github.com/Oxke/appunti/tree/main/Analisi_Complessa}{\texttt{Oxke/appunti/Analisi\_Complessa}}}
\date{Primo semestre A.A. 2024 \-- 2025, prof. Enrico Vitali}
\begin{document}

\maketitle
Libro suggerito: \emph{Hirsch, Smale, Devaney}

\tableofcontents
\newpage

\setcounter{section}{-1}
\section{Esempi}
Sia abbia una ``popolazione'' la quantità $x(t)$ evolva nel tempo. Allora il
rapporto \(x'(t) / x(t)\) è il tasso di variazione della popolazione.
L'equazione
\[
    \frac{x'(t)}{x(t)} = r(t, x(t))
\]
è un'equazione differenziale. Tipicamente si considera il problema ai valori
iniziali (di Cauchy) dove è aggiunta anche una condizione \(x(0) = x_{0}\) 

\begin{example}[Malthus]
    Se \(r\) è costante abbiamo la cosiddetta legge di Malthus.
    \begin{align*}
        \frac{x'(t)}{x(t)} &= r \quad x(t) > 0 \\
        \log x(t) &= rt + c \quad c \in \mathbb{R} \\
        x(t) &= e^{c} \cdot e^{rt}
    \end{align*}
    dove se \(x(0) = e^{c} = x_{0}\) si ottiene \(x(t) = x_{0} e^{rt}\) 

    Un esempio dove questo si potrebbe verificare è il decadimento radioattivo.
\end{example}

\begin{example}[Logistica]
    Non si può invece applicare in una situazione realistica di uno studio di
    una popolazione l'esempio della crescita esponenziale, non essendo
    ragionevole in quanto non considera la capacità di carico ambientale. La si
    introduce quindi. Allora possiamo modellizzare il fatto con:
    \[
        \frac{x'(t)}{x(t)} = r\left(1 - \frac{x(t)}{K}\right)
    \]
    Da cui si ottiene dopo qualche calcolo
    \[
        x(t) = k \frac{Ce^{rt}}{1 + Ce^{rt}}
    \]
    con \(C \in \mathbb{R}\), in particolare scriviamo \(C = e^{-rt_{0}}\) con
    \(t_{0}\) definito opportunamente. Allora le soluzioni sono 
    \[
        x(t) = k \frac{e^{r(t-t_{0})}}{1 + e^{r(t-t_{0})}}
    \]
    Questo rende evidente che i grafici sono tutti uno traslato temporale
    dell'altro. Si può quindi studiare solo una soluzione, ad esempio per
    \(t_{0}=0\) essendo le altre semplici traslazioni temporali di questa.
    \[
        x(t) = k \frac{e^{rt}}{1 + e^{rt}} = \frac{k}{1 + e^{-rt}}
    \]
\begin{figure}[ht]
    \centering
    \incfig{logistica}
    \caption{logistica}\label{fig:logistica}
\end{figure}
\end{example}

Ciò che abbiamo ottenuto riguardo alle soluzioni, dove ogni soluzione è una
traslazione temporale di un'altra, è un caso generale delle equazioni
differenziali non dipendenti dal tempo. Il che è una facile osservazione del
fatto che se \(x'(t) = f(x(t))\) e \(x_\tau(t) := x(t - \tau)\) allora anche
\(x_\tau\) è soluzione poiché \(x_\tau'(t) = x'(t-\tau) = f(x(t-\tau)) =
f(x_\tau(x))\).

\begin{example}
    Le equazioni precedenti modellizzano anche fenomeni differenti. Ad esempio in
    chimica se considero la reazione chimica \(H_{2}+I_{2} \to 2HI\) posso
    considerare la velocità di cambiamento della concentrazione nella soluzione
    della reazione e quindi in questo caso ottenere
    \[
        -\frac{1}{2} \frac{d[HI]}{dt} = \frac{d[H_{2}]}{dt} = \frac{d[I_{2}]}{dt}
    \]
    dove la prima derivata è definita essere la ``velocità'' \(v(t)\) della
    reazione. La legge cinetica dice che \(v\) è proporzionale al prodotto delle
    concentrazioni di \(H_{2}\) e \(I_{2}\) quindi 
    \begin{align*}
        v(t) =  k {[H_{2}]}_t {[I_{2}]}_t = \frac{d{[HI]}_t}{dt} \\
    \end{align*}
    E il resto è lasciato come esercizio
    con l'obiettivo di mostrare che la reazione ha uno sviluppo logistico.

La reazione inversa invece si modellizza con \(x'(t) = -r{x(t)}^2\). Proviamo a
risolverla e otteniamo che
\begin{align*}
    x' = rx^2 \implies \int \frac{1}{x^2} dx = rt + c \\
    -\frac{1}{x(t)} = rt + c \implies x(t) = -\frac{1}{rt + c}
\end{align*}
Se poniamo \(x(0) = x_{0}\) otteniamo \(x_{0} = -\frac{1}{c}\) da cui \(c =
-\frac{1}{x_{0}}\) quindi 
\[
    x(t) = -\frac{1}{rt - \frac{1}{x_{0}}}
\]
\begin{figure}[ht]
    \centering
    \incfig{xpisxsr}
\caption{\(x'(t) = rx{(t)}^2\) per \(r = 1\) }\label{fig:xpisxsr}
\end{figure}
\end{example}

\begin{example}[Oscillatore armonico]
\begin{figure}[ht]
    \centering
    \incfig{oscillatore_armonico}
    \caption{oscillatore armonico}
    \label{fig:oscillatore_armonico}
\end{figure}
    Sia \(m\) una massa vincolata in modo elastico ad una posizione fissa. Sia
    \(x=0\) l'ascissa quando la molla è a riposo. Se la massa è nella posizione
    di ascissa \(x(t)\) al tempo \(t\) allora subisca la forza di richiamo
    (Hooke) \(F = -kx(t)\). Allora dalla seconda legge della dinamica
    \[
        m \ddot{x} = -kx^2 \iff \ddot{x}(t) + \omega^2 x(t) = 0, \quad \omega^2
        = \frac{k}{m}
    \]
    È un'equazione differenziale del secondo ordine lineare a coefficienti
    costanti, omogenea. Allora le soluzioni sono della forma
    \[
        x(t) = c_{1}\cos(\omega t) + c_{2}\sin(\omega t), \quad c_{1}, c_{2} \in
        \mathbb{R}
    \]
    Ho due costanti poiché devo definire posizione e velocità iniziale, e
    infatti il problema tipico ai valori iniziali per un'equazione del secondo
    ordine è 
    \[
        \begin{cases}
            \ddot{x} + \omega^2x = 0 \\
            x(0) = x_{0} \\
            \dot{x}(x) = v_{0}
        \end{cases}
    \]
    Posso riscrivere la precedente soluzione nella forma 
    \[
        x(t) =
        \sqrt{c_{1}^2+c_{2}^2}(\frac{c_{1}}{\sqrt{c_{1}^2+c_{2}^2}}\cos(\omega
        t) + \frac{c_{2}}{\sqrt{c_{1}^2+c_{2}^2}}\sin(\omega t))
    \]
    dove i coefficienti di seno e coseno sono le coordinate di un punto sulla
    circonferenza unitaria, quindi sono coseno e seno di un angolo \(\varphi\),
    da cui otteniamo che \(x(t) = A\cos(\omega t + \varphi)\) 
\end{example}
\begin{example}[Varianti dell'oscillatore armonico]
    In presenza di attrito viscoso le precedenti diventano
    \begin{align*}
        m\ddot{x} = -kx - h\dot{x} \\
        \ddot{x} + \gamma \dot{x} + \omega^2x = 0
    \end{align*}
    E se aggiungiamo anche una forza esterna costante 
    \begin{align*}
        m\ddot{x} = -kx - h\dot{x} + \psi \\
        \ddot{x} + \gamma \dot{x} + \omega^2x = f
    \end{align*}
    che è non omogenea
\end{example}
\begin{example}[Corrente elettrica]
    Preso un circuito \(RC\) abbiamo una forza elettromotrice che crea una
    differenza di potenziale \(\mathcal{E}\), un condensatore
    di capacità \(C\) e una resistenza \(R\). Sia \(q(t)\) la carica sulle
    piastre del condensatore. Allora risulta che in ogni momento
    \(\frac{q(t)}{V} = C\) costante. La resistenza invece per la legge di ohm
    \(V = i(t)R\), allora otteniamo una legge
    \[
       \mathcal{E} = Ri + \frac{q}{C} = Rq' + \frac{q}{C} 
    \]
    che è una equazione lineare del primo ordine.

    In un circuito reale invece è presente un terzo termine legato
    all'induttanza del filo, creando un circuito \(RLC\), consideriamo quindi di
    aggiungere al circuito precedentemente analizzato un'induttanza \(L\).
    Allora abbiamo
    \[
        \mathcal{E} - \mathcal{E}_L = Ri + \frac{q}{C}
    \]
    dove \(\mathcal{E}_L = Li'\) è l'inerzia elettrica del sistema, l'equazione
    diventa
    \[
        L\ddot{q} + R\dot{q} + \frac{q}{C} = \mathcal{E}
    \]
    Ossia un'ODE lineare a coefficienti costanti del secondo ordine non omogenea.
\end{example}

\begin{example}[Equazione di Schrödinger]
    \[
        -\frac{\hbar}{2m} \nabla^2_x \psi(x, t) + U(x, t)\psi(x, t) = i
        \frac{\partial \psi}{\partial t}
    \]
    Supponiamo che il potenziale \(U\) sia indipendente dal tempo \(t\), ossia
    \(U = U(x)\) e cerchiamo soluzioni della forma a variabili separate, cioè
    \(\psi(x, t) = u(x) \varphi(t)\), inoltre poniamoci in una sola dimensione,
    otteniamo:
    \[
        -\frac{\hbar}{2m} u''(x)\varphi(t) + U(x)u(x) \varphi(t) =
        iu(x)\varphi'(t)
    \]
    Da cui dividendo per \(u(x)\varphi(t)\) 
    \[
        -\frac{\hbar}{2m}\frac{u''(x)}{u(x)} + U(x) =
        i\frac{\varphi'(t)}{\varphi(t)}
    \]
    E poiché abbiamo che un'equazione in \(x\) è uguale ad una in \(t\) deve
    essere che entrambi i membri sono costanti, diciamo \(E\).
    \[
        \begin{cases}
            \frac{\hbar^2}{2m}u''(x) = (U(x) - E)u(x) \\
            \frac{\varphi'(t)}{\varphi(t)} = -iE
        \end{cases}
    \]
    La prima è un'equazione differenziale lineare del secondo ordine a
    coefficienti non costanti (in generale) e si può riscrivere come 
    \[
        Lu := -\frac{\hbar^2}{2m} u''(x) + U(x)u(x)
    \]
    è un operatore lineare su \(u\) e allora l'equazione diventa
    \[
        Lu = Eu
    \]
    ossia un'equazione agli autovalori per l'operatore \(L\).

    Ad esempio nel caso \(U(x) = \frac{1}{2}k x^2\) e con opportuni cambi di
    variabile si arriva alla cosiddetta \emph{equazione di Hermite}
    \[
        H''(\xi) - 2\xi H' + \cos t H = 0
    \]
    che dà luogo ai cosiddetti \emph{polinomi di Hermite}
\end{example}
Altri due esempi importanti sono, nel caso dei sistemi (tra cui l'esempio famoso
del preda-predatore di Lotka-Volterra) e le elastiche piane.
Ulteriore esempio è il moto di un pendolo, che si può modellizzare con un'ODE di
secondo ordine non lineare.
\begin{example}[Elastiche piane]
    Sia abbia una verga elastica (barra) che supponiamo in una posizione di
    equilibrio della forma grafico \(y = u(x)\) 
\begin{figure}[ht]
    \centering
    \incfig{elastica_piana}
    \caption{Elastica Piana}\label{fig:elastica_piana}
\end{figure}
    Con ipotesi modellistica, ossia \textbf{il momento flettente è proporzionale
    alla curvatura}, dove la curvatura in un punto \(x\) si può calcolare con
    \[
        \kappa(x) = \frac{u''(x)}{{(1 + {u'(x)}^2)}^{3/2}}
    \]
    e il momento flettente si può immaginare intuitivamente come la forza locale
    sulla verga ed è proporzionale al valore di \(u(x)\). Allora si ottiene
    l'equazione
    \[
        \kappa(x) = -\lambda u(x) \iff u''(x) + \lambda u(x){(1 +
        {u'(x)}^2)}^{3/2} = 0
    \]
    dove \(\lambda \in \mathbb{R}\) è una costante.
\begin{remark}
    La costante \(\lambda\) e la lunghezza della verga sono legate (significato
    modellistico)
\end{remark}
\end{example} 
\begin{example}[Equazioni di Lotka-Volterra]
    Siano \(x_{1}(t)\) e \(x_{2}(t)\) le popolazioni di due specie che interagiscono
    tra loro. Allora si può modellizzare il fatto che la popolazione di una
    specie è proporzionale alla sua popolazione e alla popolazione dell'altra
    specie. Sia allora \(\frac{x_{i}'(t)}{x_{i}(t)}\) il tasso di variazione
    della popolazione \(x_{i}\). Supponiamo adesso che \(x_{1}\) sia la
    ``preda'' e \(x_{2}\) il ``predatore''. Allora si può modellizzare
    l'evoluzione del sistema esprimendo il tasso di variazione delle
    popolazioni. In particolare per la preda abbiamo
    \[
        \frac{x_{1}'(t)}{x_{1}(t)} = \alpha - \beta x_{2}(t)
    \]
    dove \(\alpha\) è il tasso in assenza di predatori e \(b\) è il tasso di
    morte causato dai predatori. Per il predatore invece si ha
    \[
        \frac{x_{2}'(t)}{x_{2}(t)} = \delta x_{1}(t) - \gamma
    \]
    In conclusione, il sistema di equazioni differenziali è
    \[
        \begin{cases}
            x_{1}'(t) &= (\alpha - \beta x_{2}(t))\,x_{1}(t) \\
            x_{2}'(t) &= (\delta x_{1}(t) - \gamma)\,x_{2}(t)
        \end{cases}
    \]
    che è un sistema non lineare di due equazioni differenziali. Il problema ai
    valori iniziali naturalmente associato è quello che si ottiene aggiungendo i
    dati \(x_{1}(t_{0}) = x_{1}^{0}\) e \(x_{2}(t_{0}) = x_{2}^{0}\).

    Anche questo sistema può essere trasformato ad una versione logistica,
    cambiando i fattori \(\alpha \) in \(\alpha(1 - \frac{x_{1}}{k_{1}})\) e
    analogamente per \(x_{2}\), ottenendo il sistema
    \[
        \begin{cases}
            x_{1}' = x_{1}(\alpha - \lambda x_{1} - \beta x_{2}) \\
            x_{2}' = x_{2} (-\gamma + \delta x_{1} - \mu x_{2})
        \end{cases}
    \]
\end{example}

\section{Equazioni differenziali ordinarie}
In generale quindi abbiamo diversi esempi (\(x' = rx\), \(x' = rx(1-x)\), \(Rq'
+ \frac{1}{C} q = \mathcal{E}\)) di equazioni della forma \(x' = f(t, x)\).
Anche in Lotka-Volterra abbiamo una forma simile ma con due variabili, infatti
considerando \(\mathbf{x}(t) = (x_{1}(t), x_{2}(t))\) abbiamo che possiamo
riscrivere il sistema come un sistema vettoriale della forma \(\mathbf{x}'(t) =
\mathbf{f}(t, \mathbf{x}(t))\).
\begin{definition}{soluzione di un'equazione differenziale}
    Sia \(D \subseteq \mathbb{R} \times \mathbb{R}^{n} \), con \(n \ge 1\)
    aperto. Sia \(f : D \to \mathbb{R}^{n}\) continua. Consideriamo l'equazione
    differenziale \(x'(t) = f(t, x(t))\), che è detta quindi in \emph{forma
    normale}.

    Diciamo \textbf{soluzione} dell'equazione differenziale ogni funzione \(x :
    J \to \mathbb{R}^{n}\) con \(J\) intervallo, di classe \(C^{1}\) e tale che 
    \[
        \forall t \in J, (t, x(t)) \in D
    \]
    e su \(D\) è verificata l'uguaglianza 
    \[
        x'(t) = f(t, x(t))
    \]
\end{definition}
Nel caso scalare (ossia \(n=1\)) dunque abbiamo che \(x(\cdot )\) è soluzione se ogni punto
\((t, x(t))\) del grafico ha pendenza pari al valore di \(f(t, x(t))\).
\begin{figure}[ht]
    \centering
    \incfig{pendenzagrafico}
    \caption{Soluzione di un'equazione differenziale nel caso \(n=1\) }\label{fig:pendenzagrafico}
\end{figure}

Nel caso invece di equazioni differenziali del secondo ordine (come il moto
armonico, il pendolo, l'elastica piana, il circuito RLC ecc\dots) si ha che 
\[
    x''(t) = f(t, x(t), x'(t))
\]
con \(x(\cdot )\) incognita. Questa forma è detta \emph{forma normale} per
un'equazione del secondo ordine.
In generale se \(\mathbf{x}(t) = (x_{1}(t), x_{2}(t), x_{3}(t)) \) è un punto
mobile in \(\mathbb{R}^{3}\) sotto l'azione di un campo di forza \(\mathbf{F}(t,
\mathbf{x}(t), \mathbf{x}'(t))\) allora per la seconda legge della dinamica si
ottiene il sistema del secondo ordine
\[
    m\mathbf{x}''(t) = \mathbf{F}(t, \mathbf{x}(t), \mathbf{x}'(t)) 
\]
Un'equazione del secondo ordine in forma normale può essere ricondotta a un
sistema del primo ordine in forma normale, come
\[
    x''(t) = f(t, x(t), x'(t)) \iff
    \begin{cases}
        x'(t) &= v(t) \\
        v'(t) &= f(t, x(t), v(t))
    \end{cases}
\]
Dove abbiamo introdotto la variabile \(v(t) = x'(t)\). A questo punto il sistema
può essere scritto in forma vettoriale come \(\mathbf{x}(t) = (x(t), v(t))\), e
quindi \(\mathbf{x}'(t) = \mathbf{f}(t, \mathbf{x}) = (v(t), f(t, x(t), v(t)))\) 

Analogalmente equazioni di ordine superiore possono essere ricondotte a sistemi
di primo ordine introducendo le variabili \(x_{i} = x^{(i)}\) dove \(x^{(i)}\) è
la \(i\)-esima derivata di \(x\). Il sistema che analizzeremo sarà quindi
\[
    \begin{cases}
        x_{1}'(t) &= x_{2}(t) \\
        x_{2}'(t) &= x_{3}(t) \\
        &\vdots \\
        x_{n}'(t) &= f(t, x_{1}(t), x_{2}(t), \ldots, x_{n}(t))
    \end{cases}
\]
dove \(n\) è il grado dell'equazione differenziale.

Il problema ai valori iniziali associato al sistema del primo ordine
\(\mathbf{x}'(t) = \mathbf{f}(t, \mathbf{x}(t))\) si ha aggiungendo il requisito
\(\mathbf{x}(0) = \mathbf{y}_0\), per cui ovviamente nel caso di un'equazione di
ordine superiore il problema ai valori iniziali è dato dal richiedere, per ogni
derivata \(x^{(i)}\), il valore iniziale \(x^{(i)}(0) = y_{i}\).

È particolare il caso in cui \(f\) non dipende da \(t\) e viene detto
\textbf{caso autonomo} allora se \(\Omega \subseteq \mathbb{R}^{n} \) è aperto e
\(f: \Omega \to \mathbb{R}^{n}\) è continua allora l'equazione è \(x' = f(x)\)
dove la soluzione è una funzione \(x : J \to \Omega\) con \(J\) intervallo.
\begin{example}[Logistica]
    L'equazione, come visto in precedenza è 
    \[
        x' = rx(1- \frac{x}{k}) = f(x)
    \]
    Allora il campo di pendenza non dipende da \(t\), vedasi
    figura~\ref{fig:pendenza_logistica}
\begin{figure}[ht]
    \centering
    \incfig{pendenza_logistica}
    \caption{Pendenza della logistica}\label{fig:pendenza_logistica}
\end{figure}

Allora abbiamo un'invarianza delle soluzioni per traslazione temporali, infatti
se \(x\) è soluzione e \(x_\tau(t) := x(t - \tau)\) allora \(x_\tau'(t) =
f(x(t-\tau)) = f(x_\tau(t))\).
In tal modo possiamo creare uno ``Spazio degli stati'' ossia un'immagine in cui
raffiguriamo soltanto le posizioni di \(x\), come si evolve il sistema in quei
punti, poiché rappresentare \(t\) è ridondante, otteniamo per la logistica il
seguente schema:

\begin{figure}[ht]
    \centering
    \incfig{logistica_stati}
    \caption{Spazio degli stati dell'equazione logistica}\label{fig:logistica_stati}
\end{figure}
\end{example}

Possiamo espandere l'idea dello spazio degli stati a equazioni vettoriali
autonome del primo ordine, dove rappresentiamo in ogni punto \(\mathbf{x}\) dello spazio
\(\mathbb{R}^{n}\) la pendenza, data dal vettore \(\mathbf{f}(\mathbf{x})\),
successivamente possiamo rappresentare l'evoluzione del sistema in questo
spazio, ottenendo le \emph{orbite} (cercare su internet ``campo di pendenza
Lotka-Volterra'' oppure ``orbite Lotka-Volterra'' per vedere esempi, in tal caso
in \(\mathbb{R}^2\)). Le orbite quindi in generale (anche nel caso non autonomo)
sono \textbf{la proiezione della curva della soluzione su uno spazio degli
stati, che è dato dalle coordinate che non sono quella del tempo}.

\subsection{Alcuni esempi di risoluzione esplicita}
\begin{example}[Equazioni a variabili separabili]
    Si tratta di equazione differenziale della forma
    \[
        x'(t) = g(t) \, h(x)
    \]
    con \(g\) e \(h\) funzioni continue su un intervallo (ad esempio). Se
    \(\overline{x}\) è uno zero di \(h\) allora \(x(t) = \overline{x}\) è una
    soluzione costante. Un esempio chiaro è la logistica
    (figura~\ref{fig:logistica}) in cui se \(h(x) = x\left( 1- \frac{x}{K}
    \right) \) allora \(x(t) = 0\) e \(x(t) = K\) sono soluzioni costanti.

    Sia \(x: J \to \mathbb{R}\) una soluzione che non assume mai come valore uno
    degli zeri di \(h\). Allora possiamo scrivere
    \[
        \frac{x'(t)}{ h(x(t)) } = g(t) \quad \text{(su \(J\))}
    \]
    Da cui integrndo entrambi i membri
    \[
        \int \frac{x'(t)}{h(x(t))} dt = \int g(t) dt \iff \int \frac{1}{h(\xi)}
        d\xi = \int g(t) dt 
    \] 
    Dove si è fatto il cambio di variabile \(\xi = x(t)\). Allora se \(H\) e
    \(G\) sono primitive di \(\frac{1}{h}\) e di \(g\) rispettivamente si ha che
    \[
        H(x(t)) = G(t) + c
    \]
    che è un'equazione che definisce implicitamente la soluzione.
    \begin{example}
        Si consideri l'equazione \(x' = rt \left( x^2 - x \right) \) con \(r \in
        \mathbb{R}\). Allora si ha che \(h(x) = x^2 - x\) e \(g(t) = rt\).
        Gli zeri di \(h\) sono \(0\) e \(1\) per cui \(x(t) = 1\) e \(x(t) = 0\)
        sono le soluzioni costanti.

        Se invece \(x(t) \neq 0, 1\) allora si ha
        \[
            \frac{x'}{x^2 - x} = 2t \iff \int \frac{1}{x^2 - x} dx = \int 2t dt
            \iff \log \left| \frac{x-1}{x} \right| = t^2 + c
        \]
        quindi abbiamo che, elevando entrambi i membri alla base \(e\), e
        sostituendo \(e^{c} \in \mathbb{R}\) con \(C > 0\).
        \[
            \left|\frac{x-1}{x}\right| = Ce^{t^2}
        \]
        Poiché in questo caso il segno di \(\frac{x-1}{x}\) è costante su \(J\)
        (infatti \(x(J)\) è connesso e non contiene né \(0\) né \(1\)).
        Scegliendo quindi \(K \in \mathbb{R} \sminus \{0\}\) abbiamo
        \[
            x(t) = \frac{1}{1 - Ke^{t^2}} \quad K \neq 0
        \]
        Notiamo che invece per \(K = 0\) si recupera la soluzione costante \(x(t)
        = 1\).
    \end{example}
\end{example}

\begin{example}[Equazioni lineari del primo ordine]
    \[
        x'(t) + p(t)\,x(t) = q(t)
    \]
    con \(p, q\) funzioni continue su un intervallo \(I\).

    Sia \(P(t)\) una primitiva di \(p(t)\). Moltiplichiamo per \(e^{P(t)}\).
    \[
        e^{P(t)}x'(t) + e^{P(t)}p(t)x(t) = e^{P(t)}q(t)
    \]
    Dove il primo membro è evidentemente la derivata di \((e^{P(t)}x(t))\),
    quindi integrando entrambi i membri si ottiene
    \[
        e^{P(t)}x(t) = \int e^{P(t)}q(t) dt
    \]
    (Cioè \(e^{P(t)} x(t)\) è una primitiva di \(e^{P(t)} q(t)\)). Esplicitando
    \(x(t)\) otteniamo
    \[
        x(t) = e^{-P(t)} \int e^{P(t)}q(t) dt
    \]
    Se consideriamo il problema con dato \(x(t_{0}) = x_{0}\) la soluzione si
    può ottenere direttamente integrando tra \(t_{0}\) e \(t\), ossia
    \[
        \begin{cases}
            \displaystyle
            P(t) = \int_{t_{0}}^{t} p(s) ds \\
            \displaystyle
            x(t) = e^{-P(t)} \left( x_{0} + \int_{t_{0}}^{t} e^{P(s)}q(s) ds
                \right)
        \end{cases}
    \]
    Nel caso particolare dell'equazione \(x' = ax\), con \(a \in \mathbb{R}\)
    otteniamo (anche con variabili separabili) che \(x(t) = Ce^{at}\). In modo
    analogo si vede che le soluzioni di \(\varphi' = a\varphi\) con \(a \in
    \mathbb{C}\) e \(\varphi : J \to \mathbb{C}\) sono della forma \(\varphi(t)
    = C e ^{a t}\) con \(C \in \mathbb{C}\) 
    
    Per \emph{esercizio}, 
        Sapendo che la derivata \(\varphi'\) di \(\varphi : t \mapsto
        \varphi_{1} + i\varphi_{2}\) con \(\varphi_{1}, \varphi_{2} : J \to
        \mathbb{R} \) è \(\varphi' : t \mapsto \varphi_{1}' + i\varphi_{2}'\)
        mostrare che \(\frac{d}{dt}e^{at} = a e^{at}\), con \(a \in
        \mathbb{C}\).
\end{example}

\begin{example}[Equazioni lineari del secondo ordine a coefficienti costanti]
    \[
        ax'' + bx' + cx = 0
    \]
\begin{remark}
\begin{itemize}[label = --]
    \item L'insieme \(V\) delle soluzioni è uno spazio vettoriale
    \item La modellistica suggerisce che \(\dim V = 2\) 
\end{itemize}
    Ipotizziamo un tentativo di soluzione della forma \(x(t) = e^{\lambda t}\) 
    allora abbiamo \(x'(t) = \lambda e^{\lambda t}\) e \(x''(t) = \lambda^2
    e^{\lambda t}\). Sostituendo nella equazione e dividendo per \(e^{\lambda
    t} \neq 0\) otteniamo
    \[
        a\lambda^2 + b\lambda + c = 0 \quad \quad (A)
    \]
    Se \(\Delta = b^2 - 4ac > 0\) allora \((A)\) ha due soluzioni \(\lambda_{1},
    \lambda_{2}\) distinte, quindi \(e^{\lambda_{1} t}\) e \(e^{\lambda_{2} t}\)
    sono due soluzioni linearmente indipendenti.

    Se \(\Delta = 0\) (A) ha una soluzione \(\lambda\), per cui \(e^{\lambda
    t}\) è una soluzione e si verifica che anche \(te^{\lambda t}\) è soluzione
    linearmente indipendente con la precedente.

    Se \(\Delta < 0\) passiamo in campo complesso e cerchiamo \(u(t) = x(t) +
    iy(t)\) con \(x, y : J \to \mathbb{R}\) e \(u : J \to \mathbb{C}\), tale che
    anche \(u\) sia soluzione dell'equazione differenziale. Considereremo poi
    \(x(t) = Re(u(t))\). Come sopra ipotizziamo \(t \mapsto e^{\lambda t}\)
    soluzione e otteniamo la stessa equazione \((A)\), allora esistono due
    soluzioni \(\lambda_{1, 2} = \alpha \pm i\beta \), poiché i coefficienti di
    \((A)\) sono reali. Allora otteniamo le due soluzioni dell'equazione
    differenziale
    \[
        e^{(\alpha + i\beta)t} \quad e^{(\alpha - i\beta)t}
    \]
    che sono linearmente indipendenti. Ma lo spazio delle soluzioni generato da
    queste equazioni ammette anche la base \textbf{reale} data da 
    \[
        \frac{u + \overline{u}}{2} \text{ e } \frac{u - \overline{u}}{2i}
    \]
    che in questo caso sono \(e^{\alpha t}\cos(\beta t)\) e \(e^{\alpha t}
    \sin(\beta t)\).

    In tutti e tre i casi, se \(x_{1}(t)\) e \(x_{2}(t)\) sono due soluzioni
    linearmente indipendenti, allora una generica soluzione \(x(t)\) è della
    forma 
    \[
        x(t) = c_{1}x_{1}(t) + c_{2}x_{2}(t) \quad c_{1}, c_{2} \in \mathbb{R}
    \]

    Nel caso completo l'equazione è del tipo 
    \[
        ax'' + bx' + cx = f(t)
    \]
    Sia allora \(\overline{x}(\cdot )\) una soluzione (``nota''). L'integrale
    generale è dato dalle funzioni della forma 
    \[
        x(t) = x_{o}(t) + \overline{x}(t)
    \]
    al variare di \(x_{o} \) tra le soluzioni dell'equazione omogenea associata,
    ossia \(ax'' + bx' + cx = 0\).
    Questo perché se \(L : C^{2}(\mathbb{R}) \to C^{0}(\mathbb{R})\) un
    operatore lineare, ad esempio proprio \(Lx = (t \mapsto ax''(t) + bx'(t) +
    cx(t))\), allora il problema \(Lx = f\)  ha soluzione \(L^{-1}(f) =
    \overline{x} + \ker L\) con \(\overline{x}\) tale che \(L\overline{x} = f\)
    e \(\ker L\) lo spazio delle soluzioni dell'equazione omogenea associata
    \(Lx = 0\).

    In alcuni casi è particolarmente facile trovare una soluzione
    \(\overline{x}\) particolare, ad esempio ipotizzando ne esista una della
    forma di un polinomio di \(t\), e cercando i coefficienti per cui funzioni.
    In altri casi ha più senso cercare una soluzione particolare di forme
    diverse, ad esempio con esponenziali o seni e coseni o come ti pare, alla
    fine se il problema ti chiede di trovare una soluzione particolare è perché
    si può fare e allora ci pensi un attimo a occhio si vede facilmente.
\end{remark}
\end{example}

Sia \(D \subseteq \mathbb{R} \times \mathbb{R}^{n} \) aperto e \(f : D \to
\mathbb{R}^{ n } \) continua. Fissato \((t_{0}, x_{0}) \in D\) consideriamo il
problema ai valori iniziali
\[
    \begin{cases}
        x' = f(t, x) \\
        x(t_{0}) = x_{0}
    \end{cases}
\]
\begin{proposition}\label{proposition:equivalenza_pvi}
    Sia \(x : J \to  \mathbb{R}^{n}\) funzione continua tale che \((t, x(t)) \in
    D\)  per ogni \(t \in J\), ossia ha grafico in \(D\).
    Allora sono equivalenti:
\begin{enumerate}[label = \alph*)]
    \item \(x\) è soluzione del problema ai valori iniziali
    \item \(\displaystyle x(t) = x_{0} + \int_{t_{0}}^{t} f(s, x(s)) ds\) per ogni \(t \in J\) 
\end{enumerate}
\end{proposition}

Per quanto la proposizione~\ref{proposition:equivalenza_pvi} sia abbastanza
ovvia, ci serve per poter dimostrare il problema di esistenza e unicità delle
soluzioni, poiché permette di trasformare il problema di trovare una soluzione
in un problema del punto fisso.

\begin{definition}{Funzione Lipschitziana}
Una funzione \(g: G \subseteq \mathbb{R}^{m} \to \mathbb{R}^{k} \) è detta
\textbf{lipschitziana} se esiste una costante \(L > 0\) tale che 
\[
    \|g(x) - g(y)\| \le L \|x - y\| \quad \forall x, y \in G
\]
\end{definition}
\begin{proposition}
    Sia \(G\) un aperto convesso limitato e \(g \in C^{1}(\overline{G},
    \mathbb{R}^{k})\). Allora \(g\) è lipschitziana.
\end{proposition}
\begin{proof}
    Siano \(x_{1}, x_{2} \in G\) aperto convesso limitato.
    Per ogni \(t \in [0, 1]\) Sia
    \[
        \varphi(t) = g(x_{1} + t(x_{2} - x_{1}))
    \]
    Allora si ha che
    \begin{align*}
        g(x_{2}) - g(x_{1}) = \varphi(1) - \varphi(0) =
        \int_{0}^{1}\varphi'(t)dt = \int_{0}^{1} (Dg)(x_{1} +
        t(x_{2}-x_{1}))(x_{2}-x_{1})dt \\
        \le \int_{0}^{1} |Dg(x_{1} + t(x_{2}-x_{1}))| |x_{2}-x_{1}| dt \le
        \left(\max_{\overline{G}} |Dg|\right) |x_{2}-x_{1}|
    \end{align*}
\end{proof}
\begin{proposition}
    Sia \(G \in \mathbb{R}^{m}\) aperto e \(g \in C^{1}(G, \mathbb{R}^{k})\).
    Allora \(g\) è lipschitziana su ogni compatto \(K \subseteq G\) (anche detto
    \emph{localmente lipschitziana}).
\end{proposition}
\begin{example}
    La funzione \(x \mapsto x^2\) non è ovviamente lipschitziana su
    \(\mathbb{R}\). Eppure per ogni compatto \(K \subseteq \mathbb{R}\) (ad
    esempio \([-M, M]\)) la funzione è lipschitziana su \(K\), infatti 
    \[
        |x^2 - y^2| = |x+y||x-y| \le 2M|x-y|
    \]
\end{example}

\begin{definition}{Funzione l.l.2u.1}
    Sia \(D \subseteq \mathbb{R}^{N + 1} \) aperto e \(f : D \to
    \mathbb{R}^{N}\) (con \(f(t, \mathbf{x})\)). Diciamo che \(f\) è localmente lipschitziana nella seconda
    variabile, uniformemente rispetto alla prima se per ogni compatto \(K
    \subseteq D\) esiste una costante \(L_K >0\) tali che:
    \[
        \forall (t, \mathbf{x}), (t, \mathbf{y}) \in K, \quad \|f(t, \mathbf{x})
        - f(t, \mathbf{y})\| \le L_K \|\mathbf{x} - \mathbf{y}\|
    \]
\end{definition}
\begin{remark}
    Se ho una funzione \(C^{1}(D, \mathbb{R}^{N})\) allora è per la proposizione
    precedente localmente lipschitziana in entrambe le variabile, quindi per
    ogni \(K\subseteq D  \) compatto esiste \(L_K > 0\) tale che
    \[
        \forall (t_{1}, \mathbf{x}), (t_{2}, \mathbf{y}) \in K \quad \|f(t_{1},
        \mathbf{x}) - f(t_{2}, \mathbf{y})\| \le L_K \|(t_{1}, \mathbf{x}) - (t_{2},
        \mathbf{y})\|
    \]
    quindi in particolare se \(t_{1}=t_{2}=t\) abbiamo la locale lipschitzianità
    nella seconda variabile uniformemente rispetto alla prima
\end{remark}

\subsection{Esistenza e unicità delle soluzioni}
Sia \(D \subseteq \mathbb{R}^{N+1} \) aperto e \(f : D\to \mathbb{R}^{N}\) e
\((t_{0}, x_{0}) \in D\) e consideriamo il problema
\[
    (P) \quad
    \begin{cases}
        x' = f(t, x) \\
        x(t_{0}) = x_{0}
    \end{cases}
\]
\begin{figure}[ht]
    \centering
    \incfig[.6]{problema}
    \caption{Problema ai valori iniziali, \(\alpha = \frac{b}{M}\) in questo
    caso, evidentemente}\label{fig:problema}
\end{figure}
Siano \(a, b > 0\) tali che 
\[
    R_{a, b}  = [t_{0} - a, t_{0} + a] \times \overline{B}_{b}(x_{0}) \subseteq
    D
\]

\begin{theorem}[Esistenza e Unicità]
Sia \(f\) localmente lipschitziana nella seconda variabile uniformemente
rispetto alla prima. Allora
\begin{enumerate}[label = \alph*)]
    \item Esiste una soluzione di \((P)\) definita in \([t_{0} - \alpha, t_{0} +
        \alpha]\), con \(\alpha = \min\left(a, \frac{b}{M}\right)\), dove \(M = \max_{R_{a,
        b}}|f| \) 
    \item Nell'intervallo \([t_{0} - \alpha, t_{0} + \alpha]\) la soluzione,
        ossia se \(\varphi_{1} : J_{1} \to \mathbb{R}^{N}\) e \(\varphi_{2} :
        J_{2} \to \mathbb{R}^{N}\) sono soluzioni di \((P)\) allora
        \(x_{1}(t) = x_{2}(t) \forall t \in J_{1} \cap J_{2} \subseteq [t_{0} -
        \alpha, t_{0} + \alpha]\) 
\end{enumerate}
\end{theorem}
\begin{proof}
    Abbiamo visto che se \(x : J \to \mathbb{R}^{N}\) con \(J\) intervallo è una
    funzione continua con grafico in \(D\), allora \(x\) è soluzione di \((P)\)
    se e solo se 
    \[
        x(t) = x_{0} + \int_{t_{0}}^{t} f(s, x(s)) ds \quad \forall t \in J
    \]
    Sia \(x : [t_{0} - \alpha , t_{0} + \alpha] \to \overline{B}_b(x_{0})\).
    Poniamo ora
    \[
        (Tx)(t) = x_{0} + \int_{t_{0}}^{t} f(s, x(s)) ds \quad \forall t \in
        [t_{0} - \alpha, t_{0} + \alpha]
    \]
    Dove risolvere \((P)\) diventa mostrare che esiste un punto fisso di \(T\).
    Verifichiamo che \((Tx)(\cdot )\) assume valori in
    \(\overline{B}_b(x_{0})\). Infatti 
    \[
        |(Tx)(t) - x_{0}| = \left| \int_{t_{0}}^{t} f(s, x(s)) ds \right| \le
        \left|\int_{t_{0}}^{t} |f(s, x(s))| ds \right| \le M|t - t_{0}| \le M\alpha \le b
    \]
    Allora otteniamo che \(T : C^{0}([t_{0}-\alpha, t_{0} + \alpha];
    \overline{B}_b(x_{0})) \to C^{0}([t_{0}-\alpha, t_{0} + \alpha];
    \overline{B}_b(x_{0}))\). Possiamo quindi iterare l'applicazione di \(T\),
    quindi abbiamo la successione 
    \[
        x_{0}, x_{1} = Tx_{0}, x_{2} = Tx_{1}, \ldots, x_{n} = Tx_{n-1}
    \]
    Ora quindi mostriamo che la successione \(x_{n}\) converge uniformemente con
    il criterio di Cauchy
    \begin{align*}
        |x_{1}(t) - x_{0}(t)| &= \left| \int_{t_{0}}^{t} f(s, x_{0}(s))\right|
        \le M|t - t_{0}| \\
        |x_{2}(t) - x_{1}(t)| &= \left| \int_{t_{0}}^{t} f(s, x_{1}(s)) - f(s,
        x_{0}(s))\right| ds \le  \left| \int_{t_{0}}^{t} |f(s, x_{1}(s)) - f(s,
        x_{0}(s))| ds \right| \le \\
                                   &\le L_R \left|\int_{t_{0}}^{t} |x_{1}(s) - x_{0}(s)| ds\right| \le ML_R
        |\int_{t_{0}}^{t}|s-t_{0}| ds| = \frac{ML_R}{2} |t - t_{0}|^2
    \end{align*}
    \begin{align*}
        |x_{3}(t) - x_{2}(t)| &= \left| \int_{t_{0}}^{t} f(s, x_{2}(s)) - f(s,
        x_{1}(s))\right| ds \le \left| \int_{t_{0}}^{t} |f(s, x_{2}(s)) - f(s,
        x_{1}(s))| ds \right| \le \\
                              &\le L_R \left|\int_{t_{0}}^{t} |x_{2}(s) - x_{1}(s)| ds\right| \le
        \frac{ML_R^2}{2}
        \left|\int_{t_{0}}^{t}|s-t_{0}|^2 ds\right| = \frac{ML_R^2}{6} |t - t_{0}|^3
                           \\ &\vdots
    \end{align*}
    E in generale abbiamo 
    \[
        |x_{k+1}(t) - x_{k}(t)| \le \frac{ML_R^{k}}{(k+1)!} |t - t_{0}|^{k+1}
    \]
    Quindi abbiamo che se fissiamo \(n, m \in \mathbb{N}\) con \(m > n\) 
    \[
        |x_{m}(t) - x_{n}(t)| \le \sum_{k=n}^{m-1} |x_{k+1}(t) - x_{k}(t)| \le 
        \sum_{k=n}^{m-1} \frac{ML_R^{k}}{(n+1)!} |t - t_{0}|^{n+1} \le
        \frac{M}{L_R}
    \sum_{k=m}^{\infty} \frac{{(L_R \alpha)}^{k+1}}{(k+1)!}
    \]
    Che è il resto di una serie esponenziale, quindi per \(m, n\)
    sufficientemente grandi la serie converge a zero, per cui abbiamo mostrato
    la convergenza uniforme di \(x_{k}\). Ora sappiamo 
    \[
        x_k \longrightarrow x \in C^{0}([t_{0} - \alpha, t_{0} + \alpha];
        \overline{B}_b(x_{0})) \quad \text{uniformemente}
    \]
    Ora semplicemente possiamo portare il limite sotto il segno di integrale
    perché \(f(\cdot, x_k(\cdot )) \to f(\cdot, x(\cdot ))\) uniformemente in
    \([t_{0}-\alpha, t_{0}+\alpha]\) e
    quindi otteniamo che \(x\) è soluzione di \((P)\).

    Ora procediamo con l'unicità. Sia \(z : J \to \mathbb{R}^{N}\) una soluzione
    di \((P)\). Considieriamo i valori di \(t \in J \cap [t_{0}, t_{0} +
    \alpha]\) e analogalmente per \(t \le  t0\) e vogliamo mostrare che \(z(t) =
    x(t)\) con \(x(\cdot )\) la soluzione costruita primala soluzione costruita
    prima. Allora abbiamo per ipotesi che
    \[
        z(t) = x_{0} + \int_{t_{0}}^{t} f(s, z(s)) ds
    \]
    E valutiamo quindi
    \[
        |z(t) - x_{0}| \le \int_{t_{0}}^{t} |f(s, z(s))| ds
    \]
    Fissiamo ora un valora \(\overline{t} \in [t_{0}, t_{0}+ \alpha]\)
    arbitrario in \(J\) i \(t \in [t_{0}, \overline{t}]\). Allora \((s, z(s))\)
    per \(s in [t_{0}, t]\) è in un compatto di \(D\). Sia \(M_{1}\) il massimo di
    \(f\) su tale compatto. Allora 
    \[
        |z(t) - x_{0}| \le M_{1} |t - t_{0}| \quad \forall t \in [t_{0},
        \overline{t}]
    \]
    Ora procediamo con 
    \begin{align*}
        |z(t) - x_{1}(t)| &\le \int_{t_{0}}^{t} |f(s, z(s)) - f(s, x_{0})| ds \le
        L_{1} \int_{t_{0}}^{t} |z(s) - x_{0}| ds \le \\ &\le  L_{1} M_{1}
        \int_{t_{0}}^{t} |s - t_{0}| ds = \frac{L_{1}M_{1}}{2} |t - t_{0}|^2
    \end{align*}
    Con \(L_{1}\) una costante di Lipschitz per \(f\) relativa a un compatto che
    contiene sia \(R\) che il grafico di \(z\) 
    Procedendo in questo modo nuovamente si ottiene in generale
    \[
        |z(t) - x_{k}(t)| \le \frac{M_{1}L_{1}^{k}}{(k+1)!} |t - t_{0}|^{k+1}
        \longrightarrow 0 \text{ per \(k \to \infty\)}
    \]
\end{proof}
\begin{remark}[Unicità ``globale'']
    Sia \(x' = f(t, x)\) localmente lipschitziana in \(x\) uniformemente in
    \(t\). Siano \(x_{1}: J_{1} \to \mathbb{R}^{N}\) e \(x_{2}: J_{2} \to
    \mathbb{R}^{N}\) due soluzioni tali che esista \(t_{0} \in J := J_{1}\cap
    J_{2}\) con \(x_{1}(t_{0}) = x_{2}(t_{0})\) allora \(x_{1} = x_{2}\) su
    \(J\).
    Quindi la funzione 
    \[
        x(t) = \begin{cases}
            x_{1}(t) & t \in J_{1} \\
            x_{2}(t) & t \in J_{2}
        \end{cases}
    \]
    è soluzione sud \(J_{1} \cup J_{2}\) 
\end{remark}
\begin{proof}
    Consideriamo \(t > t_{0}\) Allora sia 
    \[
        \overline{t} := \sup \{ t \in J \mid x_{1}(t) = x_{2}(t) \text{ su }
        [t_{0}, t] \}
    \]
    Allora se \(\overline{t} = \sup J\) abbiamo finito, altrimenti consideriamo
    \(\overline{t} < \sup J\). Per continuità quindi \(x_{1}(\overline{t}) =
    x_{2}(\overline{t})\). Considerando ora il problama di Cauchy
    \[
        \begin{cases}
            x' = f(t, x) \\
            x(\overline{t}) = x_{1}(\overline{t}) = x_{2}(\overline{t})
        \end{cases}
    \]
    e ora per il teorema di esistenza e unicità esiste un intorno destro di
    \(\overline{t}\) si ha \(x_{1}(t) = x_{2}(t)\), che è in contraddizione con
    la definizione di \(\overline{t}\).
\end{proof}

Se manca l'ipotesi di lipschitzianità di \(f\) allora può cadere l'unicità.
Costruiamo un famoso esempio.
\begin{example}
    \(N = 1\), \(f(x) = \sqrt{|x|}\). È evidente non lipschitziana in quanto la
    derivata non è limitata.
    \begin{figure}[ht]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                xmin= -4, xmax= 4,
                ymin= -4, ymax = 4,
                axis lines = middle,
            ]
            \addplot[domain=-4:4, samples=101]{sqrt(abs(x))};
            \end{axis}
        \end{tikzpicture}
        \caption{Grafico di \(f(x) = \sqrt{|x|}\)}\label{fig:grafico_di_sqrt}
    \end{figure}
    Consideriamo il problema di Cauchy
    \[
        \begin{cases}
            x' = \sqrt{|x|} \\
            x(0) = 0
        \end{cases}
    \]
   Sia ora \(x : J \to \mathbb{R}\) una soluzione, con \(0 \in J\). Allora
   \(x(\cdot )\) è monotona non decrescente; consideriamo \(t \in J, t \ge 0\) e
   sia
   \[
       c_+ = \sup \{t\ge 0 : x(\cdot )= 0 \text{ su } [0, t]\} 
   \]
   Ora se \(c_+ = +\infty\) allora \(x(\cdot ) = 0\) su \([0, +\infty]\).
   Altrimenti, per \(t > c_+\) si ha che \(x(t) > 0\) quindi otteniamo
   \[
       \frac{x'(t)}{\sqrt{|x(t)|}} = 1 \iff \int
       \frac{x'(s)}{\sqrt{|x(s)|}} ds = t + c \iff
       2\sqrt{|x(t)|} = t + c
   \]
   Allora \(\displaystyle x(t) = \frac{1}{4} {(t + c)}^2\) e poiché \(x(c_+) =
   0\) allora \(c = -c_+\) quindi 
   \[
       x(t) = \frac{1}{4} {(t - c_+)}^2 \quad \forall t \ge c_+ 
   \]
   Similmente per \(t < 0 \) definendo similmente \(c_-\) abbiamo che le
   soluzioni del problema sono del tipo
   \[
       x(t) = \begin{cases}
           \frac{1}{4} {(t - c_+)}^2 & t \ge c_- \\
           0 & t \in [c_-, c_+] \\
           -\frac{1}{4} {(t - c_-)}^2 & t > c_+
       \end{cases}
   \]
   Dove \(c_-, c_+ \ge 0\) arbitrari (eventualmente anche \(+\infty\)). Quindi
   abbiamo infinite soluzioni. 
\begin{figure}[ht]
    \centering
    \incfig{pennellopeano}
    \caption{Pennello di Peano}\label{fig:pennellopeano}
\end{figure}
\end{example}
    Comunque abbiamo l'esistenza della soluzione. Esiste anche un teorema a
    riguardo
\begin{theorem}[Peano]
    Sia \(f : D \to \mathbb{R}^{N}\) continua e \((t_{0}, x_{0}) \in D\). Sia
    \(R_{a, b} \) come nel teorema di esistenza e unicità. Allora il problema
    \[
        \begin{cases}
            x' = f(t, x) \\
            x(t_{0}) = x_{0}
        \end{cases}
    \]
    ammette almeno una soluzione definita in \([ t_{0} - \alpha, t_{0} + \alpha
    ]\), dove \(\alpha = \min(a, \frac{b}{M})\) con \(M = \max_{R_{a, b}}|f|\).
\end{theorem}
Dimostreremo questo risultato usando un teorema di compattezza abbastanza
potente, che invece non dimostriamo. Procediamo con della terminologia.

    Sia \(\varphi_n : [a_{0}, b_{0}] \to \mathbb{R}\) continua. Diciamo che
\begin{itemize}[label = --]
    \item La successione \(\varphi_n\) è \textbf{equilimitata} se esiste \(M \in
        \mathbb{R}\) tale che
        \[
            \forall n \in \mathbb{N} \,\, \forall x \in [a_{0}, b_{0}] \quad
            |\varphi_n(x)| \le M
        \]
    \item La successione \(\varphi_n\) è \textbf{equicontinua} se 
        \[
            \forall \varepsilon > 0 \,\, \exists \delta > 0 \,\, \forall n \in
            \mathbb{N} \,\, \forall t',
            t'' \in [a_{0}, b_{0}] \quad |t' - t''| < \delta \implies
            |\varphi_n(t') - \varphi_n(t'')| < \varepsilon
        \]
\end{itemize}
\begin{theorem}[Ascoli \-- Arzelà]
    Sia \(\varphi_n\) una successione di funzioni equicontinue ed equilimitate
    su \([a_{0}, b_{0}]\). Allora esiste una sottosuccessione uniformemente
    convergente in \([a_{0}, b_{0}]\) 
\end{theorem}
\begin{proof}[Dimostrazione del teorema di Peano]
    Sia \(N = 1\) 
\begin{figure}[ht]
    \centering
    \incfig[.4]{teo_peano}
    \caption{Costruzione successione \(x_{n}\)}\label{fig:teo_peano}
\end{figure}
Fissato \(n \in \mathbb{N}\) suddividiamo \\ \([t_{0}, t_{0}+\alpha]\) in \(n\)
parti. Definiamo poi \(x_{n} : [t_{0}, t_{0} + \alpha] \to  \mathbb{R}\) come
segue (affine a tratti).
\begin{align*}
    x_{n}(t) &:= x_{0} + f(t_{0}, x_{0})(t - t_{0}) \quad \forall t \in [t_{0},
    t_{1}] \\
    x_n(t) &:= x_{n}(t_{1}) + f(t_{1}, x_{n}(t_{1}))(t - t_{1}) \quad \forall t
    \in [t_{1}, t_{2}] \\
    \vdots \\
    x_{n}(t) &:= x_{n}(t_{n-1}) + f(t_{n-1}, x_{n}(t_{n-1}))(t - t_{n-1}) \quad
    \forall t \in [t_{n-1}, t_{n}]
\end{align*} 
Notare che la pendenza di ogni tratto non supera, in valore assoluto, \(M\),
quindi \(M\alpha \le M \frac{b}{M} =b\) 

Ora vogliamo mostrare che la successione \(\{x_{n}\}\) soddisfa le iptesi del
teorema di Ascoli \-- Arzelà, infatti
\begin{itemize}[label = --]
    \item \emph{equilimitatezza} I valori sono in \([x_{0} - b, x_{0} + b]\) 
    \item \emph{equicontinuità} Sia \(\gamma_n = f(t_k, x_{n}(t_k))\) per \(t
        \in [t_k, t_{k+1}]\) costante a tratti. Allora comunque presi \(t', t''
        \in [t_{0}, t_{0}+\alpha]\) si ha che 
        \[
            (\star) \quad x_{n}(t') - x_{n}(t'') = \int_{t'}^{t''} \gamma_n ds
            \implies 
            |x_{n}(t') - x_{n}(t'')| \le M|t' - t''|
        \]
\end{itemize}
Allora esiste una sottosuccessione uniformemente convergnte \(x_{n_k} \to x\) in
\([t_{0}, t_{0}+\alpha]\). Per semplicità notazionale supponiamo che \(n_k = n\)
quindi abbiamo \(x_{n}\to x\). Ora da \((\star)\) otteniamo che per \(t'=t, t''
= t_{0}\)
\[
    x_{n}(t) = x_{0} + \int_{t_{0}}^{t} \gamma_n(s) ds
\]
Ora vorremmo poter passare al limite sotto il segno di integrale e ottenere la
soluzione del problema di cauchy, ma necessitiamo di convergenza uniforme di
\(\gamma_n(\cdot )\) a \(f(\cdot , x(\cdot ))\). Infatti abbiamo che, fissando
\(\varepsilon>0\) esiste per continuità uniforme di \(f\) un \(\delta > 0\) tale che
\[
    \forall (t_{1}, x_{1}), (t_{2}, x_{2}) \in R_{a, b} \quad |(t_{1}, x_{1}) -
    (t_{2}, x_{2})| \le \delta \implies |f(t_{1}, x_{1}) - f(t_{2}, x_{2})| \le
    \varepsilon
\]
Ora se \(s \in [t_k, t_{k+1} ]\) 
\begin{align*}
    |\gamma_n(s) - f(s, x(s))| = |f(t_k, x_{n}(t_k)) - f(s, x(s))| \le \\ \le |f(t_k,
    x_{n}(t_k)) - f(s, x_{n}(s))| + |f(s, x_{n}(s)) - f(s, x(s))|
\end{align*}
Ricordando ora che \(|x_{n}(t') - x_{n}(t'')| \le M |t' - t''\) abbiamo che se
\(n\) è sufficiente grande si ha che \(M / \frac{\alpha}{n} \le \delta\) e
allora \(|x_{n}(t_k) - x_{n}(s)| \le \delta\) e quindi \(|f(t_k, x_{n}(t_k)) -
f(s, x_{n}(s))| \le \varepsilon\). Inoltre per la convergenza uniforme di
\(x_n\) a \(x\) si ha che \(|f(s, x_{n}(s)) - f(s, x(s))| \le \varepsilon\).
Mettendo assieme i pezzi abbiamo quindi la convergenza uniforme di \(\gamma\) e
quindi possiamo passare al limite sotto il segno di integrale e ottenere che
\(x\) è soluzione del problema di Cauchy in \([t_{0}, t_{0} + \alpha]\)
\end{proof}
\begin{proposition}
    Sia \(f : D \to \mathbb{R}^{N}\) continua e \(K \subseteq D \) compatto.
    Allora esiste \(\alpha > 0\) (dipendente solo da \(K\)) tale che, per ogni
    \((t_{0}, x_{0}) \in K\) il problema
    \[
        \begin{cases}
            x' = f(t, x) \\
            x(t_{0}) = x_{0}
        \end{cases}
    \]
    ammette soluzione definita in \([t_{0} - \alpha, t_{0} + \alpha]\)
\end{proposition}
\begin{figure}[ht]
    \centering
    \incfig[.4]{compatto}
    \caption{compatto}
    \label{fig:compatto}
\end{figure}
\begin{remark}
    Modificando la costruzione della dimostrazione del teorema di Peano
    operando una suddvisione in \(n\) parti anche di \([x_{0}-b, x_{0}+b]\) e
    scegliendo su ogni tratto la pendenza \(\max f\) o \(\min f\) sul quadratino
    contenente \((t_{k}, x_{n}(t_k))\) (con qualche complicazione in più se
    becchi il punto di cambio quadratino) si ottengono due soluzioni del
    problema di Cauchy: le soluzioni massimale e minimale rispettivamente.
    Nell'esempio \(x' = \sqrt{|x|}\) abbiamo in particolare che \(0\) è la
    soluzione minimale e \(t^2\) è la soluzione massimale.
\end{remark}
\begin{example}
    Sia \(f(t, x) = x^2\) e consideriamo il problema di Cauchy
    \[
        \begin{cases}
            x' = x^2 \\
            x(0) = x_{0}
        \end{cases}
    \]
    Allora la soluzione è \(x(t) = -\frac{1}{t-\frac{1}{x_{0}}}\) che a
    prescindere di come si fa non può essere definita in \(t = x_{0}\).
    \begin{figure}[ht]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                xmin= -2, xmax= 5,
                ymin= -3, ymax = 3,
                axis lines = middle,
            ]
                \addplot[domain=-2:5, samples=100]{ - 1 / (x - 1) };
            \end{axis}
        \end{tikzpicture}
    \end{figure}
    Un obiettivo dei prossimi teoremi sarà capire quando si può prolungare il
    dominio su tutto \(\mathbb{R}\) o su molta parte.
\end{example}

Proviamo ora a guardare alla stima sull'intervallo di esistenza, data dal
Teorema di esistenza e unicità. Allora, ricordando
l'immagine~\ref{fig:problema} % TODO check ref
abbiamo che è definita in \([-\alpha, \alpha]\) con \(\alpha = \min(a, b/M)\) e
\(M = \max |f| = \max_{R_{a,b} }  |x^2| = \max_{[1-b, 1+b]}{(1+b)}^2\).
Quindi abbiamo \(\alpha = \min(a, \frac{b}{{(1+b)}^2})\). Poiché possiamo
prendere \(a\) arbitrariamente grande (\(f\) è definito su tutto \(\mathbb{R}^2
\ni (t, x)\)) allora \(\alpha = \frac{b}{{(1+b)}^2}\).

\subsection{Prolungamento}
Sia in seguito \(f : D\subseteq \mathbb{R}^{N+1} \to \mathbb{R}^{N} \) continua
e \(x : J \to \mathbb{R}^{N}\) soluzione di \(x' = f(t, x)\).

\begin{definition}{Prolungamento}
    Diciamo \textbf{prolungamento} di \(x\) ogni soluzione
    \[
        \hat{x} : \hat{J} \to \mathbb{R}^{N} \quad \hat{J} \not\supseteq J,
        \quad \hat{x}|_J = x
    \]
    se \(x(\cdot )\) non ammette prolungamento diciamo che è definita su un
    intervallo massimale.
\end{definition}
\begin{theorem}[Prolungamento]\label{th:prolungamento}
    Sia \(f\) continua, allora
\begin{enumerate}[label = \alph*)]
    \item Se \(x : J \to \mathbb{R}^{N}\) è definita su un intervallo massimale,
        questo è aperto. Posto \(J = (\omega_-, \omega_+)\) risulta:
        Per ogni \(K \subseteq D \) compatto esiste \(U\) intorno di
        \(\omega_+\) (\(\omega_-\)) tale che
        \[
            \forall t \in U \cap J \quad (t, x(t)) \not\in K
        \]
        ossia il grafico di \(x\) abbandona definitivamente ogni compatto, per
        \(t \to \omega_+ \) (\(\omega_-\)). Scrivereemo anche
        \[
            (t, x(t)) \to \partial D \quad \text{per } t \to \omega_{\pm} 
        \]
    \item Ogni soluzione ammette un prolungamento a un intervallo massimale

\end{enumerate}
\end{theorem}

\begin{figure}[ht]
    \centering
    \incfig[.5]{proprieta_massimale}
    \caption{Illustrazione del teorema di prolungamento}\label{fig:proprieta_massimale}
\end{figure}

\paragraph{Conseguenze per l'esistenza globale}
\begin{proposition}

    Sia \(D = I \times \Omega\), \(I \subseteq \mathbb{R} \) intervallo e
        \(\Omega \subseteq \mathbb{R}^{N} \) aperto. 
        Sia \(x : J \to \mathbb{R}^{N}\) una soluzione e \(J\) massimale.
        Supponiamo esiste \(Y \subseteq \Omega \) compatto tali che
        \[
            \forall  t \in J \quad x(t) \in Y
        \]
        Allora \(J = I\) e viene chiamata \textbf{esistenza globale}
\end{proposition}
\begin{proof}
    Mostriamo che \(\omega_+ = \sup I\). Se fosse \(\omega_+ < \sup I\), preso
    comunque \(t_{0} \in J\) si avrebbe
    \[
        (t, x(t)) \in  [t_{0}, \omega_+] \times Y \quad t_{0} \le  t < \omega_+
    \]
    che sarebbe assurdo perché significherebbe che il grafico di \(x\) è contenuta in un
    compatto
\end{proof}
\begin{figure}[ht]
    \centering
    \incfig[.5]{esistenza_globale}
    \caption{Esistenza Globale}\label{fig:esistenza_globale}
\end{figure}

\begin{example}
Consideriamo la logistica per esempio
\[
    x' = rx(1-\frac{x}{K})
\]
Consideriamo il problema
\[
    \begin{cases}
        x' = rx(1-\frac{x}{K}) \\
        x(0) = x_{0} \in (0, K)
    \end{cases}
\]
Il teorema di esistenza e unicità garantisce l'esistenza in \([t_{0} - \alpha,
t_{0}+ \alpha] = [-\alpha, \alpha]\). Sia \(\hat{x}\) un prolungamento
assicurato dal teorema di prolungamento. Per semplicità sia \(x : J \to
\mathbb{R}^{N}\) la soluzione di \((P)\) con \(J\) massimale. Sappiamo che le
costanti \(0\) e \(K\) sono soluzioni. Allora per unicità \(\forall t \in  J\),
\(x(t) \in (0, K)\) e quindi \(J = \mathbb{R}\).
\end{example}

\begin{example}
    Similmente abbiamo per (esercizio)
    \[
        x' = (t^2 + t + 1) x^2 \log ( 1 + {(1-\frac{x}{K})}^2 )
    \]
\end{example}

\begin{proposition}
    Sia \(D = I \times \mathbb{R}\) (quindi \(N = 1\)) e \(x : J \to
    \mathbb{R}\) soluzione con \(J\) massimale.
    Esistono
    \[
        x_{1}, x_{2} : I \to \mathbb{R}
    \]
    funzioni continue (non necessariamente soluzioni) tali che 
    \[
        \forall  t \in J : x_{1}
    \]
    Allora \(J = I\) 
\end{proposition}
\begin{proof}
    Similmente a prima, l'idea è che deve raggiungere il bordo di \(\Omega\) e
    non potendolo raggiungere ``in verticale'' deve raggiungerlo ``in
    orizzontale''. Più precisamnte, fisiamo \(t_{0} \in J\) e \(\beta \in
    (t_{0}, \sup I)\). Sia \(m = \min_{[t_{0}, \beta]} x_{1} \) e \(M =
    \max_{[t_{0}, \beta]}x_{2} \). Allora 
    \[
        \forall t \in J \cap [t_{0}, \beta] \quad x(t) \in [m, M] =: Y
    \]
    Allora per il risutato precedente \(J \supseteq [t_{0}, \beta) \) 
    Per l'arbitrarietà di \(\beta\) si ha \(\sup J = \sup I\) 
\end{proof}

\begin{proposition}
    Similmente a prima, ma sia ora \(N \ge 1\). Sia \(D = I \times
    \mathbb{R}^{N}\). Sia \(x : J \to \mathbb{R}^{N}\) soluzione con \(J\)
    masssimale. Se esiste \(\rho : I \to \mathbb{R}\) continua, tale che 
    \[
        \forall t \in J \quad |x(t)| \le \rho(t)
    \]
    Allora \(J = I\) 
\end{proposition}
\begin{proof}
    Similmente a sopra
\end{proof}

\begin{proposition}
    Sia \(D = I \times \mathbb{R}^{N}\) e \(f\) limitata.
    Sia \(x : J \to \mathbb{R}^{N}\) soluzione con \(J\) massimale. Allora \(J =
    I\) 
\end{proposition}
\begin{proof}
    se \(t_{0} \in J\) per ogni \(t \in J\) si ha che
    \begin{align*}
        x(t) = x(t_{0}) + \int_{t_{0}}^{t} f(s, x(s)) ds \iff |x(t)| &\le
        |x(t_{0})| + \int_{t_{0}}^{t} |f(s, x(s))| ds \le \\
        &\le |x(t_{0})| + M|t - t_{0}| =: \rho(t) \quad \forall t \in J
    \end{align*}
    dove \(M\) è un maggiorante per \(|f|\). A questo punto si applica il caso
    precedente 
\end{proof}

\begin{proof}[Dimostrazione del Teorema di Prolungamento] \(\) 
\begin{enumerate}[label = \alph*)]
    \item Sia \(x : J \to \mathbb{R}^{N}\) soluzione con \(J\) massimale. Allora
        \(J\) è aperto, infatti se ad esempio fosse
        \[
            \omega_+ := \sup J \in J
        \]
        Allora \((\omega_+, x(\omega_+)) \in D\). In tal caso \(x\) sarebbe
        prolungabile considerando la soluzione di \(z' = f(t, z) ; z(\omega_+) =
        x(\omega_+)\) che è chiaramente assurdo perché \(J\) è massimale.

        Non dimostriamo che \((t, x(t)) \to \partial D\) per \(t \to \omega_+\).
    \item Sia \(x : J \to \mathbb{R}^{N}\) una soluzione. Mostriamo che ammette
        un prolungamento massimale (destro wlog). Sia \(b = \sup J\). Se
        \(x(\cdot )\) non fosse prolungabile in \(t=b\) allora \(J\) sarebbe
        massimale. Supponiamo allora che
        \[
            x : [t_{0}, b] \to \mathbb{R}^{N} \text{ soluzione }
        \]
        Il grafico è compatto. Sia \(K \subseteq D \) un compatto contenente il
        grafico di \(x|_{[t_{0}, b]}\). Sappiamo ora che esiste \(\alpha_K >0\)
        tale che \(\forall (\tau_0, z_0) \in K\), il problema di Cauchy \(z' =
        f(t, z) ; z(\tau_0) = z_{0}\) ha soluzione in \([\tau_0 - \alpha_K, \tau_0
        + \alpha_K]\). Concludiamo quindi che possiamo prolungare \(x\) fino a
        \(b + \alpha_K\) considerando \((\tau_0, z_{0}) = (b, x(b))\). Se ora
        \((b + \alpha_K, x(b + \alpha_K)) \in K\) si ripete il ragionamento.
        Poiché \(K\) è compatto, dopo l'applicazione del ragionamento un numero
        finito di volte, poiché \(\alpha_K\) è il medesimo ad ogni passo, il
        grafico esce da \(K\), cioè esiste una \(b_K\) tale che \(x\) è definita
        su \([t_{0}, b_K]\) e \((b_K, x(b_K)) \not\in K\). Applichiamo il metodo
        considerando una famiglia \({\{V_{j}\}}_{j \in \mathbb{N}}\) con
        \(V_{j}\) aperto e \(V_{j} \subset\subset D \), \( V_{j} \to D \) crescenti,
        ossia \(V_{j} \subseteq V_{j+1}  \) e \(\bigcup_{j} V_{j} = D\) e
        inoltre \(\overline{V_{1}} = \text{graf}(x|_{[t_{0},b]})\). Applichiamo
        ora lo schema precedente con \(K = \overline{V_{1}}\) e allora esiste
        \(b_{1} = b_{\overline{V_{1}}} \) tale che \(x\) è definita su \([t_{0},
        b_{1}]\) e \((b_{1}, x(b_{1})) \not\in \overline{V_{1}}\) (per
        semplicità notazionale supponiamo che il grafico di
        \(x|_{[t_{0},b_{1}]}\) sia contenuto in \(V_{2}\)) allora ora iterando
        abbiamo che esiste \(b_{2} = b_{V_{2}}\) tale che \(x\) è definita su 
        \([t_{0}, b_{2}]\) e \((b_{2}, x(b_{2})) \not\in V_{2}\) e così via.
        Abbiamo ora \(b_{1} < b_{2}<\dots < b_k <\dots\) tale che \(x\) è
        definita su \([t_{0}, b_k]\) e \((b_k, x(b_k)) \not\in V_{k}\). Ne
        seguirà che, posto \(\omega_+ = \sup_{k \in \mathbb{N}}b_k \) si a che
        \(x\) è definita in \(J := [t_{0}, \omega_+)\). Se \(\omega_+ = +\infty\)
        allora banalmente \(J\) è massimale destro. Se \(J\) non fosse massimale
        si avrebbe \(x(\cdot )\) definita in \(\omega_+\) e \((\omega_+,
        x(\omega_+)) \in D\). Ciò è incompatibile con 
        \[
            \overline{V_k} \not\ni (b_k, x(b_k)) \to (\omega_+, x(\omega_+)) \quad \text{per }
            k \to \infty
        \]
\end{enumerate}
\end{proof}

\subsection{Stime}
\begin{theorem}[Lemma di Gronwall]
    Sia \(\beta \in C^{0}(I)\), \(\beta \ge 0\); \(a \in I\) e \(\alpha \in
    \mathbb{R}\) e \(u \in C^{0}(I)\) tali che
    \[
        u(t) \le \alpha + \int_{a}^{t} \beta(s) u(s) ds \quad \forall t \in I, t
        \ge a
    \]
    Allora
    \[
        u(t) \le \alpha e^{\int_{a}^{t} \beta(s) ds} \quad \forall t \in I, t
        \ge a
    \]
\end{theorem}
\begin{proof}
    % TODO
\end{proof}

\paragraph{Applicazione al problema di Cauchy}
Consideriamo l'equazione differenziale \(x' = f(t, x)\) con \(f : D \to
\mathbb{R}^{N}\) continua localmente lipschitziana. Siano \(x_{1},x_{2} : J \to
\mathbb{R}^{N}\) due soluzioni. Fissiiamo \(t_{0} \in J\) si ha che
\begin{align*}
    x_{1}(t) &= x_{1}(t_{0}) + \int_{t_{0}}^{t} f(s, x_{1}(s)) ds \\
    x_{2}(t) &= x_{2}(t_{0}) + \int_{t_{0}}^{t} f(s, x_{2}(s)) ds
\end{align*}
Sottraendo membro a membro si ha
\[
    |x_{1}(t) - x_{2}(t)| \le |x_{1}(t_{0}) - x_{2}(t_{0})| + \int_{t_{0}}^{t}
    |f(s, x_{1}(s)) - f(s, x_{2}(s))| ds
\]
Fissato \(\overline{t} > t_{0}\), se \(t \in [t_{0}, \overline{t}]\) e \(K\) è
un compatto di \(D\) contenente i grafici di \(x_{1, 2}|_{[t_{0}, \overline{t}]}
\). Sia allora \(L_K\) una costante di Lipschitz di \(f\) relativa a \(K\).
Allora
\[
    \underbrace{|x_{1}(t) - x_{2}(t)|}_{u(t)} \le \underbrace{|x_{1}(t_{0}) -
    x_{2}(t_{0})|}_{\alpha} + \underbrace{L_K}_{\beta}
    \int_{t_{0}}^{t} \underbrace{|x_{1}(s) - x_{2}(s)|}_{u(s)} ds
\]
Che rispetta le ipotesi del lemma di Gronwall e quindi sappiamo che
\[
    \underbrace{|x_{1}(t) - x_{2}(t)|}_{u(t)} \le \underbrace{|x_{1}(t_{0}) -
    x_{2}(t_{0})|}_{\alpha} e^{L_K(t-t_{0})}
    \quad \forall t \ge t_{0}
\]
Da tale schema scende anche l'unicità della soluzione del problema di Cauchy.
Infatti se \(x_{1}(t_{0}) = x_{2}(t_{0})\) abbiamo
\[
    |x_{1}(t) - x_{2}(t)| \le 0 \quad \forall t \in J, t \ge t_{0}
\]

Iniziamo ora con un'idea del prossimo teorema, con un'intuizione geometrica. Sia
dato un campo di pendenze (\(N=1\)). Ossia 
\[
    (t, x) \mapsto \omega(t, x) \in \mathbb{R}^2
\]
\begin{figure}[ht]
    \centering
    \incfig[.8]{confronto}
    \caption{La curva \(x(\cdot)\) ha pendenza sempre minore della pendenza che
    il campo di pendenze assegna in ogni punto, mentre la curva \(u(\cdot )\)
segue la pendenza in ogni punto e ha valore iniziale \(u(a)\) non minore di \(x(a)\)  }\label{fig:confronto}
\end{figure}

\begin{theorem}[Teorema del confronto]
    Sia \(D \subseteq \mathbb{R}^2 \) aperto e \(\omega : D \to \mathbb{R}\)
    continua e localmente lipschitziana in \(x\) uniformemente rispetto a \(t\).
    Sia \(x, u : J \to \mathbb{R}\) di classe \(C^{1}\), sia \(a \in J\) 
        Se \(x'(t) \le \omega(t, x(t))\) e \(u'(t) = \omega(t, u(t))\), se
        \(x(a) \le u(a)\) allora
        \[
            x(t) \le u(t) \quad \forall t \in J, t \ge a
        \]
\end{theorem}
\begin{proof}
    Supponiamo per assurdo che esista un valore \(\overline{t} \in J\) con
    \(\overline{t} > a\) tale che \(x(\overline{t})> u(\overline{t})\).
    Sia \(t_{0} = \sup \{t \in [0, \overline{t}] : x(t) \le u(t)\} \). Allora
    \(x(t_{0}) = u(t_{0})\) (per continuità)e \(x(t) > u(t)\) per \(t \in
    (t_{0}, \overline{t}]\).
    Adesso per ogni \(t \in [t_{0}, \overline{t}]\) abbiamo
    \[
        x(t) = x(t_{0}) + \int_{t_{0}}^{t} x'(s) ds \le x(t_{0}) +
        \int_{t_{0}}^{t} \omega(s, x(s)) ds
    \]
    e
    \[
        u(t) = u(t_{0}) + \int_{t_{0}}^{t} u'(s) ds = u(t_{0}) + \int_{t_{0}}^{t}
        \omega(s, u(s)) ds
    \]
    Sottraendo membro a membro e prendendone il module otteniamo
    \[
        x(t) - u(t) \le x(t_{0}) - u(t_{0}) + \int_{t_{0}}^{t} \omega(s, x(s)) - \omega(s, u(s)) ds
    \]
    Sia ora \(L_K\) una costante di Lipschitz relativa a un compatto \(K\)
    contenente i grafici di \(x, u\) su \([t_{0}, \overline{t}]\). Allora
    \[
        x(t) - u(t) \le x(t_{0}) - u(t_{0}) + L_K \int_{t_{0}}^{t} |x(s) -
        u(s)| ds
    \]
    Ma ora in \([t_{0}, \overline{t}]\) possiamo togliere il modulo perché
    abbiamo che \(x(t) \ge u(t)\). Abbiamo allora
    \[
        \underbrace{x(t) - u(t)}_{u(t)} \le \underbrace{x(t_{0}) -
        u(t_{0})}_{\alpha=0} + \underbrace{L_K}_\beta \int_{t_{0}}^{t}
        \underbrace{x(s) - u(s)}_{u(s)} ds
    \]
    Che rispetta le ipotesi del lemma di Gronwall e quindi sappiamo che
    \[
        x(t) - u(t) \le 0 \quad \forall t \in [t_{0}, \overline{t}]
    \]
    che è assurdo.
\end{proof}

\begin{example}
    Consideriamo 
    \[
        \begin{cases}
        x' = rx\left( 1 - \frac{x}{k} \right)  \\
        x(0) = x_{0} < 0
        \end{cases}
    \]
    Allora evidentemente \(x' \le -\frac{r}{k} x^2\) per \(x < 0\) e quindi
    abbiamo
    \[
        \begin{cases}
            x' \le  -\frac{r}{k} x^2 \\
            x(0) = x_{0} < 0
        \end{cases}
        \quad 
        \begin{cases}
            u' =  -\frac{r}{k} u^2 \\
            u(0) = x_{0}
        \end{cases}
    \]
    Ne concludiamo che \(x(t) \le u(t)\) per il teorema del confronto. In
    particolare abbiamo che \(\omega_+ < +\infty\) 

    Vogliamo ora fare un ragionamento simile per studiare il caso \(x_{0} > k\).
    Se consideriamo la parabola di equazione \(y = rx(1-\frac{x}{k})\) abbiamo
    che sicuramente esiste una parabola \(-\gamma x^2\) tale per cui \(y \le
    -\gamma x^2  \) per \(x \ge x_{0}\) e quindi abbiamo che
    \[
        \begin{cases}
            x' \le -\gamma x^2 \\
            x(0) = x_{0} > k
        \end{cases}
        \quad
        \begin{cases}
            u' = -\gamma u^2 \\
            u(0) = x_{0}
        \end{cases}
    \]
    e quindi \(x(t) \ge u(t)\) per il teorema del confronto. In particolare
    abbiamo che \(x\) ha un asintoto verticale a sinsitra (per \(t < 0\)).
\end{example}
\begin{remark}[Teorema dell'asintoto]
    Sia \(x : [a, +\infty) \to \mathbb{R}\) una funzione derivabile tale che 
    \[
        \lim_{t \to +\infty} x(t) = l \in \mathbb{R} \quad \text{ (finito,
        \(x(\cdot )\) ha un asintoto)}
    \]
    Inoltre esiste \(\lim_{t \to +\infty} x'(t)\). 
    Allora
    \[
        \lim_{t \to +\infty} x'(t) = 0
    \]
    Infatti abbiamo
    \[
        x(t + 1) - x(t) = x'(\xi_t) \quad \xi_t \in (t, t+1)
    \] e portando al limite otteniamo
    \[
        0 = l - l = \lim_{t \to +\infty} x'(\xi_t) = 0
    \]

    La conseguenza è che se ho \(x(\cdot )\) soluzione del problema di Cauchy
    della logistica, allora se \(x \to l\) per \(t \to +\infty\) ho che 
    \[
        x'(t) = rx(t)(1-\frac{x(t)}{k}) \to rl (1 - \frac{l}{k}) = 0
    \]
    quindi necessariamente \(l=0\) (no) oppure \(l=k\) (sì).
\end{remark}

\subsection{Dipendenza continua}
\begin{theorem}
    Siano \(f_{0}, f_{j} : D \to \mathbb{R}^{N}\), con \(j \in \mathbb{N}\) e
    \(D \in \mathbb{R}^{N+1}\) funzioni continue. Consideriamo i problemi
    \[
        (P_{j})\,\,\begin{cases}
            x' = f_{0}(t, x) \\
            x(t_{0}) = x_{0}
        \end{cases}
        \quad
        (P_{0}) \,\,
        \begin{cases}
            x' = f_{j}(t, x) \\
            x(t_{0}^{j}) = x_{0}^{j}
        \end{cases}
    \]
    dove \({(t_{0}^{j}, x_{0}^{j})}\) e \((t_{0},x_{0})\) sono assegnati in
    \(D\). Supponiamo ora che \(f_{j}\to f_{0}\) uniformemente sui compatti di
    \(D\), che \((t_{0}^{j}, x_{0}^{j}) \to {(t_{0},x_{0})}\) e supponiamo che
    \(f_{0}\) sia localmente Lipschitziana in \(x\) uniformemente rispetto a
    \(t\).
    Sia \([a,b]\) un intervallo su cui è definita la soluzione \(\varphi_{0}\)
    di \((P_{0})\). Se \(\varphi_j\) risolve \((P_{j})\) allora per \(j\)
    sufficientemente grande \(\varphi_j\) è definita in \([a,b]\) e \(\varphi_j
    \to \varphi_{0}\) uniformemente su \([a,b]\) 
\end{theorem}
\begin{figure}[ht]
    \centering
    \incfig[.4]{dipcontinua}
    \caption{dipcontinua}\label{fig:dipcontinua}
\end{figure}
\begin{remark}
    Si noti il caso particolare in cui \(f_{j}=f_{0}\).
\end{remark}
Per il precedente teorema esiste anche una forma variante.
    \[
        \begin{cases}
            x'=f(t, x, \lambda) \\
            x{(t_{0})} = x_{0}
        \end{cases}
    \]
    con \(f : G \to \mathbb{R}^{N}\) e \(G \subseteq \mathbb{R}\times
    \mathbb{R}^{N} \times \mathbb{R}^{m} \) aperto e chiamiamo \(G_\lambda :=
    \{{(t,x)} \in \mathbb{R}^{N+1} : {(t,x,\lambda)} \in G\} \). Supponiamo ora
    che \(f\) sia continua e tale che \(f{(\cdot , \cdot ,\lambda)}\) sia
    localmente lipschitziana su \(G_\lambda\) nella seconda variabile
    uniformemente rispetto alla prima, per ogni \(\lambda\).~\emph{In ipotesi di
unicità} indichiamo con \(x(\cdot ,t_{0}, x_{0})\) l'unica soluzione, definita
sul suo intervallo massimale \({(\omega_-{(t_{0},x_{0})},
\omega_+{(t_{0},x_{0})})}\). Consideriamo ora il problema
\[
    (P_\lambda) \begin{cases}
        x' = f(t, x, \lambda) \\
        x(t_{0}) = x_{0}
    \end{cases}
\]
    dove \({(t_{0},x_{0},\lambda)}\) è assegnato in \(G\). Indichiamo con
    \(x{(\cdot ,t_{0},x_{0},\lambda)}\) la soluzione di \((P_\lambda)\) definita
    nel proprio intervallo massimale \({(\omega_-{(t_{0},x_{0},\lambda)},
    \omega_+{(t_{0},x_{0},\lambda)})}\). Allora abbiamo
\begin{theorem}
\begin{itemize}
    \item \(\omega_-\) (\(\omega_+\)) è semicontinua superiormente
        (inferiormente) in \(G\) 
    \item l'insieme 
        \[
            E = \{{(t,t_{0},x_{0},\lambda)} \in \mathbb{R}\times G :
            \omega_-{(t_{0},x_{0},\lambda)} < t < \omega_+{(t_{0},x_{0},\lambda)}\} 
        \]
        è aperto
    \item \(x : E \to \mathbb{R}^{N}\) definita da
        \({(t,t_{0},x_{0},\lambda)} \mapsto x{(t,t_{0},x_{0},\lambda)}\) è
        continua
\end{itemize}
\end{theorem}
\begin{definition}{Semicontinuità}
    Sia \(X\) uno spazio topologico, \(x_{0} \in X\) e \(f: X \to \mathbb{R}\).
    Diciamo che \(f\) è \textbf{semicontinua inferiormente} in \(x_{0}\) se
    \[
        \forall \varepsilon > 0 \quad \exists U \text{ intorno di } x_{0} :
        f(x) > f(x_{0}) - \varepsilon \quad \forall x \in U
    \]
\end{definition}
Dove vale la seguente caratterizzazione
\begin{proposition}
    Sono equivalenti: 
\begin{enumerate}[label = \roman*)]
    \item \(f\) è semicontinua inferiormente in \(X\)
    \item \(\{x \in X : f{(x)}>\alpha\} \) è aperto per ogni \(\alpha \in \mathbb{R}\) 
    \item l'epigrafico di \(f\), cioè 
        \[
            \text{epi}(f) = \{{(x, \alpha)} \in X \times \mathbb{R} : f(x) \le
            \alpha\} 
        \]
        è chiuso
    \item \(\liminf_{x \to x_{0}} f(x) \ge f(x_{0})\)
\end{enumerate}
\end{proposition}
\begin{proof}\( \)
\begin{itemize}
    \item[\(i) \implies ii)\)] Fissiamo \(x_{0} \in \{f>\alpha\}\); allora
        \(f(x_{0}) > \alpha\). Dalla definizione esiste \(U\) intorno di
        \(x_{0}\) tale che \(\forall x \in U\) si ha che \(f(x) \ge f(x_{0})
        -\varepsilon > \alpha\) e quindi \(U \subseteq \{f > \alpha\}\) 
    \item[\(ii) \implies iii) \)] 
    \item[\(iii) \implies iv) \)]
    \item[\(iv) \implies i)\)]
\end{itemize}
\end{proof}

\begin{proof}[Dimostrazione parziale del Teorema]
    Dalla caratterizzazione di semicontinuità inferiore sappiamo che l'insieme
    \(\{(t, t_{0},x_{0}, \lambda) : t < \omega_+{(t_{0},x_{0},\lambda)}\} \) è
    aperto. Analogamente per \(\{{(t,t_{0},x_{0},\lambda)}: t>
        \omega_-{(t_{0},x_{0},\lambda)} \). L'intersezione dà \(E\) aperto.
        Dimostrare che \(\omega_-\) e \(\omega_+\) sono semicontinue
        rispettivamente superiormente e inferiormente è molto complicato.
\end{proof}
\begin{figure}[ht]
    \centering
    \incfig[.5]{prooftheorema}
    \caption{prooftheorema}
    \label{fig:prooftheorema}
\end{figure}
\begin{eser}
    \[
        (P) \begin{cases}
            x' = 1-te^{x} \\
            x(0) = \alpha \in \mathbb{R}
        \end{cases}
    \]
     Studiamo quando \(x' > 0\) e abbiamo \(1 - te^{x}> 0\) e quindi \(te^{x}<1\)
     e \(t < e^{-x}\) e quindi \(x < -\log t\).
     Sia ora 
     \[
         \overline{t} = \sup \{t \ge t_{1} : x(\tau) > \psi {(\tau)} \forall \tau
         \in [t_{1}, t]\} 
     \]
    Supponiamo ora \(\overline{t} < +\infty\) e allora sia \(\delta(t) =
    x{(t)}-\psi {(t)}\). Allora \(\delta {(\overline{t})}=0\) per continuità e
    \(\delta'{(\overline{t})} = \underbrace{x'{(\overline{t})}}_{0}  -
    \underbrace{\psi'{(\overline{t})}}_{<0} > 0\). Ne consegue che in un intorno
    sinistro di \(\overline{t}\) si ha che \(\delta(t) < 0\) che è assurdo. Ne
    conseguo che \(\overline{t} = +\infty\) e quindi si ottiene che \(\omega_+ =
    +\infty\), infatti il grafico di \(x{(\cdot )}\) si deve trovare sotto al
    valore \(x{(t_{1})}\) e sopra al grafico di \(\psi\). Per monotonia esiste
    \(\lim_{t\to +\infty} x{(t)}\). Se fosse finito si avrebbe
    \[
        \lim_{t\to +\infty} x'{(t)} = \lim_{t \to +\infty} 1 - te^{x{(t)}} =
        -\infty
    \]
    escluso per il teorema dell'asintoto. Ne concludiamo che \(\lim_{t\to
    +\infty} = -\infty\).

    Per \(t < 0\) invece abbiamo che
    \[
        0 \le 1-te^{x} \le 1 - t e^{\alpha} = 1 + e^{\alpha} |t|
    \]
    che è una crescita sottolineare e quindi \(\omega_- = -\infty\) e per un
    argomento simile al precedente si ha che \(\lim_{t \to -\infty} x{(t)} =
    -\infty\)
\end{eser}
\begin{figure}[ht]
    \centering
    \incfig[.6]{eser1}
    \caption{Esercizio 1.1}\label{fig:eser1}
\end{figure}
\begin{eser}
    Si studi qualitativamente il problema di Cauchy
    \[
        \begin{cases}
            x' = x{(x^3-t^2)} \\
            x{(1)}=1
        \end{cases}
   \]
\end{eser}
\begin{remark}[sulla dipendenza continua]
    Consideriamo il problema di Cauchy
    \[
        \begin{cases}
            x' = x^2 \\
            x{(0)} = x_{0} > 0
        \end{cases}
    \]
    allora otteniamo \( \displaystyle x{(t)} = - \frac{1}{t-\frac{1}{x_{0}}}\).

    Fissato \(T > 0\) consideriamo i valori \(x_{0}\) per i quali la soluzione è
    definita (almeno) in \([0, T]\), quindi \(x_{0} < \frac{1}{T}\). Per \(x_{0}
    \to 0\) per la dipendenza continua la soluzione tende (uniformemente perché
    su \([0, T]\)) alla soluzione 0. In particolare \(x{(T)} < \varepsilon\) se 
    \[
        \frac{1}{x_{0}} - T > \frac{1}{\varepsilon} \iff \frac{1}{x_{0}} > T +
        \frac{1}{\varepsilon} \iff x_{0} < \frac{1}{T + \frac{1}{\varepsilon}}
        =: \delta_{\varepsilon, T} 
    \]
    per cui \(\delta\) dipende sia da \(\varepsilon\) che da \(T\) e non è
    possibile individuarlo uniformemente rispetto a \(T\).

    La proprietà, diversa, di ``dipendenza continua'' su intervalli illimitati
    darà luogo alla definizione di stabilità.
\end{remark}

\section{Sistemi autonomi}
Sia \(\Omega \subseteq \mathbb{R}^{N} \) aperto e sia \(f : \Omega \to
\mathbb{R}^{N}\). Supponiamo \(f\) localmente lipschitziana in \(\Omega\). Il
sistema che consideriamo è 
\[
    \begin{cases}
        x' = f(x) \\
        x(t_{0}) = x_{0}
    \end{cases}
\]
Indichiamo con \(x{(\cdot , t_{0}, x_{0})}\) la soluzione definita
sull'intervallo massimale.
\begin{proposition}
\begin{enumerate}[label = \arabic*.]
    \item Sia \(x : J \to \mathbb{R}^{N}\) una soluzione di \(x' = f{(x)}\); sia
    \(\tau > 0\). Allora \(x_\tau : J+\tau \to \mathbb{R}^{N}\) definita da
    \(x_\tau{(t)} = x{(t - \tau)}\) è soluzione.
\item Se \(x_{1}\) e \(x_{2}\) sono due soluzioni di \(x' = f{(x)}\) che assumono
    un valore comune allora sono traslate temporali l'una dell'altra.
\end{enumerate}
\end{proposition}
\begin{proof}
\begin{enumerate}[label = \arabic*.]
    \item Già vista 200 volte: 
        \[
            x'_\tau{(t)} = x'{(t - \tau)} = f{(x{(t-\tau)})} = f{(x_\tau{(t)})}  
        \]
\begin{figure}[ht]
    \centering
    \incfig[.4]{prop_2}
\end{figure}
    \item usando la notazione del disegno, supponiamo \(u{(t)} = x_{1}{(t -
        {(t_{2} - t_{1})})}\). Allora \(u\) è soluzione di \(x' = f{(x)}\) in
        quanto traslata di \(x'\). Inoltre \(u{(t_{2})} = x_{1}{(t_{1})} =
        \overline{x} = x_{2}{(t_{2})}\), per unicità quindi \(u \equiv x_{2}\) 
\end{enumerate}
\end{proof}
Allora stesso modo si vede che \(x{(t, t_{0}, x_{0})} = x{(t-t_{0}, 0,
x_{0})}\). Infatti \(x{(\cdot , t_{0}, x_{0})}\) risolve il problema originale e
allora
\[
    x{(\cdot - t_{0}, 0, x_{0})} \text{ risolve } \begin{cases}
        x' = f{(x)} \\
        x(\cdot - t_{0}, 0, x_{0})|_{t = t_{0}}  = x{(0, 0, x_{0})} = x_{0}
    \end{cases}
\]
che per unicità coincidono.

Ne consegue che posso sempre ricondurre un problema di Cauchy autonomo a uno in
cui \(t_{0} = 0\). È una cosa così comune che motiva la seguente definizione

\begin{definition}{Flusso}
    Diciamo \textbf{flusso} associato all'equazione differenziale \(x' = f
    {(x)}\) la funzione
    \[
        \varphi {(t, \xi)} = x{(t , 0, \xi)}
    \]
    con \(\xi \in \Omega\) e \( t\) variabile nell'intervallo massimale
    \({(\omega_-{(\xi)}, \omega_+{(\xi)})}\) della soluzione \(x{(\cdot , 0, \xi)}\) 
\end{definition}

\begin{proposition}\label{prop:flusso}
    \begin{itemize}
    \item \(\omega_+\, [\omega_-]\) è semicontinua inferiormente [superiormente] in
    \(\Omega\)
\item \[
        \{{(t, \xi)} \in \mathbb{R} \times \Omega : \xi \in \Omega,
        \omega_-{(\xi)} < t < \omega_+{(\xi)}\} 
    \]
    è aperto.

\item \(\varphi : E \to \mathbb{R}^{N}\) è continua

\item \(\varphi {(0, \cdot )} = \text{id}_\Omega\) 

\item \(\varphi {(s, \varphi {(t, \xi)})} = \varphi {(s+t, \xi)}\) 
    \end{itemize}
\end{proposition}
    
\begin{proof}[Dimostrazione ultimo punto]
    Le funzioni \(\varphi {(\cdot , \varphi {(t, \xi)})}\)  e \(\varphi {(\cdot
    +t, \xi)}\) sono due soluzioni di \(x'=f{(x)}\) che coincidono in \(t = 0\),
    poiché valgono entrambe \(\varphi {(t, \xi)}\). Per unicità quindi
    coincidono.
\end{proof}

\begin{remark}
    Sia \({(X, d)}\) uno spazio metrico che sia \(\varphi : \mathbb{R} \times X
    \to X\) continua tale che
    \[
        \begin{cases}
            \varphi {(0, \cdot )} = \text{id}_X \\
            \varphi {(s, \varphi {(t, \xi)})} = \varphi {(s+t, \xi)}
        \end{cases}
    \]
    allora \(\varphi \) è anche detta ``sistema dinamico''
\end{remark}

\begin{definition}{Orbita}

Dato \(x_{0} \in \Omega\) diciamo \textbf{orbita} per \(x_{0}\) l'insieme 
\[
    \gamma_{x_{0}} = \{\varphi {(t, x_{0})} : t \in {(\omega_-{(x_{0})},
    \omega_+{(x_{0})})}\}
\]
\end{definition}
\begin{remark}
    Utilizzando \(t \mapsto x{(t, t_{0},x_{0})}\) in luogo di \(x{(t, 0,
    x_{0})}\) si ottiene lo stesso insieme \(\gamma_{x_{0}}\), perché è
    semplicemente una traslata temporale.
\end{remark}
\begin{note}
    \(\gamma_{x_{0}} \) è la proiezione del grafico di \(x{(\cdot ,0, x_{0})}\)
    su \(\Omega\) 
\end{note}
\begin{proposition}
    Se due orbite hanno un punto in comune, allora coincidono
\end{proposition}
\begin{proof}
    Solito discorso di traslazione temporale, perché due soluzioni che assumono
    lo stesso valore devono essere traslate temporali una dell'altra, e quindi
    la proiezione su \(\Omega\) coincide.
\end{proof}
\begin{proposition}
    Se un'orbita non è un singoletto allora è una curva regolare.
\end{proposition}
\begin{proof}
    Sia \(x\) soluzione di \(x' = f{(x)}\). Se \(x'{(t_{0})} = 0\) per un
    qualche \(t_{0}\) allora
    \[
        0 = x'{(t_{0})} = f{(x{(t_{0})})}
    \]
    ma allora posto \(x{(t_{0})} = x_{0}\) la funzione costante \(u{(t)} =
    x_{0}\) è una soluzione, e per unicità è l'unica soluzione, quindi l'orbita
    è un singoletto.
\end{proof}
\begin{eser}
    Si consideri il sistema
    \[
        \begin{cases}
            x' = \frac{x - t^2}{x^2 + t^2} \\
            x{(0)} = a > 0
        \end{cases}
    \]
    Allora \(f{(t, x)} > 0\) per \(x > t^2\) 
    Per il teorema di esistenza e unicità esiste \(\delta > 0\) tale che la
    soluzione esiste in \([-\delta, \delta]\). Possiamo supporre \(\delta < a\).
    Per \(t \ge \delta\) 
    \[
        \left| \frac{x-t^2}{x^2 + t^2} \right| \le \frac{1}{\delta} {\left(
        |x|+t^2 \right)} 
    \]
    e quindi per crescita sottolineare \(\omega_- = -\infty\). 
    Ora l'obiettivo è trovare una funzione \(u\) tale che \(x' \le u'\) e \(u\)
    taglia \(x = t^2\). Se fosse ora che \(x{(t)} \ge t^2\) per \(t \in [0,
    \omega_+]\) allora necessariamente da un certo tempo in poi \(x {(t)} \ge
    1\), per tali \(t\) allora \(x{(t)}\le x{(t)}^2\) da cui
    \[
        x'{(t)} \le \frac{x{(t)}^2 - t^2}{x{(t)}^2 + t ^2} \le  1
    \]
    ma allora \(x{(t)}\le x{(0)} + t = a +t\) assurdo. Alternativamente si può
    mostrare che taglia la parabola anche dicendo che
    \[
        x' \le \frac{x}{x^2 + t ^2} \le \frac{x}{x^2} = \frac{1}{x}
    \]
    allora \(u' = \frac{1}{u}\) ha soluzione \(u{(t)} = \sqrt{2{(t+c)}}\) e
    poiché \(x{(t)} \le u{(t)}\) che taglia \(x=t^2\) allora necessariamente
    anche \(x\) taglia tale parabola. Quindi \(\omega_+ = +\infty\) 
    Ora sia \( l = \lim_{t \to \infty} x{(t)}\). Se \( l \in \mathbb{R}\) allora
    \[
        x'{(t)} \to -1 \text{ escluso dal teorema dell'asintoto }
    \]
    allora \(\lim_{t \to \infty} x{(t)} = - \infty\) 
\end{eser}
\begin{figure}[ht]
    \centering
    \incfig[.3]{esercizio2-1}
    \caption{esercizio2-1}
    \label{fig:esercizio2-1}
\end{figure}
\begin{eser}
    Si risolva il problema di Cauchy
    \[
        \begin{cases}
            x' = \frac{x{(1-x)}}{2t}\\
            x{(0)} = x_{0}
        \end{cases}
    \]
    in \(t > 0\). Poi si studi qualitativamente il problema di Cauchy
    \[
        \begin{cases}
            x' = \frac{g{(x)}}{2t} \\
            x{(1)} = x_{1}
        \end{cases}
    \]
    dove \(g{(x)}\) ha lo stesso segno di \(x {(1-x)}\) 
\end{eser}


\section{Tecniche elementari di Integrazione}
Ne conosciamo già diverse, come le equazioni a variabili separabili, le
equazioni lineari del primo ordine e secondo ordine. Cambiare poco nelle forme
porta a equazioni differenziali molto diverse e con soluzioni difficili.
Nell 1800 si è cercato di mettere ordine e di capire in quali casi si può solo
trovare un modello qualitativo (esempio trovare che Lotka-Volterra abbia le
orbite chiuse). E molto spesso anche se ci sono soluzioni a volte basta sapere
una soluzione approssimata, e quindi le tecniche esplicite di soluzione sono un
po' meh. E allora a cosa servono le tecniche esplicite di risoluzione? Boh
diciamo che quelle facili sono utili perché dai, servono (cit.) mentre altre più
complicate si fanno solo per vedere quanto è difficile risolvere equazioni
differenziali ma è simpatico quindi vederle come esempi.

\subsection{Equazioni di tipo omogeneo}
Si tratta di equazioni della forma
\[
    x ' = g{\left( \frac{x}{t} \right)}  \text{ con \(g\) continua } 
\]
Si ponga \(z{(t)} = {\frac{x{(t)}}{t}}\) cioè \(x{(t)} = tz{(t)}\) da cui
\(x'{(t)} = z{(t)} + tz'{(t)}\) e quindi l'equazione diventa
\[
    z + tz' = g{(z)} \iff z' = \frac{g{(z)} - z}{t}
\]
che è a variabili separabili
\begin{example}
    \[
        x' = \frac{t + x}{t - x} = \frac{1 + \frac{x}{t}}{1 - \frac{x}{t}} =:
        g{\left( \frac{x}{t} \right)} 
    \]
    e quindi ponendo \(z = \frac{x}{t}\) abbiamo \(x' = z + tz'\) e quindi
    \[
        z + tz' = \frac{1 + z}{1 - z} \iff tz' = \frac{1+z}{1-z} - z = \frac{1+
        z - z + z^2}{1 - z} = \frac{1 + z^2}{1 -z}
    \]
    che diventa
    \[
        z' = \frac{1}{t}\frac{1 + z^2}{1-z} \implies  \int \frac{1-z}{1 + z^2} dz =
        \log|t| + c \implies  \arctan z - \frac{1}{2}\log{(1+z^2)} = \log|t| + c
    \]
    e quindi
    \[
        \arctan \frac{x}{t} - \log{\sqrt{1+{\left( \frac{x}{t} \right)} ^2}} =
        \log|t| + c
    \]
    e poiché \(\log{\sqrt{1 + {\left( \frac{x}{t} \right)}^2 }} = \log
    \frac{\sqrt{t^2+x^2}}{|t|} = \log \sqrt{t^2+x^2} - \log|t|\) abbiamo che le
    soluzioni sono definite esplicitamente da
    \[
        \arctan \frac{x}{t} - \log \sqrt{t^2+x^2} = c
    \]
    Allora per \(t > 0\) se chiamiamo \(\theta = \arctan \frac{x}{t}\) e \(\rho
    = \sqrt{x^2 + t^2}\) significa \(\theta - \log \rho = c\) da cui
    \[
        \rho = C e^{\theta}
    \]
    che è un pezzo di una spirale logaritmica
    Similmente per \(t < 0\) abbiamo che \(\alpha = \arctan{\left( \frac{x}{-t}
    \right)} = - \arctan \frac{x}{t}\) e allora se \(\theta = \pi - \alpha\)
    otteniamo di nuovo una spirale logaritmica.

    Questa però non è il modo più ``bello'' di risolvere questa equazione:
    vedremo un modo per risolvere questa equazione attraverso il formalismo
    delle forme differenziali, e trovando soluzioni più chiare. In questo caso
    ad esempio
    \[
        x' = \frac{t + x}{ t- x } \mapsto \omega := {(t + x)}dt - {(t - x)}dx = 0 
    \]
\end{example}

Le equazioni di tipo omogeneo ammettono una avvia generalizzazione. Premessa:
\(x'= g{(at + bx)}\) si ponga \(z{(t)} = at + bx{(t)}\), allora \(z'= a+bx'\) e
quindi \(z' = a + bg{(z)}\) che è a variabili separabili.
Ora possiamo generalizzare le precedenti equazioni di tipo omogeneo in 
\[
    x' = g{\left( \frac{at + bx + c}{a't + b'x + c'} \right)} 
\]
che ha come caso particolare il precedente \(x' = g{\left( \frac{x}{t} \right)}
\) se \(a = a' = 1\) e \(b = c= b'= c'= 0\) e anche \(x' = g{(at + bx)}\) per
\(c'=1\) e \(c = a'=b'=0\). Distinguiamo ora due casi
\begin{itemize}[label = --]
    \item \(\text{det} \begin{bmatrix}
        a & b  \\
        a' & b'
    \end{bmatrix} = 0\) ad esempio \({(a', b')} = \gamma{(a, b)}\). Allora
    l'equazione diventa
    \[
        x' = g{\left( \frac{at + bx +c}{\gamma{(at + bx)} + c'} \right)} =
        \tilde{g}{(at+ bx)}
    \]
    e ricadiamo nel caso precedente
    \item \(\text{det}\begin{bmatrix}
        a & b \\
        a' & b'
    \end{bmatrix} \neq 0\) allora nel piano \(x-t\) le due rette \(at + bx + c =
    0\) e \(a't + b'x + c'= 0\) sono incidenti in un punto \({(t_{0}, x_{0})}\).
    Applichiamo quindi il cambiamento di variabili \(u = x - x_{0}\) e \(\tau =
    t -t_{0}\) cioè considero \(u{(\tau)} = x{(\tau + t_{0})}- x_{0}\). Allora
    l'equazione 
    \begin{align*}
        u'{(\tau)} &= x'{(\tau + t_{0})} = g{\left( \frac{a{(\tau + t_{0})} +
        b{(u{(\tau)} + x_{0})} + c}{a'{(\tau + t_{0})} + b'{(u{(\tau)} + x_{0})}
+ c'} \right)} = \\
                   &= g{\left( \frac{a\tau + bu + \overbrace{at_{0} + bx_{0} +
                           c}^{=0}}{a'\tau + b'u +
               \underbrace{a't_{0} + b'x_{0} + c'}_{=0} } \right)} = g{\left(
       \frac{a\tau + bu}{a'\tau + b'u} = g{\left( \frac{a + b{\left(
\frac{u}{\tau} \right)} }{a' + b'{\left( \frac{u}{\tau} \right)} } \right)}
\right)} = \\
    &= \tilde{g}{\left( \frac{u}{\tau} \right)} 
    \end{align*}
    che è del primissimo tipo visto.
\end{itemize}
\subsection{Equazioni del tipo \(F{(y, y')} = 0\) oppure \(F{(x, y')} = 0\) }
In questa sezione e nelle prossime, per via del significato geometrico
sottostante alle equazioni e ai metodi esposti, preferiamo chiamare \(x\) la
``variabile indipendente'' e \(y\) la ``variabile dipendente'', quindi \(y =
y{(x)}\) 
\begin{example}[Brachistocrona]
    (curva di minima discesa) 
    Siano \(p_{1} = {(x_{1}, y_{1})}\) e \(p_{2} = {(x_{2}, y_{2})}\) con
    \(x_{1} < x_{2}\) e \(y_{1} > y_{2}\) (figura~\ref{fig:brachistocrona}).
\begin{figure}[ht]
    \centering
    \incfig[.5]{brachistocrona}
    \caption{brachistocrona}\label{fig:brachistocrona}
\end{figure}

    Qual è la funzione su per la quale il tempo di discesa sotto
    l'azione della sola forza peso è minimo? Sia 
    \[
      \begin{cases}
          x = x{(t)} \\
          y = y{(y)}
      \end{cases}
    \]
    la legge oraria del moto del punto. Supporremo che la curva descritta sia il
    grafico di funzione \(u : [x_{1},x_{2}] \to \mathbb{R}\). Pertanto, per ogni
    \(t\) risulta \(y{(t)} = u{(x{(t)})}\). 

    Se assumiamo che il tempo \(t=0\) corrisponda alla posizione iniziale
    \(p_{1}\), lo spazio percorso fino all'istante \(t\) è
    \[
        s{(t)} = \int_{x_{1}}^{x{(t)}}\sqrt{1 + u'{(x)}^2}dx
    \]
    e la velocità (scalare) è data da
    \begin{equation}\label{eq:v_met1}
        v{(t)} = \sqrt{1 + u'{{(x{(t)})}^2} } x'{(t)}
    \end{equation}
    D'altronde possiamo anche calcolare \(v\) utilizzando la conservazione
    dell'energia: se \(m\) è la massa del punto, \(g\) l'accelerazione di
    gravità e \(v_{0} = v{(0)}\) la velocità iniziale, allora
    \[
        \frac{1}{2} m v_{0}^2 + mgy_{1} = \frac{1}{2} m v{(t)}^2 + mgy{(t)}
    \]
    da cui
    \begin{align*}
        v{(t)}^2 &= v_{0}^2 + 2g(y_{1} - y{(t)}) \\
         &= 2g{(H - u{(x{(t)})})}, \quad \text{ con } H = \frac{v_{0}^2}{2g} +
         y_{1}
    \end{align*}
    Per confronto con la~\eqref{eq:v_met1} otteniamo 
    \[
      x'{(t)} = \frac{\sqrt{2g{{\left( H - {(u \circ x)}{(t)}
      \right)}}}}{\sqrt{1 + u'{(x{(t)})^2}}}
    \]
    Possiamo assumere che \(x{(t)}\) sia invertibile; per l'inversa \(t'{(x)}\)
    risulta
    \[
        t'{(x)} = \frac{1}{x'{(t)}} = \frac{\sqrt{1 + u'{{(x)}^2}}}{\sqrt{2g{(H -
        u{(x)})}}}
    \]
    Il tempo impiegato per percorrere l'arco fra \(p_{1}\) e \(p_{2}\) si
    ottiene ora per integrazione:
    \[
        T{(u)} = \frac{1}{\sqrt{2g}} \int_{x_{1}}^{x_{2}} \frac{\sqrt{1 +
        {u'{(x)}}^2}}{H - u{(x)}} dx
    \]
    Come verrà maggiormente dettagliato in appendice, le \emph{eventuali}
    soluzioni del problema di minimo per il funzionale 
    \[
      T{(u)} = \int_{x_{1}}^{x_{2}} f{(u{(x)}, u'{(x)})} dx \quad \text{  con  } f{(u,
      u')} = \frac{1}{\sqrt{2g}} \frac{\sqrt{1+ {u'{(x)}}^2}}{H - u{(x)}}
    \]
    rendono costante la funzione \(f{(u, u')} - u'f_{u'} {(u, u')}\). Un calcolo
    diretto porta quindi alla condizione
    \begin{equation}\label{eq:brachistocrona_diff}
      {(H - u)}{(1 + u'^2)} = c^2 \quad (\text{\(c^2\) costante})
    \end{equation}
\end{example}
\paragraph{\(F{(y, y')} = 0\)} Prima di procedere nella risoluzione della
brachistocrona, consideriamo il caso generale di un'equazione differenziale del
tipo \(F{(y, y')} = 0\). In particolare sia \(\mathcal{C}\) la curva nel piano
\(y, y'\) di tale equazione. Sia allora
\[
  \mathcal{C} = \begin{cases}
      y = A{(s)} \\
      y' = B{(s)}
  \end{cases}
\]
una rappresentazione parametrica di \(\mathcal{C}\). Cerchiamo allora una
rappresentazione parametrica del grafico \(y = y{(x)}\) di una soluzione di
\(F{(y, y')} =0\) nella forma 
\[
  \begin{cases}
      x = x{(s)} \\
      y = y{(x{(s)})}
  \end{cases}
\]
Poniamo \(y{(s)} = y{(x{(s)})}\) e poiché vale
\[
    \frac{dy}{ds} = y'{(x{(s)})} x'{(s)} \implies A'{(s)} = B{(s)} x'{(s)}
\]
da cui
\begin{equation}\label{eq:diff_Fyyp}
    x'{(s)} = \frac{A'{(s)}}{B{(s)}} \quad x{(s)} = \int \frac{A'(s)}{B(s)} ds
    \implies \text{ soluzione: } \begin{cases}
        x = \int \frac{A'(s)}{B(s)} ds \\
        y = A{(s)}
    \end{cases}
\end{equation}
\setcounter{excounter}{\value{excounter}-1}
\begin{example}[Brachistocrona]
    Tornando all'esempio precedente vogliamo risolvere l'equazione~\eqref{eq:brachistocrona_diff}, ossia
    \[
    F{(y, u')} = {(H - u)}{\left( 1 + {u'}^2 \right)} = c^2 \implies
    \begin{cases}
        H - u = \frac{c^2}{1 + \xi^2} \iff u = H - \frac{c^2}{1 + \xi^2} \\
        u' = \xi
    \end{cases}
    \]
    da cui, operando la sostituzione \(\xi = \tan \frac{s}{2}\) abbiamo
    \[
      \begin{cases}
          u = H - c^2 \cos^2 \frac{s}{2} = H - \frac{c^2}{2} {(1 + \cos s )} &=:
          A{(s)} \\
          u' = \tan \frac{s}{2} &=: B{(s)}
      \end{cases}
    \]
    e ora risolvendo secondo la~\eqref{eq:diff_Fyyp} otteniamo \(\displaystyle
    x{(s)} = \int \frac{A'{(s)}}{B{(s)}} ds = \frac{c^2}{2} \int \frac{\sin
    s}{\tan \frac{s}{2}} = \frac{c^2}{2} 2 \int \frac{\cancel{\sin \frac{s}{2}}
    \cos \frac{s}{2}}{\cancel{\sin \frac{s}{2}} / \cos \frac{s}{2}} ds =
    c^2 \int \cos^2 \frac{s}{2} ds = \frac{c^2}{2} \int {(1 + \cos s)} ds\) e
    quindi una rappresentazione parametrica del grafico della soluzione è
    \[
        \begin{cases}
            x = \frac{c^2}{2} {(s + \sin s)} \\
            y = H - \frac{c^2}{2} {(1 + \cos s)}
        \end{cases}
        \implies 
        \begin{cases}
            x = \frac{c^2}{s} {(\theta + \pi - \sin \theta)} =
            K + r{(\theta - \sin \theta)} \\
            y = H - \frac{c^2}{2} {(1 - \cos \theta)} =
            H - r{(1 - \cos \theta)}
        \end{cases}
    \]
    con \(s = \theta + \pi\), \(\frac{c^2}{2} = r\) e \(K = \frac{c^2}{2} \pi\) 
    che è l'equazione di un arco di cicloide, ossia la curva descritta da un
    punto di una circonferenza lungo la sua rotazione senza slittamento su una
    retta, come in figura~\ref{fig:cicloide}

\begin{figure}[ht]
    \centering
    \incfig{cicloide}
    \caption{La cicloide ha equazione \(x = r{(\theta - \sin \theta)}\) e \(y =
    r{(1 - \cos \theta)}\)}\label{fig:cicloide} \end{figure}
\end{example}

\paragraph{\(F{(x, y')} = 0\)} Questo caso si affronta in modo analogo al
precedente. Sia infatti \(\mathcal{C}\) una curva nel piano \(x, y'\) descritta
da \(F{(x, y')} = 0\) e rappresentata parametricamente da
\[
  \mathcal{C} : \begin{cases}
      x = A{(s)} \\
      y' = B{(s)}
  \end{cases}
\]
allora \(\frac{dy}{ds} = y'{(x{(s)})}x'{(s)}\) e quindi similmente a prima
otteniamo
\[
  \mathcal{C} : \begin{cases}
      x = A{(s)} \\
      y = \int A'{(s)} B{(s)} ds
  \end{cases}
\]
\section{Sistemi lineari}
\subsection{Equazioni differenziali e forme differenziali in due dimensioni} 
Sia \(\Omega \subseteq \mathbb{R}^2 \) aperto, \(f: \Omega \to \mathbb{R}^2\)
una funzione \(C^{1}\) e \(x' = f{(x)}\). Allora se \(f = {(f_{1}, f_{2})}\) e
\(x = {(x_{1}, x_{2})}\) allora
\begin{equation}\label{eq:diff_2}
  x' = f{(x)} \iff \begin{cases}
      x_{1}' = f_{1}{(x_{1}, x_{2})} \\
      x_{2}' = f_{2}{(x_{1}, x_{2})}
    \end{cases}
\end{equation}
Sia ora \(x : J \to \Omega\) una soluzione, \(J = {(a, b)}\) e sia \(\gamma\)
l'orbita corrispondente. Allora \(x{(\cdot )}\) è una rappresentazione
parametrica di \(\gamma\) e possiamo individuare \(\gamma\) mediante una
qualunque altra rappresentazione parametrica. In particolare sia \(\psi :
{(\alpha,\beta)} \to (a, b)\) è \(C^{1}\), biettiva con \(\psi'\) mai nulla e
con inversa \(C_{1}\). Se allora \(u = x \circ \psi\) allora
\[
    u'{(\tau)} = x'{(\psi {(\tau)})}\psi'{(\tau)} =
    f{(x{(\psi{(\tau)})})}\psi'{(\tau)} = f{(u{(\tau)})}\psi'{(\tau)}
\]
allora rinominando \(\psi'{(\tau)} = \lambda{(\tau)}\) abbiamo che \(u\)
soddisfa la proprietà
\begin{definition}{\(u' \parallel f{(u)}\) }
    Diciamo che \(u\) soddisfa la proprietà \(u' \parallel f{(u)}\) se esiste una
    funzione \(\lambda : J \to \mathbb{R}\) continua e mai nulla tale che \[u'{(\tau)} = f{(u{(\tau)})}\lambda{(\tau)}\]
\end{definition}
Viceversa, se \(u : (\alpha, \beta) \to \Omega\) soddisfa \(u' \parallel
f{(u)}\) allora è la riparametrizzazione di una soluzione di \(x' = f{(x)}\).
Infatti sia \(\psi\) una primitiva di \(\lambda\), ossia \(\psi' = \lambda\).
Definiamo \(x = u \circ \psi^{-1}\) che è soluzione, infatti\footnote{dirò per
comodità che \(h = fg = f \cdot g\) quando \(h{(t)} = f{(t)}g{(t)}\)}
\[
x' = {(u'\circ \psi^{-1})}\cdot {\psi^{-1}}' = {(\lambda \circ
\psi^{-1})}{(f \circ u \circ \psi^{-1})} \frac{1}{{(\psi' \circ
\psi^{-1})}} = f \circ x = f{(x)}
\]
Quindi la determinazione delle orbite si riduce all'individuazione di funzioni
\(u\) soddisfacenti \(u'\parallel f{(u)}\). Da qui in poi useremo la notazione
\(x{(\cdot )}\) anziché \(u{(\cdot )}\).
\begin{proposition}\label{prop:41}
    Sia \(x: J \to \Omega\) una curva \emph{regolare} su cui \(f\) non si
    annulla. Allora sono equivalenti:
\begin{enumerate}[label = \roman*)]
    \item \(\exists \lambda \in C^{0}{(J)}\) mai nulla tale che \(x'=
        \lambda{(f{(x)})}\) 
    \item \(\det \begin{bmatrix}
        x_{1}'{(t)} & x_{2}'{(t)} \\
        f_{1}{(x{(t)})} & f_{2}{(x{(t)})}
    \end{bmatrix} = 0\) per ogni \(t \in J\) 
\end{enumerate}
\end{proposition}
\begin{proof}
    L'implicazione \({(i)} \implies {(ii)}\) è ovvia. Se \(x'= \lambda f\)
    allora
    \begin{equation}\label{eq:prop41}
\begin{pmatrix}
        x_{1}' \\
        x_{2}'
    \end{pmatrix} = \lambda \begin{pmatrix}
        f_{1}\circ x \\
        f_{2}\circ x
    \end{pmatrix}
    \end{equation}

    Per \({(ii)} \implies {(i)}\) abbiamo per ipotesi che la seconda riga non è
    mai nulla (\(f\) non si annulla) e la prima non è mai nulla (\(x\) è
    regolare). Necessariamente quindi vale la~\eqref{eq:prop41} con un
    \(\lambda{(t)}\) mai nullo. Inoltre \(\forall t \in J\) almeno una fra
    \(f_{1}\) e \(f_{2}\) è non nulla, e quindi \(\lambda{(t)} =
    \frac{x_{1}'{(t)}}{f_{1}{(x{(t)})}}\) oppure l'altra localmente, e quindi è
    continua.
\end{proof}

La condizione \({(ii)}\) della proposizione~\ref{prop:41} si può scrivere come 
\[
  f_{2}{(x{(t)})}x_{1}'{(t)} - f_{1}{(x{(t)})}x_{2}'{(t)} = 0
\]
ossia posto
\begin{equation}\label{eq:diff_associata}
  \omega{(x_{1},x_{2})} = f_{2}{(x_{1}, x_{2})}dx_{1} - f_{1}{(x_{1},
  x_{2})}dx_{2}
\end{equation}
l'uguaglianza diventa semplicemente \(\langle \omega{(x{(t)})}, x'{(t)} \rangle
= 0\) 

In generale data una forma differenziale \(\omega{(x_{1},x_{2})} = A{(x_{1},
x_{2})}dx_{1} + B{(x_{1}, x_{2})}dx_{2}\) su \(\Omega\) si pone
\begin{definition}{Curva soluzione}
    Una curva regolare \(x:J\to \Omega\) si dice \textbf{curva soluzione}
    dell'equazione \(\omega{(x_{1}, x_{2})} = 0\) se per ogni \(t \in J\)
    soddisfa
    \[
        A{(x{(t)})}x'{(t)} + B{(x{(t)})}y'{(t)} = 0 \,\,\big(= \langle \omega{(x{(t)})},
        x'{(t)}\rangle\big)
    \]
\end{definition}
Il problema della determinazione delle orbite di~\eqref{eq:diff_2} equivale ad
individuare le curve soluzione di~\eqref{eq:diff_associata}.
\begin{remark}[Formalmente]
    La notazione è bella, ed ha una sua motivazione, per cui essendo una bella
    notazione si ottengono risultati sensati:
    \[
      \begin{cases}
          \frac{dx_{1}}{dt} = f_{1}{(x_{1}, x_{2})} \\
          \frac{dx_{2}}{dt} = f_{2}{(x_{1}, x_{2})}
      \end{cases}
      \implies \frac{dx_{1}}{dx_{2}} = \frac{f_{1}}{f_{2}} \implies f_{2}dx_{1} -
      f_{1}dx_{2} = 0
    \]
\end{remark}
Sinora abbiamo osservato solo sistemi autonomi con \(N = 2\). Possiamo anche
considerare problemi \(N=1\) non autonomi, ossia \(x' = f{(t, x)}\), riducendoli
ad un sistema autonomo in \(N = 2\) con
\[
  \begin{cases}
      x_{1} := t \\
      x_{2} := x
  \end{cases}
    \implies  
\begin{cases}
    x_{1}' = 1 \\
    x_{2}' = f{(x_{1}, x_{2})}
\end{cases}
\]
le cui orbite sono date da \(f{(x_{1}, x_{2})}dx_{1} - dx_{2} = 0\), ossia
\[
  f{(t, x)}dt - dx = 0 \quad \text{ che può essere trovato formalmente da }
  {\frac{dx}{dt} = f}
\]
Un caso rilevante è quello in cui~\eqref{eq:diff_associata} è esatta, ossia
esiste una funzione \(H \in C^{1}{(\Omega)}\) tale che \(dH = \omega\) 
\begin{proposition}
    Sia \(\omega = dH\). Allora
\begin{itemize}[label = --]
    \item su ogni curva soluzione la funzione \(H\) è costante
    \item una curva regolare contenuta in un insieme di livello di \(H\) è una
        curva soluzione
\end{itemize}
\end{proposition}
\begin{proof}
    Sia \(x : J \to \Omega\) una curva \(C^{1}\). Abbiamo che
    \[
      \frac{d}{dt} H {(x{(t)})} = \frac{\partial H}{\partial x_{1}} x_{1}'{(t)}
      + \frac{\partial H}{\partial x_{2}} x_{2}'{(t)} = \langle
      \omega{(x{(t)})}, x'{(t)} \rangle
    \]
    dove il primo termine è nullo se \(H\) è costante sul supporto di \(H\),
    ossia \(x\) è contenuta in un insieme di livello di \(H\); l'ultimo termine
    invece è nullo quando \(x\) è curva soluzione.
\end{proof}
\begin{eser}
    Si studino le curve soluzione del problema del pendolo
\[
    \ddot{\theta} + \omega^2  \sin\theta = 0   
\]
    considerando le curve soluzione sul piano \((\theta, \dot{\theta})\) 
\end{eser}
\begin{example}[Lotka-Volterra]
    consideriamo \(x_{1}, x_{2} > 0\) e il sistema
\[
    \begin{cases}
        x_{1}' = x_{1}{(\alpha - \beta x_{2})} \\
        x_{2}' = x_{2}{(-\gamma + \delta x_{1})}
    \end{cases}
\]
    che dà origine alla forma differenziale
\[
    \omega = x_{2} {(-\gamma + \delta x_{1})} dx_{1} - x_{1}{(\alpha - \beta
    x_{2})}dx_{2} = 0
\]
    sfortunatamente non è esatta, infatti non è chiusa
\[
    \frac{\partial A}{\partial x_{2}} = -\gamma + \delta x \neq -\alpha + \beta
    x_{2} = \frac{\partial B}{\partial x_{2}}
\]
    ma possiamo cercare un fattore integrante \(\mu{(x_{1}, x_{2})}\) \emph{mai
    nullo} tale che \(\mu \omega\) sia esatta. L'idea è che se esiste allora
    \(\omega = 0 \iff \mu \omega = 0\). L'equazione diventa
\[
    \mu{(x_{1}, x_{2})}x_{2} {(-\gamma + \delta x_{1})}dx_{1} - \mu{(x_{1},
    x_{2})}x_{1}{(\alpha - \beta x_{2})}dx_{2} = 0
\]
    e vogliamo che
\[
    \frac{\partial }{\partial x_{2}} {\left( \mu{(x_{1}, x_{2})} x_{2}{(-\gamma
    + \delta x_{1})} \right)} = \frac{\partial }{\partial x_{1}} {\left(
\mu{(x_{1}, x_{2})} x_{1}{(\alpha - \beta x_{2})} \right)}
\]
    e cerchiamo \(\mu\) nella forma \(\mu{(x_{1}, x_{2})} = \varphi {(x_{1})}
    \psi {(x_{2})}\). La precedente diventa quindi
\begin{align*}
    \varphi {(x_{1})} \psi'{(x_{2})} x_{2}{(-\gamma + \delta x_{1})} + \varphi
    {(x_{1})}\psi {(x_{2})} {(- \gamma + \delta x_{1})} = \\
    = \varphi'{(x_{1})}\psi {(x_{2})} x_{1}{(\alpha - \beta x_{2})} + \varphi
    {(x_{1})}\psi {(x_{2})} {(-\alpha + \beta x_{2})}
\end{align*}
    cioè
\[
    \varphi {(x_{1})}{(-\gamma + \delta x_{1})} \underbrace{\left( \psi'{(x_{2})}x_{2} +
    \psi {(x_{2})} \right)}_{\overset{\text{set}}{=}0}  = \psi {(x_{2})} {(\alpha - \beta x_{2})}
    \underbrace{\left(
\varphi'{(x_{1})} x_{1} + \varphi {(x_{1})} \right)}_{ \overset{\text{set}}{=}0} 
\]
    e come \(\varphi \) e \(\psi\) possiamo considerare una soluzione di
    \begin{align*}
        u'{(x)} x + u{(x)} &= 0 \\
        \frac{u'}{u} &= -\frac{1}{x} \\
        \log |u| &= -\log x + c \\
        u{(x)} &= \frac{c}{x}
    \end{align*}
    e quindi \(\varphi {(x_{1})} = \frac{1}{x_{1}}\) e \(\psi{(x_{2})} =
    \frac{1}{x_{2}}\) da cui \(\mu{(x_{1}, x_{2})} = \frac{1}{x_{1} x_{2}}\). La
    nostra forma differenziale diventa
\[
    \tilde{\omega} = {\left( - \frac{\gamma}{x_{1}} + \delta \right)} dx_{1} - {\left(
    \frac{\alpha}{x_{2}} - \beta \right)} dx_{2} = 0
\]
    e una possibile \(H{(x_{1}, x_{2})}\) tale che \(dH = \tilde{\omega} \) è 
\[
    H{(x_{1}, x_{2})} = -\gamma \log x_{1} + \delta x_{1} - \alpha \log x_{2} +
    \beta x_{2} \quad \text{ è costante}
\]
    quindi ora se rappresentiamo le curve nel piano \((x_{1}, x_{2})\) otteniamo
    la figura~\ref{fig:lotka-volterra}
    \begin{figure}[ht]
        \centering
    \begin{tikzpicture}
    \begin{axis}[
        axis lines=middle,
        xmin=0, xmax=5,
        ymin=0, ymax=5,
        enlargelimits,
        view={0}{90},
        xlabel=\(x_{1}\),
        ylabel=\(x_{2}\),
        ]
        \addplot3 [
        contour gnuplot={levels={1,1.1,1.25,1.5,2,3}},
        thick,
        samples=100,
        ] {- 2 *ln(x) + x - ln(y) + y / 2};
    \end{axis}
    \end{tikzpicture}
    \caption{Le curve soluzione del sistema di
    Lotka-Volterra con \(\gamma = 2, \delta = \alpha = 1\) e \(\beta =
\frac{1}{2}\), i valori assunti da \(H\) sono indicati}\label{fig:lotka-volterra} 
    \end{figure}
    
\end{example}
\begin{example}
    Consideriamo il problema \(\displaystyle x' = \frac{t + x}{t-x}\).
    volendo calcolare le curve soluzione nel piano \((t, x)\) studiamo la forma
    differenziale
\[
    \omega = {(t - x)}dx - {(t + x)}dx = 0
\]
    ossia
    \begin{equation}\label{eq:ex34}
        {(x_{1} + x_{2})}dx_{1} - {(x_{1} - x_{2})}dx_{2} = 0
    \end{equation}
    non è esatta e non si riesce (facilmente?) a trovare un fattore integrante.
    Tuttavia possiamo studiarlo in coordinate polari. In particolare poniamo
\[
    \begin{cases}
        x_{1} = x_{1}{(t)} = \rho{(t)} \cos \theta{(t)} \\
        x_{2} = x_{2}{(t)} = \rho{(t)} \sin\theta{(t)}
    \end{cases}
\]
    La~\eqref{eq:ex34} diventa
\[
    \cancel{\rho}{(\cos \theta + \sin \theta)} {(\rho' \cos \theta - \rho
    \theta'\sin\theta)} - \cancel{\rho}{(\cos \theta - \sin \theta)} {(\rho' \sin \theta
    + \rho \theta' \cos \theta)} = 0
\]
    svolgendo i calcoli abbiamo 
\[
    \rho' - \rho \theta' = 0 \implies d\rho - \rho d\theta = 0  \implies
    \frac{1}{\rho} d\rho - d\theta = 0
\]
    e quindi \(H{(\rho, \theta)} = \log \rho - \theta\) è costante e quindi le
    curve espresse in forma polare hanno equazione
\[
    \log \rho = \theta + c \implies \rho = e^{\theta + c} = C e^{\theta} \quad
    C > 0
\]
\end{example}

\subsection{Sistemi lineari}
Consideriamo il sistema lineare
\begin{equation}\label{eq:sist_lin}
    x' = A{(t)}x + b{(t)} \quad
    A \in C^{0}{(I, M^{N \times N}{(\mathbb{R})})} \quad b \in C^{0}{(I,
    \mathbb{R}^{N})}
\end{equation}
dove \(I \subseteq \mathbb{R} \) è un intervallo aperto.
Se \(N = 2\)  abbiamo
\begin{equation}\label{eq:sist_lin_2}
    \begin{cases}
    x'_1 = a_{11}{(t)}x_{1} + a_{12}{(t)}x_{2} + b_{1}{(t)} \\
    x_{2}' = a_{21}{(t)}x_{1} + a_{22}{(t)}x_{2} + b_{2}{(t)}
    \end{cases}
\end{equation}
Allora abbiamo \(f{(t, x)} = A{(t)}x + b{(t)}\) per cui per crescita
sottolineare abbiamo esistenza globale, e quindi \(I\) è intervallo massimale.

In aggiunta se \(A, b \in C^{k}\) allora \(x{(\cdot )} \in C^{k+1}{(I,
\mathbb{R}^{N})}\). 

Sia ora \(L: C^{1}{(I, \mathbb{R}^{N})} \to C^{0}{(I, \mathbb{R}^{N})}\)
definito come \(x \mapsto x' - A{(t)}x\). L'equazione è
\begin{equation}
    Lx = b
\end{equation}
e \(L\) è lineare, per cui
\begin{proposition}
    Sia \(\overline{x}\) una soluzione di~\eqref{eq:sist_lin}. Allora tutte e
    sole le soluzioni di tale equazione si ottengono con \(x = x_{0} +
    \overline{x}\) al variare di \(x_{0}\) fra le soluzioni di 
    \begin{equation}\label{eq:sist_lin_omog}
        x' = A{(t)}x
    \end{equation}
    che è l'equazione omogenea associata
\end{proposition}
\begin{proof}
    \(L^{-1}{(b)} = \overline{x} + L^{-1}{(0)}\) 
\end{proof}

\paragraph{Equazione omogenea} Consideriamo ora
l'equazione~\eqref{eq:sist_lin_omog} omogenea associata a
un sistema lineare~\eqref{eq:sist_lin}. Sia \(V = L^{-1}{(0)}\) lo spazio delle
soluzioni. Allora se \(x{(\cdot , t_{0}, x_{0})}\) è la soluzione del problema
di Cauchy con dato iniziale \(x{(t_{0})} = x_{0}\).

\begin{proposition}\label{prop:44}
    Fissiamo \(t_{0} \in I\) e sia 
    \begin{align*}
        \varphi^{t_{0}}: \mathbb{R}^{N} &\longrightarrow V \\
        \xi &\longmapsto \varphi^{t_{0}}(\xi) = x{(\cdot , t_{0}, \xi)}
    \end{align*}
    Allora \(\varphi ^{t_{0}}\) è un isomorfismo di spazi vettoriali
\end{proposition}
\begin{proof}
    Siano \(\xi_{1}, \xi_{2} \in \mathbb{R}^{N}\) e \(\alpha, \beta \in
    \mathbb{R}\), inoltre sia \(u_{1} = \varphi ^{t_{0}}{(\xi_{1})}\) e \(u_{2}
    = \varphi ^{t_{0}}{(\xi_{2})}\). Allora chiamato
    \[
      \xi = \alpha \xi_{1} + \beta\xi_{2}
    \]
    vogliamo mostrare che \(\varphi ^{t_{0}}{(\xi)} = \alpha u_{1} + \beta
    u_{2}\). La funzione \(u := \alpha u_{1} + \beta u_{2}\) è soluzione e
    inoltre
    \[
      u{(t_{0})} = \alpha u_{1}{(t_{0})} + \beta u_{2}{(t_{0})} = \alpha
      \xi_{1} + \beta \xi_{2} = \xi
    \]
    Per unicità segue che \(u{(\cdot )} = x{(\cdot , t_{0}, \xi)} = \varphi
    ^{t_{0}}{(\xi)}\) 

    Quindi \(\varphi ^{t_{0}}\) è un omomorfismo. Del resto
    \[
      \varphi ^{t_{0}}{(\xi)} = 0 \implies \xi = x{(t_{0}, t_{0}, \xi)} =
      \varphi ^{t_{0}}{(\xi)}|_{t = t_{0}} = 0
    \]
    quindi \(\varphi \) è iniettiva.

    Infine data \(u \in V\)  risulta \(u =
    \varphi ^{t_{0}}{(\xi)}\) con \(\xi = u{(t_{0})}\) e quindi \(\varphi \) è
    suriettiva
\end{proof}
Ne consegue direttamente che \(\dim V = N\) e anche il seguente
\begin{corollary}
    Sia \(t_{0} \in I\) fissato, siano \(x^{{(1)}}, \dots, x^{{(N)}}\) elementi
    di \(V\). Allora \(x^{{(1)}}, \dots, x^{{(N)}}\) sono linearmente
    indipendenti in \(V\) se e solo se tali sono i vettori di \(\mathbb{R}^{N}\)
    \(x^{{(1)}}{(t_{0})}, \dots, x^{{(N)}}{(t_{0})}\) 
\end{corollary}

\begin{definition}{Wronskiana}
    Dati \(N\) elementi di \(V\) (soluzioni di~\eqref{eq:sist_lin_omog})
    \[
      x^{{(1)}}, \dots, x^{{(N)}}
    \] diciamo matrice \textbf{Wronskiana} di tali soluzioni la matrice che ha
    come colonne
    \[
        \mathbf{X}{(t)} = {(x^{{(1)}}{(t)} | x^{{(2)}}{(t)} | \dots |
        x^{{(N)}}{(t)})}
    \]
    Il determinante
    \[
      W^{t} = \det \mathbf{X}{(t)}
    \]
    è il (determinante) \textbf{wronskiano}
\end{definition}

Quindi, fissato \(t_{0} \in I\), le soluzioni \(x^{{(1)}}, \dots, x^{{(N)}}\)
sono linearmente indipendenti se e solo se \(\det \mathbf{X} {(t_{0})} = 0\). In
tal caso abbiamo che \(\forall t \in I\) risulta \(\det \mathbf{X}{(t)} = 0\)
\begin{example}
    Consideriamo il sistema
    \[
      \begin{cases}
          x_{1}' = 2x_{1} + x_{2} \\
          x_{2}' = -4x_{1} - 3x_{2}
      \end{cases}
      \quad
      A = \begin{pmatrix}
          2 & 1 \\
          -4 & -3
      \end{pmatrix}
    \]
    allora \(\dim V = 2\) e una base di \(V\) è data da
    \[
      x^{{(1)}}{(t)} = e^{t} \begin{pmatrix}
          1 \\
          -1
      \end{pmatrix} \quad x^{( 2 )}{(t)} = e^{-2t} \begin{pmatrix}
          1 \\
          -4
      \end{pmatrix}
    \]
    Verifichiamo che sono soluzioni:
    \begin{align*}
        {\left(x^{{(1)}}_1\right)}' = e^{t} = 2e^{t} - e^{t} = 2x^{{(1)}}_{1} +
        x^{{(1)}}_{2} \\
    {\left(x_{2}^{{(1)}}\right)}' = -e^{t} = -4e^{t} -(- 3e^{t}) = -4x^{{(1)}}_{1} -
        3x^{{(1)}}_2
    \end{align*}
    e analogamente per \(x^{(2)}\). La matrice wronskiana è
    \[
      \mathbf{X}{(t)} = \begin{pmatrix}
          e^{t} & e^{-2t} \\
          -e^{t} & -4e^{-2t}
      \end{pmatrix}
    \]
    che ha determinante \(\det \mathbf{X} = -4e^{-t} + e^{-t} = -3 e^{-t} \neq 0\) 
\end{example}
\begin{theorem}[Liouville]\label{thm:liouville_wronskiano}
    Siano \(x^{{(1)}}, \dots, x^{{(N)}}\) soluzioni. Sia \(W{(t)} = \det
    \mathbf{X} {(t)}\). Allora \(W\) risolve 
    \[
        W'{(t)} = {(\text{tr} A{(t)})} W{(t)}
    \]
    cioè 
    \[
        W{(t)} = W{(t_{0})} e^{\int_{t_{0}}^{t} \text{tr} A{(s)} ds} \quad t, t_{0}
        \in I
    \]
\end{theorem}
Ciò conferma che \(W{(t)} \equiv 0\) oppure \(W^{t}\) non si annulla mai.

\paragraph{Matrice risolvente} Prendiamo le soluzioni con dati iniziali \(e_{1},
e_{2}, \dots, e_N\) cioè per ogni \(\tau \in I\) e \(i = 1, \dots, N\) sia 
\[
  u^{{(i)}}{(\cdot, \tau)} = x{(\cdot , \tau, e_{i})}
\]
Allora la matrice \(\mathbf{X} \) wronskiana corrispondente agli \(u^{{(i)}}\) è
\[
  \mathbf{X} {(\tau)} = {\left( u^{{(1)}}{(\tau, tau)} | \dots | u^{N}{(\tau,
  tau)}\right)} = {\left( e_{1}, e_{2}, \dots, e_N \right)} = I
\]
sono linearmente indipendenti
\begin{definition}{Matrice risolvente}
    Diciamo \textbf{matrice risolvente} dell'equazione~\eqref{eq:sist_lin_omog}
    la matrice (funzione di \(t\) e \(\tau\) )
    \[
      R{(t, \tau)} = {\left( u^{{(1)}}{(t, \tau)} | \dots | u^{{(N)}}{(t, \tau)} \right)} 
    \]
\end{definition}
Allora la soluzione di (\(t \in I\) e \(\xi \in \mathbb{R}^{N}\))
\[
  \begin{cases}
      x' = A{(t)}x \\
      x{(\tau)} = \xi
  \end{cases}
\]
è data da
\[
    x{(t)} = R{(t, \tau)} \xi = \xi_{1} u^{{(1)}}{(t, \tau)} +~\dots + \xi_{N}
    u^{N}{( t, \tau)}
\]
così che \(x{(\tau)} = R{(\tau, \tau)}\xi = \mathbf{X} {(\tau)} \xi= I\xi =
\xi\). Enunciato in altra forma: se \(x{(\cdot )}\) è soluzione
di~\eqref{eq:sist_lin_omog} allora per ogni \(t, \tau \in I\) 
\[
    x{(t)} = R{(t, \tau)} x{(\tau)}
\]
Da qui scende che se \(\mathbf{X}{(\cdot )}\) è la matrice wronskiana di \(N\)
soluzioni del tipo \(x^{{(i)}}\) per \(i = 1, \dots, N\) allora
\[
    x^{{(i)}}{(t)} = R{(t, \tau)} x^{{(i)}}{(\tau)} \quad i = 1, \dots, N
\]
quindi
\[
    \mathbf{X} {(t)} = R{(t, \tau)} \mathbf{X} {(\tau)}
\]
Se in particolare le \(x^{{(i)}}\) sono linearmente indipendenti allora
\[
    R{(t, \tau)} = \mathbf{X} {(t)} \mathbf{X} {(\tau)}^{-1}
\]
\addtocounter{excounter}{-1}
\begin{example}[Nell'esempio precedente]
    \begin{align*}
        \mathbf{X}{(t)}^{-1} &= -\frac{1}{3}e^{t} \begin{pmatrix}
          -4e^{-2t} & e^{t} \\
          -e^{-2t} & e^{t}
      \end{pmatrix}^{T} = -\frac{1}{3}e^{t} \begin{pmatrix}
          -4e^{-2t} & -e^{-2t} \\
          e^{t} & e^{t}
          \end{pmatrix} = \\ &= -\frac{1}{3} \begin{pmatrix}
          -4e^{-t} & -e^{-t} \\
          e^{2t} & e^{2t}
      \end{pmatrix}
    \end{align*}
    e dunque
    \begin{align*}
        R{(t, \tau)} &= -\frac{1}{3} \begin{pmatrix}
          e^{t} & e^{-2t} \\
          -e^{t} & -4e^{-2t}
          \end{pmatrix} \begin{pmatrix}
          -4e^{-\tau} & -e^{-\tau} \\
          e^{2\tau} & e^{2\tau}
          \end{pmatrix} = \\ &= -\frac{1}{3} \begin{pmatrix}
          -4e^{t-\tau}+e^{-2{(t-\tau)}} & -e^{t-\tau} + e^{-2{(t-\tau)}} \\
          4e^{t-\tau} - 4e^{-2{(t-\tau)}} & e^{t-\tau} - 4e^{-2{(t-\tau)}}
      \end{pmatrix}
    \end{align*}
    e in effetti abbiamo che
    \[
      R{(\tau, \tau)} = -\frac{1}{3} \begin{pmatrix}
          -3 & 0 \\
          0 & -3
      \end{pmatrix} = I
    \]
    \begin{remark}
        In questo caso \(R{(t, \tau)}\) è funzione di \(t - \tau\), in effetti
        in generale se \(A\) non dipende da \(t\)  (sistema autonomo) abbiamo
        che \(u^{{(i)}}{(t)} = x{(t, \tau, e_{i})} = x{(t-\tau, 0, e_{i})}\) e
        quindi
        \(R{(t, \tau)} = R{(t-\tau, 0)}\) ed è dunque sufficiente conoscere
        \(R{(t, 0)}\) 
    \end{remark}
\end{example}

Sappiamo ora che dato un sistema lineare~\eqref{eq:sist_lin}, noi consideriamo
il sistema omogeneo associato~\eqref{eq:sist_lin_omog} e cerchiamo le soluzioni
calcolando \(R{(t, \tau)}\), oppure \(R{(t, 0)}\) nel caso di \(A\) non
dipendente da \(t\). Infine cerchiamo una soluzione particolare
\(\overline{x}{(\cdot )}\). Come possiamo fare per tale scopo?

\paragraph{Metodo di variazione delle costanti}
\begin{proposition}
    La funzione
    \[
        \overline{x}{(t)} = \int_{t_{0}}^{t} R{(t, s)}b{(s)}\,ds
  \]
  è soluzione dell'equazione~\eqref{eq:sist_lin} 
\end{proposition}
\begin{proof}
Supponiamo di conoscere una \(N\)-upla di soluzioni linearmente indipendenti
dell'omogenea~\eqref{eq:sist_lin_omog} \(x^{{(1)}}, \dots, x^{{(N)}}\). Allora
cerchiamo \(\overline{x}{(\cdot )}\) della forma
\[
  \overline{x}{(t)} = \mathbf{X} {(t)}\xi{(t)}
\]
Si ha \(\overline{x}'{(t)} = \mathbf{X}'{(t)}\xi {(t)} + \mathbf{X} {(t)}
\xi'{(t)}\) e quindi \(\overline{x}\) è soluzione se e solo se
\begin{align*}
    \mathbf{X}'\xi + \mathbf{X} \xi' &= A{(\mathbf{X} \xi)} + b \\
    \cancel{A\mathbf{X} \xi} + \mathbf{X} \xi' &= \cancel{A\mathbf{X} \xi}+ b \\
    \implies \mathbf{X} \xi' &= b \iff \xi' = \mathbf{X}^{-1} b
\end{align*}
dunque
\(\xi\) è primitiva di \(\mathbf{X}^{-1}b\), ossia 
\[
    \xi{(t)} = \int \mathbf{X}^{-1}{(t)} b{(t)} dt \text{ ad esempio } \xi{(t)} =
    \int_{t_{0}}^{t} \mathbf{X}^{-1}{(s)}b{(s)}ds
\]
Allora otteniamo
\[
    \overline{x}{(t)} = \mathbf{X} \int_{t_{0}}^{t} \mathbf{X}^{-1}{(s)}b{(s)}ds
    = \int_{t_{0}}^{t} R{(t, s)}b{(s)}ds
\]
\end{proof}

\begin{example}[Esempio precedente, plus] 
    Consideriamo il sistema
    \begin{equation}\label{eq:ex44}
      \begin{cases}
          x_{1}' = 2x_{1} + x_{2} &- 2t\\
          x_{2}' = -4x_{1} - 3x_{2} &+ 4t + 3
      \end{cases}
    \end{equation}
    e abbiamo
    \[
      \mathbf{X}^{-1} {(t)} = -\frac{1}{3} \begin{pmatrix}
          -4e^{-t} & -e^{-t} \\
          e^{2t} & e^{2t}
      \end{pmatrix}
      \quad 
      b{(t)} = \begin{pmatrix}
          -2t \\
          4t + 3
      \end{pmatrix}
    \]
    da cui
    \[
      \mathbf{X}^{-1}{(t)} b{(t)} = -\frac{1}{3} \begin{pmatrix}
          8te^{-t}-{(4t+3)}e^{-t} \\
          -2te^{2t} + {(4t+3)}e^{2t}
      \end{pmatrix}
      = -\frac{1}{3}
      \begin{pmatrix}
          4te^{-t}-3e^{-3}  \\
          2te^{2t}+3e^{2t}
      \end{pmatrix}
    \]
    da cui
    \[
        \xi {(t)} = \int_{t_{0}}^{t} \mathbf{X} {(t)} b{(t)} dt = -\frac{1}{3}
        \begin{pmatrix}
            {(-4t-1)}e^{-t} \\
            {(t+1)}e^{2t}
        \end{pmatrix}
    \]
    infine
    \[
      \overline{x} = \mathbf{X} {(t)}\xi {(t)} = \begin{pmatrix}
          t \\
          1
      \end{pmatrix}
    \] che si può verificare velocemente essere effettivamente soluzione
    di~\eqref{eq:ex44}
    
\end{example}

\paragraph{ Sistemi omogenei autonomi } Come detto prima, nel caso di sistemi
autonomi \(x' = Ax\) con \(A \in M^{N \times N}{(\mathbb{R})}\) sappiamo che
\(R{(t, \tau)} = R{(t-\tau, 0)}\) e dunque è sufficiente calcolare \(R{(t, 0)}\)
per \(t \in \mathbb{R}\).

Le colonne di \(\mathbf{X} {(t)}\) sono soluzioni di \(x' = Ax\) e inoltre
\(\mathbf{X} {(0)} = I\) identità, ne consegue che vogliamo risolvere il
problema di Cauchy
\begin{equation}\label{eq:cauchy_autonomo_omoglin}
    \begin{cases}
        \mathbf{X}'{(t)} = A\mathbf{X} {(t)} \\
        \mathbf{X} {(0)} = I 
    \end{cases}
    \text{ o equivalentemente }
    \mathbf{X} {(t)} = I + \int_{0}^{t} A\mathbf{X} {(s)}\,ds
\end{equation}
In analogia con la dimostrazione del teorema del teorema di esistenza e unicità
introduciamo \(T : C^{0} \to C^{0}\) definito come
\[
    (T\mathbf{X}){(t)} = I + \int_{0}^{t} A\mathbf{X} {(s)}\,ds \quad \mathbf{X}
    \in C^{0}{(\mathbb{R}, M^{N \times N}{(\mathbb{R})})}
\]
e ne cerchiamo i punti fissi. Definiamo ora la successione
\begin{align*}
    \mathbf{X}_0{(t)} &\equiv I \\
    \mathbf{X}_1 &= T\mathbf{X}_0 = I = tA \\
    \mathbf{X}_2 &= T\mathbf{X}_1 = I + tA + \frac{1}{2}t^2A^2 \\
    \vdots \\
    \mathbf{X}_{m+1} &= Tx_{m} = I + A \int_{0}^{t} X_{m} {(s)}\,ds = \\ &= I + tA +
    \frac{1}{2}t^2 A^2 + \frac{1}{3!}t^3 A^3 +~\dots + \frac{1}{m!}t^m A^m
\end{align*}
Il problema è la convergenza di tale successione. È naturale quindi ora
pensare che la soluzione sia una sorta di \(e^{tA}\), ma è ben definita?
% Converge uniformemente? (Saltare a pagina~\pagref{ritorniamo_a_noi_dopo_exp_matr})
% TODO ERR

\paragraph{Esponenziale di una matrice} Sia \(A \in M^{N \times
N}{(\mathbb{K})}\), con \(\mathbb{K} = \mathbb{R}, \mathbb{C}\). Prendiamo 
\[
    \|A\| \left\{ |Ax| : x \in \mathbb{K}^{N}, |x| \le 1 \right\} 
\]
e l'operatore lineare \(T\) associato alla matrice \(A\). Allora
\begin{itemize}[label = --]
    \item \(|Ax| \le \|A\||x|\) per ogni \(x \in \mathbb{K}^{N}\)
    \item \(\|AB\| \le \|A\|\|B\|\) infatti \(|ABx| \le |A\cdot Bx| \le
        \|A\||Bx| \le \|A\|\|B\||x|\), basta ora osservare che prendiamo per la
        norma \(|x| \le 1\).
    \item \(\|A^{k}\| \le \|A\|^{k}\) 
\end{itemize}

Se \({(M_k)}_k\) è una successione di matrici, la convergenza è quella usuale in
\(\mathbb{K}^{N \times N}\). Consideriamo ora una serie in \(M^{N \times N}{(\mathbb{K})}\) 
\[
  \sum_{k=0}^{\infty} A_{k} 
\] allora la serie converge se converge la successione delle somme parziali, e
converge assolutamente se converge la serie \(\sum_{k=0}^{\infty} \|A_{k}\|\).
Vale che convergenza assoluta implica convergenza.

\begin{proposition}
    Siano \(\sum_{j=1}^{\infty} A_{j} \) e \(\sum_{k=0}^{\infty} B_{k} \) serie
    in \(M^{N \times N}{(\mathbb{K})}\). Sia inoltre
    \[
      \sum_{k=0}^{\infty} C_{k} \, , \quad C_{k} = \sum_{j=0}^{\infty}
      A_{j}B_{k-j}   
    \]
    (serie prodotto). Se le serie date sono assolutamente convergenti, tale è la
    serie prodotto, e vale
    \[
      \sum_{k=0}^{\infty} C_{k} = {\left( \sum_{j=0}^{\infty} A_{j}  \right)}
      \cdot {\left( \sum_{k=0}^{\infty} B_{k}  \right)}  
    \]
\end{proposition}
\begin{proof}
    \begin{equation*}
        \|C_{k}\| \le \sum_{j=0}^{k} \|A_{j}B_{k-j} \| \le \sum_{j=0}^{k}
        \|A_{j}\|\|B_{k-j} \| =: \sum_{j=0}^{k} \alpha_j \beta_{k-j}  
    \end{equation*}
    dove l'ultimo è il termine generale della serie prodotto \({\left( \sum
    \alpha_{j} \right)} {\left( \sum \beta_{k} \right)}  \) che è convergente
    per ipotesi. Per confronto concludiamo
    \[
        \sum_{k=0}^{\infty} \|C_{k}\| < +\infty 
    \]
    Calcoliamo ora 
    \[
      \lim_{m \to \infty} \sum_{k=0}^{2m}C_{k}
    \]
    e si ha 
    \begin{align*}
        \sum_{k=0}^{2m} C_{k} &= \sum_{k=0}^{2m} \sum_{j+h=k} A_{j} B_h \\
                              &= \sum_{j=0}^{m} \sum_{k=0}^{m} A_{j}B_{k} +
                              R^{1}_m + R^{2}_m 
    \end{align*}
    con
    \[
      R^{1}_m = \sum_{j=m+1}^{2m} \sum_{h=0}^{2m-j} A_{j}B_h \quad R^2_m =
      \sum_{h=m+1}^{2m} \sum_{j=0}^{2m - h} A_{j} B_h 
    \]
    Risulta dunque 
    \[
      \sum_{j=0}^{m} \sum_{h=0}^{m} A_{j}B_h = {\left( \sum_{j=0}^{m} A_{j}
      \right)} {\left( \sum_{h=0}^{m} B_h \right)} \to {\left(
              \sum_{j=0}^{\infty} A_{j} \right)} {\left( \sum_{h=0}^{\infty}
      B_{h} \right)}
    \]
    inoltre
    \begin{align*}
        \|R_{m}^{1}\| &\le \sum_{j=m+1}^{2m} \sum_{h=0}^{2m-j} \|A_{j}\|\|B_h\|
        \le \sum_{j=m+1}^{2m} {\left( \|A_{j}\| \sum_{h=0}^{2m-j} \|B_h\|
\right)} \le  \\ &\le \sum_{h=0}^{\infty} \|B_h\| \le {\left( \sum_{h=0}^\infty
\|B_h\|\right)} \cdot {\left( \sum_{j=m+1}^{\infty} \|A_{j}\|  \right)} \to 0
    \end{align*}
    per \(m \to \infty\) e analogamente per \(R^2_m\) 
\end{proof}

Ora data \(A \in M^{N\times N}\) consideriamo la serie
\[
  \sum_{k=0}^{\infty} \frac{A^{k}}{k!} 
\] e risulta
\[
  \left\| \frac{A^{k}}{k!}\right\| \le \frac{\|A\|^{k}}{k!} \quad
  \sum_{k=0}^{\infty} \frac{\|A\|^{k}}{k!} < +\infty 
\] 
\begin{definition}{Esponenziale di una matrice}
    \[
        e^{A} := \sum_{k=0}^{\infty} \frac{A^{k}}{k!}
    \]
\end{definition}

\begin{proposition}
    La serie esponenziale converge assolutamente e
    \[
      \left\|e^{A}\right\| \le e^{\|A\|}
    \]
\end{proposition}
\begin{proposition}\label{prop:prop_exp_mat_comm}
    Se \(AB = BA\) allora
    \[
      e^{A + B} = e^{A}e^{B}
    \]
\end{proposition}
\begin{eser}
    Dimostrare la proposizione~\ref{prop:prop_exp_mat_comm} 
\end{eser}
\begin{corollary}
    \(e^{A}\) è invertibile e 
    \[
      {\left( e^{A} \right)} ^{-1} = e^{-A}
    \]
\end{corollary}
\begin{proof}
    \(A\) e \(-A\) commutano e quindi
    \[
      e^{A}e^{-A} = e^{A-A} = e^{0} = I
    \]
\end{proof}

\begin{remark}
    Sia \(A\) una matrice, e \(\tilde{A} = P^{-1}AP\) una matrice simile ad
    \(A\), con \(P\) invertibile. Allora poiché \(\tilde{A}^2 =
    \tilde{A}*\tilde{A} = P^{-1} A \cancel{P P^{-1}} A P\) e in generale risulta
    sempre similmente \(\tilde{A}^{k} = P^{-1}A^{k}P\) otteniamo
    \[
      e^{\tilde{A}} = \sum_{k=0}^{\infty} \frac{\tilde{A}^{k}}{k!} =
      \sum_{k=0}^{\infty} \frac{P^{-1}A^{k} P}{k!} = P^{-1}e^{A}P
    \] 
\end{remark}

\paragraph{Ritornando a \(x'= Ax\) }\label{ritorniamo_a_noi_dopo_exp_matr}
Abbiamo che
\[
  \mathbf{X}_{m} {(t)} = \sum_{k=0}^{m} \frac{{\left( tA \right)} ^{k}}{k!} \to
  e^{tA} \text{ per } m \to \infty
\]
e si ha che
\[
  \left\|\frac{{(tA)}^{k}}{k!}\right\| \le \frac{\|tA\|^{k}}{k!} \le
  \frac{{\left( |t|\|A\| \right)}^{k} }{ k! } \le \frac{{\left( M\|A\| \right)}
  ^{k}}{k!}
\]
per \(|t| \le M\). Poiché l'ultima serie è convergente, abbiamo convergenza
totale (quindi uniforme) sui limitati di \(\mathbb{R}\). Abbiamo dunque
mostrato che la matrice risolvente \(R {(t, 0)} = e^{tA}\), infatti è facile
vedere che il limite di \(\mathbf{X}_m\), se esiste, è punto fisso di \(T\).

Abbiamo dimostrato
\begin{theorem}
    In un sistema autonomo lineare omogeneo del tipo \(x' = Ax\) con \(A \in
    M^{N \times N}{(\mathbb{R})}\) la matrice risolvente è data da
    \[
        R{(t, 0)} = e^{tA}
    \]
    e quindi la soluzione di 
    \[
      \begin{cases}
          x' = Ax \\
          x{(\tau)} = \xi
      \end{cases}
    \]
    è data da \(x^{t} = e^{(t-\tau)A}\xi\) 
\end{theorem}

Come calcolare \(e^{A}\)? È utile il passaggio a matrice simile. Abbiamo detto
che se \(\tilde{A} = P^{-1}AP\) allora \(e^{\tilde{A}} = P^{-1}e^{A}P\).
Interpretiamo ciò nel quadro delle equazioni differenziali \(x'= Ax\) con il
cambiamento di variabile \(\tilde{x}{(t)}\) tale che \(x {(t)} =
P\tilde{x}{(t)}\), con \(P\) invertibile. Allora
\[
  AP\tilde{x} = Ax = x' = P\tilde{x}' \implies \tilde{x}' = \tilde{A}\tilde{x}
\]
che ha matrice risolvente \(e^{t\tilde{A}}\). 
\begin{remark}
    Avevamo \(x'=Ax\) con \(A \in M^{N \times N}{(\mathbb{R})}\). Più in
    generale possiamo considerare il problema \(z' = Az\) con \(z :
    \mathbb{R}\to \mathbb{C}^{N}\) o anche \(z' = \mathcal{A}z\) con
    \(\mathcal{A} \in M^{N \times N}{(\mathbb{C})}\) e \(\mathcal{A} = A + iB\).
    Allora se \(z {(t)} = x {(t)} + iy {(t)}\) abbiamo che
    \begin{equation}\label{eq:obs_complex}
      z'= \mathcal{A}z \implies \begin{cases}
          x' = Ax - By \\
          y' = Bx + Ay
      \end{cases}
    \end{equation}
    che è un sistema di dimensione \(2N\). La proposizione~\ref{prop:44} rimane
    valida quindi lo spazio delle soluzioni \(V^{\mathbb{C}}\) ha dimensione
    (complessa) \(N\), se \(\mathcal{A} = A\) e \(B = 0\)
    allora~\eqref{eq:obs_complex} diventa 
    \[
      \begin{cases}
          x' = Ax & \in V^{\mathbb{R}}\\
          y' = Ay & \in V^{\mathbb{R}}
      \end{cases}
    \]
    e quindi \(V^{\mathbb{C}} = V^{\mathbb{R}} + iV^{\mathbb{R}}\). Da tutto ciò
    discende che
    \begin{proposition}
        Se \(x^{{(1)}}, \dots, x^{{(N)}}\) sono \(N\) soluzioni \textbf{reali} e
        linearmente indipendenti in \(\mathbb{R}\) allora sono anche una base di
        \(V^{\mathbb{C}}\) 
    \end{proposition}
\end{remark}

\paragraph{Calcolo di \(e^{A}\)} Vi sono alcuni casi particolari:
\begin{itemize}[label = --]
    \item \(A\) diagonale allora \(e^{A}\) diagonale con entrate
        \(e^{\lambda_{i}}\) dove \(\lambda_{i}\) sono le entrate di \(A\).
    \item \(A\) blocco nilpotente elementare di ordine \(s\), ossia \(A\) è una
        matrice \(s \times  s\) che ha solo entrate di valore 1 sulla
        sopradiagonale. Allora poiché \(A^{s} = 0\) abbiamo
        \[
          e^{tA} = I + A + \frac{t^2A^2}{2} +~\dots + \frac{t
          ^{s-1}A^{s-1}}{(s-1)!} = \begin{pmatrix}
              1 & t & \frac{t^2}{2} & \dots & \frac{t^{s-1}}{(s-1)!} \\
              0 & 1 & t & \dots & \frac{t^{s-2}}{(s-2)!} \\
              \vdots & \vdots & \ddots & \ddots & \vdots \\
              0 & 0 & \dots & 1 & t \\
              0 & 0 & \dots & 0 & 1
          \end{pmatrix}
        \]
    \item \(A\) diagonalizzabile allora \(A = P\tilde{A}P^{-1}\) se \(A\) è
        associata a \(T\) nella base canonica allora \(P\) ha come colonne gli
        autovettori di \(T\), e \(\tilde{A}\) è diagonale con gli autovalori di
        \(T\). Allora
        \[
            e^{tA} = e^{Pt\tilde{A}P^{-1}} = Pe^{t\tilde{A}}P^{-1} = \begin{pmatrix}
                v_{1} &~\dots & v_{N}
            \end{pmatrix} \begin{pmatrix}
                e^{\lambda_{1}t} & & 0 \\
                & \ddots & \\
                0 & & e^{\lambda_{N}t}
                \end{pmatrix} {\begin{pmatrix}
                v_{1} &~\dots & v_N
        \end{pmatrix}}^{-1}
        \]
\end{itemize}
Da ciò abbiamo che nel problema \(x' = Ax\) con \(A\) diagonalizzabile, allora 
\(x{(t)} = e^{tA}\xi\) al variare di \(\xi \in \mathbb{C}^{N}\), ossia \(x{(t)}
= Pe^{t\tilde{A}}P^{-1}\xi = Pe^{t\tilde{A}}C\), con \(C \in \mathbb{C}^{N}\)
arbitrario è soluzione.
\begin{example}
    Sia \(A = \begin{pmatrix}
        -4 & 3 & 6 \\
        6 & -1 & -6 \\
        -6 & 3 & 8
    \end{pmatrix}\) allora (con qualche calcolo che skippo) otteniamo
    \[
      \det {(A -  \lambda I)} = {(2 - \lambda)}{(\lambda^2 - \lambda - 2)}
    \]
    e quindi gli autovalori sono \(\lambda_{2} = 2\) doppio e \(\lambda_{1} = -1\)
    semplice.
    Allora 
    \begin{align*}
        \ker {(A - \lambda_{1}I)} &= \mathrm{span}\left\{ v_{1} := \begin{pmatrix}
          1 \\
          -1 \\
          1
  \end{pmatrix} \right\} \\
                \ker {(A - \lambda_{2}I)} &= \mathrm{span}\left\{
  v_{2} := \begin{pmatrix}
      1 \\
      0 \\
      1
      \end{pmatrix},v_{3} := \begin{pmatrix} 
      1 \\
      2 \\
      0
\end{pmatrix} \right\}
\end{align*}

e dunque \(P = \begin{pmatrix} v_{1} & v_{2} & v_{3} \end{pmatrix}\) e le soluzioni del sistema sono del tipo
    \[
     x{(t)} = Pe^{t\tilde{A}}C = \begin{pmatrix}
         1 & 1 & 1 \\
         -1 & 0 & 2 \\
         1 & 1 & 0 
         \end{pmatrix} \begin{pmatrix}
         e^{-t} &  &  \\
         & e^{2t} &  \\
         &  & e^{2t}
         \end{pmatrix} \begin{pmatrix}
         c_{1} \\
         c_{2} \\
         c_{3}
     \end{pmatrix}
    \]
in altre parole i vettori \(v_{1}e^{-t}, v_{2}e^{2t}, v_{3}e^{3t}\) formano una
base dello spazio vettoriale \(V\) delle soluzioni di \(x' = Ax\) 
\end{example}
Dal precedente esempio concludiamo che se \(A\) è \emph{diagonalizzabile} e
\(v_{1}, \dots, v_{N}\) sono una base di autovettori di \(A\) allora \(x{(t)}
\in \mathrm{span}_{i \in 1, \dots, N} \{e^{\lambda_{i}t}v_{i}\} \) 
\begin{remark}
    Ciò può essere verificato direttamente, infatti
\begin{itemize}[label = --]
    \item \(u{(t)} = e^{\lambda_{k}t} v_{k}\) è soluzione di \(x' = Ax\):
        \(u'{(t)} = \lambda_{k}e^{\lambda_{k}t}v_{k} = A(e^{\lambda_{k}t}v_{k})
        = Au{(t)}\) 
    \item sono \(N\) vettori linearmente indipendenti, infatti la matrice
        wronskiana in \(t= 0\) è \(P\) invertibile.
\end{itemize}
\end{remark}

Ricordiamo da algebra lineare che se \(T : V \to  V\) è un operatore lineare su
\(V\), allora
\[
    \ker T^{s} = \ker T^{s+1}, \quad \mathrm{Im} T^{s} = \mathrm{T^{s+1}}, \quad V = \ker T^{s} \oplus \mathrm{Im} T^{s} \quad \text{ per un certo } s \in
    1\dots n
\]
e intendiamo \(s\) come il più piccolo intero tale che valga tale proprietà
(\(n := \dim V\) è un possibile valore). Inoltre su \(\ker T^{s}\) vi è al più
(spazio banale allora \(T\) non ha autovalori) l'autovalore nullo. Infatti se
\(\lambda \in \mathbb{K}, v \in \ker T^{s}\sminus \{0\} \) tali che \(Tv =
\lambda v\) allora \(0 = T^{s}v = \lambda^{s}v\) e quindi \(\lambda = 0\).
Mostriamo che invece su \(\mathrm{Im} T^{s}\) \(T\) non può presentare 0 come
autovalore. Infatti se \(v \in V\)
con \(Tv = 0\) e quindi \(T^{s}v = 0\) allora \(v \in \ker T^{s}\) e sappiamo
che \(\ker T^{s} \cap \mathrm{Im} T^{s} = \{0\}\) dunque \(v = 0\). Riassumendo
abbiamo
\begin{lemmao}[Separazione degli autovalori o dec.~di
    Fitting]\label{lemma:fitting}
    Se \(T : V \to V\) è un operatore lineare su \(V\) allora esiste \(s \in
    \mathbb{N}\)
    tale che
    \[
      \ker T^{s} = \ker T^{s+1}
    \]
    sia \(s\)  il minimo intero con tale proprietà. Allora
    \[
        s \le \dim \ker V, \quad \mathrm{Im} T^{s} = \mathrm{Im} T^{s+1}, \quad
        V = \ker T^{s} \oplus \mathrm{Im} T^{s}
    \]
    Inoltre su \(\ker T^{s}\) non vi sono autovalori di \(T\) diversi da 0, mentre su
    \(\mathrm{Im} T^{s}\) non vi sono autovalori nulli.
\end{lemmao}
Fissiamo \(T : V \to V\) e \(\lambda \in \mathbb{K} = \mathbb{C}\).
L'applicazione \(T = \lambda I\) allora:
\begin{itemize}[label = --]
    \item ha 0 come autovalore se e solo se \(T\) ha
\(\lambda\) come autovalore 
    \item un sottospazio di \(V\) è \(T-\)invariante se e solo se è \(T -
        \lambda I\)-invariante
    \item Sia \(p{(z)}\) il polinomio caratteristico di \(T\). Allora
        \(p{(z+\lambda)}\) è il polinomio caratteristico di \(T - \lambda I\) 
\end{itemize}
Sia \(\lambda\) autovalore di \(T\) con molteplicità algebrica \(m
{(\lambda)}\). Allora 0 è autovalore di \(T - \lambda I\) con molteplicità
algebrica \(m {(\lambda)}\). Applichiamo ora il lemma~\ref{lemma:fitting} a \(T
- \lambda I\) ottenendo che 
\[
  V = V_\lambda \oplus W, \quad V_\lambda := \ker {(T - \lambda I)}^s, 
   \quad W := \mathrm{Im} {(T - \lambda I)}^s
\]
Inoltre 
\[
  s \le \dim \ker T^{s} \quad \text{ e } \quad m {(\lambda)} = \dim V_\lambda =
  \dim \ker T^{s}
\]
e \(T|_{V_\lambda} \) ha solo l'autovalore \(\lambda\) mentre \(T|_{W} \) non ha
\(\lambda\) come autovalore.
\begin{definition}
    Diciamo \textbf{autospazio generalizzato} relativo all'autovalore
    \(\lambda\) il sottospazio
    \[
        G{(\lambda, T)} = \bigcup_{j = 1} ^{\infty} \ker {(T - \lambda I)}^{j} =
        \ker {(T - \lambda I)}^{n}
    \]
    con \(n\) la molteplicità algebrica di \(\lambda\).
\end{definition}
Da quanto precede esiste \(s \le m {(\lambda)}\) tale che \(G{(\lambda, T)} =
\ker {(T - \lambda I)}^{ s }\) 

\begin{theorem}
    Siano \(\lambda_{1}, \dots, \lambda_q\) gli autovalori distinti di \(T\) ,
    allora
    \[
        V = \bigoplus_{i=1}^{q} G{(\lambda_{i}, T)}
    \]
\end{theorem}
\begin{remark}
    \(\sum_{k=1}^{q} \dim G {(\lambda_{k})} = \sum_{i=1}^{q} m {(\lambda_{k})} =
    n\) 
\end{remark}

\subsection{Caso generale}
Se \(A\) avesse un solo autovalore \(\lambda\) con molteplicità \(N\) allora
\[
  A = \lambda I + (A - \lambda I )
\]
dove \(A - \lambda I\) è necessariamente nilpotente, infatti poiché 0 è l'unico
autovalore e \(V = \ker T^{s} \oplus \mathrm{Im}T^{s}\) allora
\(\mathrm{Im}T^{s} = \{0\} \).

Poiché \(\alpha I\) commuta con ogni altra matrice per \(\alpha \in \mathbb{K}\) 
\begin{equation}\label{eq:exp-1-eigenval}
    e^{tA} = e^{t \lambda I + t{(A- \lambda I)}} = e^{t\lambda I}e^{t(A-\lambda
    I)}
\end{equation}
Sia ora \(x' = Ax\) generica. Siano \(\lambda_{1}, \lambda_{2}, \dots, \lambda_q
\in \mathbb{C}\) gli autovalori distinti di \(A_{\mathbb{C}} \). Allora
\[
    \mathbb{C}^{N} = \bigoplus_{i=1}^{q} G{(\lambda_{i}, T^A_{\mathbb{C}})}
\]
Sia \(\tilde{\mathcal{B}}_k\) una base di \(G{(\lambda_{k})}\) per ogni \(k =
1\dots q\) e sia \(\tilde{\mathcal{B}}\) l'unione di tutte le
\(\tilde{\mathcal{B}}_k\). Allora \(\tilde{\mathcal{B}}\) è una base di
\(\mathbb{C}^{N}\) rispetto a cui la matrice associata a \(T\) è diagonale a
blocchi
\[
  \tilde{A} = \begin{pmatrix}
      \tilde{A}_{1} &  &  &  \\
       & \tilde{A}_2 &  &  \\
        &  & \ddots &  \\
         &  &  & \tilde{A}_q
  \end{pmatrix} \implies e^{t\tilde{A}} =
  \begin{pmatrix}
      e^{\tilde{A}_{1}} &  &  &  \\
       & e^{\tilde{A}_2} &  &  \\
        &  & \ddots &  \\
         &  &  & e^{\tilde{A}_q}
  \end{pmatrix}
\]
dove \(\tilde{A}_k\) è la matrice associata a \(T^{A}|_{G{(\lambda_{k})}}\) rispetto
alla base \(\tilde{\mathcal{B}}_k\). 
Per ogni \(k = 1\dots q\), \(\tilde{A}_k\) ha solo \(\lambda_{k}\) come
autovalore, quindi \(\tilde{A}_k = \lambda_{k} I + {(\tilde{A}_k - \lambda_{k}
I)}\) e ci si può rifare al caso visto~\eqref{eq:exp-1-eigenval}.

\begin{eser}
    Sia \(A = \begin{pmatrix}
        1 & -6 & -3 \\
        -4 & 3 & 4 \\
        2 & -7 & -4
    \end{pmatrix}\). 
    Fornire una base dello spazio delle soluzioni di \(x' = Ax\).
\end{eser}

\begin{theorem}
    Una base dello spazio delle soluzioni dell'equazione \(x' = Ax\) è data da
    \(N\) opportune funzioni della forma
    \[
      u{(t)} = e^{\lambda t}p{(t)}
    \]
    con \(\lambda \) autovalore di \(A\) e \(p{(t)}\) polinomio a coefficienti
    in \(\mathbb{C}^{N}\) di grado al più \(m {(\lambda)} - 1\).
\end{theorem}
\begin{proof}
    \[
      \mathbb{C}^{N} = \bigoplus_{k =1}^{q} G{(\lambda_{k}, T^{A})}
    \]
    allora se \(P = \begin{pmatrix}
        v_{1} & \dots & v_N
    \end{pmatrix}\) è la matrice costituita dagli autovettori delle basi di
    \(G{(\lambda_{k})}\), \(\tilde{A} = P^{-1}AP\) e 
    \[
      e^{t\tilde{A}} = \begin{pmatrix}
          e^{t\tilde{A}_1} &  &  \\
           & \ddots & 
            &  & e^{t\tilde{A}_q}
      \end{pmatrix}
    \] 
    Una base dello spazio delle soluzioni è data dalle colonne di \(P
    e^{t\tilde{A}}\).

    Osserviamo che \(\mathcal{N}_k = \tilde{A}_k - \lambda_{k} I\) è nilpotente
    perché \(\tilde{A}_k\) ha solo l'autovalore \(\lambda_{k}\) e dunque
    \[
      e^{t\tilde{A}_k} = e^{\lambda_{k}t} \cdot e^{t \mathcal{N}_k} =
      e^{\lambda_{k} t}{\left(I + t \mathcal{N}_k + \frac{1}{2}t^2\mathcal{N}^2_k +
      \dots + \frac{1}{(s-1)!}t ^{s-1}\mathcal{N}_k^{s-1}\right)}
    \]
    allora \(x{(t)} = P e ^{t\tilde{A}} C\) è un esponenziale per un polinomio.
\end{proof}

% TODO : manca un po'

\subsection{Equazioni differenziali lineari omogenee a coefficienti costanti}
Se \(Ly = f\) abbiamo che se \(f{(t)} = P_m{(t)}e ^{\lambda t}\) si ricerca
\(\overline{y}\) della forma
\[
  \overline{y}{(t)} = t ^{\mu} Q_m {(t)} e^{\lambda t}
\]
con \(Q_{m}{(t)}\) polinomio di grado \(\le m\) e \(\mu\) molteplicità di
\(\lambda\) come radice del polinomio caratteristico. Se \(\lambda = \alpha + i
\beta\) allora si cerca
\[
    \overline{y}{(t)} =t ^{\mu} {(A{(t)}\cos \beta t + B{(t)}\sin \beta t)}e^{\alpha t}
\] 
con \(\deg A(t), \det B(t) \le m\) 

\paragraph{Bidimensionale} Se \(N = 2\) abbiamo
\begin{align*}
    x_{1}' = a_{11}x_{1} + a_{12}x_{2} \\ x_{2}' = a_{21}x_{1} + a_{22}x_{2}
\end{align*}
ossia \(x' = Ax\).
Se ora \(\lambda= 0\) è autovalore, cioè \(\det A = 0\) allora ad esempio
\[
  {(a_{21}, a_{22} )} = \lambda{(a_{11} , a_{12} )}
\]
quindi
\[
  x_{2} - \lambda x_{1} = \text{ const } \implies \text{ rette }
\]

Sia ora \(\det A \neq 0\). Allora si presentano 3 casi
\begin{itemize}[label = --]
    \item autovalori reali, matrice diagonalizzabile
    \item autovalori reali, matrice \textbf{non} diagonalizzabile
    \item autovalori complessi coniugati
\end{itemize}

\paragraph{Reali, diagonalizzabile } Esiste una base di autovettori tale che la
matrice sia diagonale. Allora a meno di moltiplicare per matrici costanti è
equivalente studiare il sistema
\[
    x' = \begin{pmatrix}
        \lambda_{1} & 0 \\
        0 & \lambda_{2}
    \end{pmatrix} x \quad \begin{cases}
    x_{1}' = \lambda_{1}x_{1} \\ x_{2}' = \lambda_{2}x_{2}
    \end{cases}
\]
che ha soluzione
\[
  \begin{cases}
      x_{1}{(t)} = x_{1}^{0} e^{\lambda_{1} t} \\
      x_{2}{(t)} = x_{2}^{0} e^{\lambda_{2} t}
  \end{cases}
\]
Se \(x_{1}^{0} = 0\) oppure \(x_{2}^{0}= 0 \) l'orbita è il corrispondente
semiasse (oppure (0,0) se entrambi sono nulli). Se \(x_{1}^{0} \neq 0 \neq
x_{2}^{0}\) allora dalla seconda equazione possiamo ottenere
\[
  e^{\lambda_{2} t} = \frac{x_{2}{(t)}}{x_{2}^{0}}; \quad
      x_{1} = x_{1}^{0} {\left( e^{\lambda_{2} t}
      \right)}^{\frac{\lambda_{1}}{\lambda_{2}}} \implies 
      x_{1} = x_{1}^{0}{\left( \frac{x_{2}}{x_{2}^{0}} \right)}^{
      \frac{\lambda_{1}}{\lambda_{2}}}
\]
che sono curve di potenze. Nella
figura~\ref{fig:orbite-problema-reali-diagonalizzabile} alcuni possibili casi.
\begin{figure}[ht]
    \centering
    \incfig{orbite-problema-reali-diagonalizzabile}
    \caption{Se gli autovalori sono positivi abbiamo il caso nero, se gli
    autovalori sono negativi abbiamo invece il caso rosso. Sulla destra il caso
in cui il segno degli autovalori non è concorde, in particolare \(\lambda_{2} <
0 < \lambda_1\) }
    \label{fig:orbite-problema-reali-diagonalizzabile}
\end{figure}
Se invece \(\lambda_{1} = \lambda_{2}\) allora otteniamo \(x_{2} = Cx_{1}\) e
quindi le orbite sono semirette partenti dall'origine.

\paragraph{Reali coincidenti, non diagonalizzabile} Se la matrice non è diagonalizzabile
allora possiamo ricondurre alla matrice
\[
  A = \begin{pmatrix}
      \lambda & 1 \\
      0 & \lambda
  \end{pmatrix}
\]
per la forma di Jordan. Allora abbiamo
\[
  x{(t)} = e^{tA}\begin{pmatrix}
      c_{1} \\
      c_{2}
  \end{pmatrix} = e^{\lambda t} e^{t \begin{pmatrix}
      0 & 1 \\
      0 & 0
  \end{pmatrix}} \begin{pmatrix}
      c_{1} \\
      c_{2}
  \end{pmatrix} = e^{\lambda t} \begin{pmatrix}
      1 & t \\
      0 & 1
  \end{pmatrix} \begin{pmatrix}
      c_{2} \\
      c_{2}
  \end{pmatrix} 
\]
dunque il sistema è
\[
  \begin{cases}
      x_{1} = {(c_{1} + c_{2} t)} e^{\lambda t} \\
      x_{2} = c_{2} e^{\lambda t}
  \end{cases}
\]
Se \(c_{2} = 0\) allora l'orbita è sull'asse \(x_{2} = 0\). Altrimenti
(supponendo \(x_{2}^{0} = c_{2} > 0\)) abbiamo
\[
  e^{\lambda t} = \frac{x_{2}}{c_{2}} \implies \lambda t = \log
  \frac{x_{2}}{c_{2}} \implies t = \frac{1}{\lambda} \log{(\frac{x_{2}}{c_{2}})}
\]
\[
  x_{1} = {\left( c_{1}+\frac{c_{2}}{\lambda} \log \frac{x_{2}}{c_{2}} \right)}
  \frac{x_{2}}{c_{2}} \overset{x_{2}, c_{2} > 0}{=} x_{2}{\left(
  \frac{c_{1}}{c_{2}} + \frac{1}{\lambda}{(\log x_{2} - \log c_{2})} \right)} 
\]
che è della forma \(\displaystyle x_{1} = x_{2}{\left( \gamma +
\frac{1}{\lambda}\log x_{2} \right)} \). Studiando tale funzione si ottiene che
il grafico delle orbite è come in
figura~\ref{fig:orbite-problema-reali-non-diagonalizzabile}.
\begin{figure}[ht]
    \centering
    \incfig[.7]{orbite-problema-reali-non-diagonalizzabile}
    \caption{Orbite problema reali non diagonalizzabile, l'origine è un nodo
    improprio}\label{fig:orbite-problema-reali-non-diagonalizzabile}
\end{figure}

\paragraph{Autovalori complessi coniugati} Abbiamo che \(\lambda_{1,2} = \alpha
\pm i \beta\). In un'opportuna base la matrice è
\[
  A = \begin{pmatrix}
      \alpha & \beta \\
      -\beta & \alpha
  \end{pmatrix} \implies e^{t A} = e^{\alpha t} \begin{pmatrix}
      \cos \beta t & \sin \beta t \\  
      -\sin \beta t & \cos \beta t
  \end{pmatrix}
\]
Se \(c_{1}, c_{2} = {(0, 0)}\) allora \(x{(t)} \equiv 0\). Altrimenti sia
\[
  R = \sqrt{c_{1}^2 + c_{2}^2} ,\quad \left\|{\left(\frac{c_{1}}{R},
      \frac{c_{2}}{R}\right)}\right\| =
  1
\]
e dunque le soluzioni diventano
\begin{align}\label{eq:compl_conj}
  \begin{cases}
      x_{1} = R e^{\alpha t} \cos{(\varphi  - \beta t)} \\
      x_{2} = R e^{\alpha t} \sin{(\varphi  - \beta t)}
  \end{cases}
\end{align}
cioè in coordinate polari 
\[
  \rho = R e^{\alpha t} \quad \theta = \varphi - \beta t \implies \rho = R e
  ^{\alpha {\left( \frac{\varphi}{\beta} - \frac{\theta}{\beta} \right)} } =
  Ke^{-\frac{\alpha}{\beta}\theta}
\]
che quindi formano spirali logaritmiche, che possono essere sia convergenti che
divergenti a seconda del segno di \(\alpha\) (ricordare che nella costante \(K\)
c'entra anche \(\alpha\), per questa osservazione guardare le
equazioni~\eqref{eq:compl_conj}). Il segno di \(\frac{\alpha}{\beta}\) influenza
soltanto il verso di rotazione della spirale. Se \(\alpha = 0\) chiaramente si
ha invece che \(\rho\) è costante e dunque le orbite sono circonferenze.

\subsection{Stabilità}
Sia \(\Omega \subseteq \mathbb{R}^{N} \) aperto e \(f : \Omega \to
\mathbb{R}^{N}\) di classe \(C^{1}\). Consideriamo l'equazione differenziale
\(x'=  f{(x)}\) e consideriamo il flusso \({(t,x)} \mapsto \varphi {(t, x)}\)
dell'equazione differenziale. Ricordiamo che \(\varphi {(\cdot , x)}\) risolve
l'equazione con dato iniziale \(t = 0\).

Se \(f{(x)} = Ax\) allora abbiamo
\[
    \varphi {(t, x)} = e^{tA}x
\]
(a volte l'operatore associato a \(e^{tA}\) viene detto \textbf{flusso lineare}) 

\begin{definition}{Punto di equilibrio}
    \(\overline{x} \in \Omega\) si dice punto di equilibrio per \(x'= f{(x)}\)
    (o per il flusso \(\varphi \)) se \(f{(\overline{x})} = 0\), ovvero se
    \(x{(t)} = \overline{x}\) è soluzione (oppure \(\varphi {(t, \overline{x})}
    = \overline{x}\))
\end{definition}
\begin{remark}
    È utile specificare la definizione anche per il flusso perché si può anche
    definire senza equazione differenziale. Ricordando le proprietà del flusso
    presentate in~\ref{prop:flusso} possiamo costruire il flusso come mappa che
    rispetti le proprietà del flusso.
\end{remark}
\begin{definition}{Stabilità e attrattività}
    Sia \(\overline{x}\) punto di equilibrio. Allora
\begin{itemize}[label = --]
    \item \(\overline{x}\) si dice \textbf{stabile} (secondo Lyapunov) se per
        ogni \(U\) intorno di \(\overline{x}\) esiste \(V\) intorno di
        \(\overline{x}\) tale che per ogni \(x \in V\) 
        \[
          \omega_+{(x)} = +\infty, \quad \varphi {(t, x)} \in U \quad \forall t
          \ge 0
        \]
    \item \(\overline{x}\) si dice \textbf{attrattivo} se esiste \(V\) intorno
        di \(\overline{x}\) tale che per ogni \(x \in V\) 
        \[
          \omega_+{(x)} = +\infty, \quad \varphi {(t,x)} \to \overline{x} \text{
          per } t \to +\infty
      \]
    \item \(\overline{x}\) si dice \textbf{asintoticamente stabile} se è stabile
        e attrattivo
\end{itemize}
\end{definition}
\begin{figure}[ht]
    \centering
    \incfig{stabilità-e-attrattività}
    \caption{In ordine, \(\overline{x}\) stabile, \(\overline{x}\) attrattivo e
    \(\overline{x}\) asintoticamente stabile}\label{fig:stabilità-e-attrattività}
\end{figure}

Spoilerone: esistono sia punti di equilibrio stabili e non attrattivi che
attrattivi e non stabili.
\begin{remark}
    Nella stabilità, per l'arbitrarietà di \(U\) consideriamo \(U \subseteq
    \overline{U} \subseteq \Omega  \), allora
    \[
        \varphi {(t, x)} \in  \overline{U} \subseteq \Omega \quad t \in [0,
        \omega_+{(w)}] 
    \]
    Ne segue che \(\omega_+{(x)} = +\infty\) 
\end{remark}
\paragraph{Stabilità dell'origine per sistemi lineari}
Riconsideriamo il problema \(x' = AX\) con \(A \in M^{N \times
N}{(\mathbb{R})}\). Allora
\begin{definition}{Pozzo e Sorgente}
    L'origine è detta \textbf{pozzo} se comunque presa \(x{(\cdot )}\) soluzione
    si ha che
    \[
      \lim_{t \to \infty} x{(t)} = 0
    \]
    
    L'origine è detta \textbf{sorgente} se comunque presa \(x{(\cdot )}\)
    soluzione non nulla, risulta
    \[
      \lim_{t \to \infty} |x{(t)}| = + \infty
    \]
\end{definition}

\begin{theorem}
    L'origine è un pozzo se e solo se tutti gli autovalori di \(A\) hanno parte
    reale negativa.

    L'origine è una sorgente se e solo se tutti gli autovalori di \(A\) hanno
    parte reale positiva.
\end{theorem}
\begin{proof}
    Sia \(\Re (\lambda) < 0\) per ogni \(\lambda = \alpha + i \beta\). Sappiamo
    che ogni soluzione è combinazione lineare di funzioni della forma 
    \[
      e^{\alpha t} \cos \beta t \, p{(t)} \quad, \quad e^{\alpha t} \sin \beta
      t \, q{(t)}
    \]
    Ne segue che \(x{(t)} \to  0\) per \(t \to \infty\).

    Sia ora \(\Re(\lambda) > 0\) per ogni \(\lambda \). Allora la matrice \(-A\)
    ha autovalori con parte reale negativa e quindi
    \[
      e^{-tA}\xi \overset{t \to \infty}{\longrightarrow} 0 \quad \forall \xi
      \implies \left| e^{-tA} \xi \right| \to 0
    \]
    e quindi in particolare per \(\xi = e_{1}, e_{2}, \dots, e_N\) la base
    canonica abbiamo
    \[
      \|e^{-tA}\| \to 0
    \]
    Sia ora \(x_{0} \in \mathbb{R}^{N} \sminus \{0\} \) e \(x{(t)} =
    e^{tA}x_{0}\) e 
    \[
      x{(t)} = e^{tA}x_{0} \implies x_{0} = e^{-tA} x{(t)} 
    \]
    Infine
    \[
        0 \neq |x_{0}| \le \underbrace{\|e^{-tA}\|}_{\to 0} \underbrace{
        |x{(t)}|}_{\to +\infty} 
    \]
\end{proof}
Sia \(v\) autovettore relativo a \(\lambda\). Allora
\[
  x{(t)} = e^{\lambda t}v \text{ è soluzione }
\]
e inoltre
\[
  |x{(t)}| = e^{\Re(\lambda) t}|v| \to \begin{cases}
      0 & \text{ se 0 è pozzo} \\
      +\infty & \text{ se 0 è sorgente}
  \end{cases}
\]

Consideriamo il caso in cui non tutti gli autovalori hanno parte reale dello
stesso segno (\emph{flussi iperbolici}), in particolare diciamo
\[
  \Re \lambda_{k} < 0 \quad k = 1, \dots, r \quad \Re \lambda_{k} > 0 \quad k =
  r+1, \dots, q
\]
dove \(\lambda_{1}, \dots, \lambda_q\) sono gli autovalori distinti di \(A\).

Prendiamo gli autospazi generalizzati \(G{(\lambda_{k})}\) e sappiamo
\[
    \mathbb{C}^{N} = \bigoplus_{k=1}^{q} G{(\lambda_{k})} = \bigoplus_{k=1}^{r}
    G{(\lambda_{k})} \oplus \bigoplus_{k=r+1}^{q} G{(\lambda_{k})} =:
    \underbrace{E^{\mathbb{C}}_s}_{(stable)}  \oplus
    \underbrace{E^{\mathbb{C}}_u}_{(unstable)} 
\]
Considerando una base reale per ogni sottospazio della forma \(G(\mu) \oplus
G{(\overline{\mu})}\) si ottiene una base reale sia per \(E^{\mathbb{C}}_s\) che
per \(E^{\mathbb{C}}_u\). Posto ora
\[
    E_s = E^{\mathbb{C}}_s \cap \mathbb{R}^{N}, \quad E_u = E^{\mathbb{C}}_u
    \cap \mathbb{R}^{N} \implies \mathbb{R}^{N} = E_s \oplus E_u
\]
\begin{definition}{Sottospazi stabile e instabile}
    I precedenti \(E_s\) e \(E_u\) vengono rispettivamente detti sottospazio
    \textbf{stabile} e sottospazio \textbf{instabile} del
    problema~\eqref{eq:sist_lin_omog}
\end{definition}
\begin{example}
    Sia \(A = \begin{pmatrix}
        1 & 4 \\
        2 & -1
    \end{pmatrix}\). Allora gli autovalori sono evidentemente \(\lambda_{1} =
    -3\) e \(\lambda_{2} = 3\). Come autovettori associati possiamo avere
    \(v_{1} = \begin{pmatrix}
        1 \\
        -1
    \end{pmatrix}\) per \(\lambda_{1}\) e \(v_{2} = \begin{pmatrix}
        2 \\
        1
    \end{pmatrix}\) per \(\lambda_{2}\). Allora \(P = \begin{pmatrix}
    v_{1} & v_{2}
    \end{pmatrix}\) e \(\tilde{A} = P^{-1}AP = \begin{pmatrix}
        -3 & 0 \\
        0 & 3
    \end{pmatrix}\). Quindi sapendo \(x = P\tilde{x}\) abbiamo che
    \[
      \tilde{x}{(t)} = e^{t\tilde{A}} \begin{pmatrix}
          c_{1} \\
          c_{2}
      \end{pmatrix} \implies \begin{cases}
      \tilde{x_{1}} {(t)} = c_{1} e^{-3t} \\
      \tilde{x}_2 {(t)} = c_{2} e^{3t}
      \end{cases}
    \]
    che è un'iperbole di equazione \(\tilde{x}_{1} \tilde{x}_{2} = c_{1} c_{2}
    \). Infine rimettiamo assieme i pezzi per concludere che 
    \[
      x{(t)} = \begin{pmatrix}
          x_{1}{(t)} \\
          x_{2}{(t)}
      \end{pmatrix} = \begin{pmatrix}
          v_{1} & v_{2}
      \end{pmatrix} \begin{pmatrix}
          \tilde{x}_1{(t)} \\
            \tilde{x}_2{(t)}
      \end{pmatrix} = c_{1} e^{-3t} \begin{pmatrix}
          1 \\
          -1
          \end{pmatrix} + c_{2} e^{3t} \begin{pmatrix}
          2 \\
          1
      \end{pmatrix}
    \]

\begin{figure}[ht]
    \centering
    \incfig{esempio46}
    \caption{\(\tilde{x}' = \tilde{A} \tilde{x}\) a sinistra, \(x' = Ax\) a
    destra}\label{fig:esempio46}
\end{figure}
\end{example}

\begin{theorem}
    L'origine è stabilese e solo se
\begin{itemize}[label = --]
    \item \(\Re \lambda \le 0\) per ogni \(\lambda\) 
    \item per gli autovalori \(\lambda\)  per i quali \(\Re \lambda = 0\) deve
        essere \(p{(\lambda)} = m {(\lambda)}\) 
\end{itemize}
\end{theorem}

\subsection{Stabilità linearizzata}
Consideriamo \(x'= f{(x)}\), con \(f \in C^{1}\) e \(\overline{x}\) di
equilibrio. Per semplicità sia \(\overline{x} = 0\), dunque \(f{(0)} = 0\).
Allora viene naturale chiedersi se uno possa studiare la stabilità di
\(\overline{x}\) studiando la stabilità del sistema lineare \(x'=
{(Df{(0)})}x\). 
\begin{theorem}
    Se \(Df{(0)}\) ha autovalori con parte reale negativa allora \(\overline{x} =
    0\) è asintoticamente stabile per \(x'= f{(x)}\) 
\end{theorem}
\begin{theorem}
    Se \(Df{(0)}\) ha un autovalore con parte reale strettamente positiva,
    allora \(\overline{x} = 0\) è instabile per \(x' = f{(x)}\) 
\end{theorem}

\begin{example}[Pendolo smorzato]
    Ricordiamo l'equazione che governa il pendolo smorzato
    \[
      \ddot{\theta} + \omega^2 \sin \theta + 2a \dot{\theta} = 0 \iff 
      \begin{cases}
          \dot{\theta} = v \\
          \dot{v} = -\omega^2 \sin\theta -2av
      \end{cases}
    \]
    quindi \(x = \begin{pmatrix}
        \theta \\
        v
    \end{pmatrix}\) e \(f{(\theta, v )} = \begin{pmatrix}
        v \\
        -\omega^2 + \sin\theta -2av
    \end{pmatrix}\). È facile trovare i punti di equilibrio dove \(f{(\theta,
    v)} = 0\), dunque
    \[
      \begin{cases}
          v = 0\\
          \sin\theta = 0 \iff \theta = k\pi, k \in \mathbb{Z}
      \end{cases}
    \]
    E per studiare la stabilità dei punti \(k\pi, 0\) studiamo gli autovalori
    della jacobiana
    \[
      Df{(k\pi, 0)} = \begin{pmatrix}
          0 & 1 \\
          -\omega^2\cos k\pi & -2a
      \end{pmatrix}
    \]
    e dopo un paio di conti viene fuori che \(\lambda_{1, 2} = -a \pm \sqrt{a^2
    - \omega^2} \) per \(k\) pari e \(\lambda_{1, 2} = -a \pm \sqrt{a^2 +
    \omega^2} \) per \(k\) dispari. Dunque per \(k\) pari \(\Re \lambda < 0\)
    sono
    asintoticamente stabili, mentre per \(k\) dispari \(\lambda_{1} < 0 <
    \lambda_{2}\) sono instabili.
\end{example}

E ora una bomba di teorema (non dimostrato ovviamente)
\begin{theorem}[Grobman\--Hartman]
    Supponiamo che \(Df{(0)}\) abbia autovalori con parte reale non nulla.
    Esistono \(U, V\) intorni di \(\overline{x} = 0\) e \(h : U \to V\)
    omeomorfismo tali che 
    \[
        e^{tDf{(0)}}h{(x)} = h{(\varphi {(t, x)})}
    \]
\end{theorem}
\begin{figure}[ht]
    \centering
    \incfig[.7]{omeomorfismo-linearizzato}
    \caption{Omeomorfismo linearizzato}
    \label{fig:omeomorfismo-linearizzato}
\end{figure}

\subsection{Funzioni di Lyapunov}

Nel caso del pendolo semplice, si può anche pensare di trovare i punti di
equilibrio stabili come punti di ``minima energia potenziale''. È possibile
generalizzare e formalizzare tale ragionamento nel seguente modo.

    Sia \(\Omega \subseteq \mathbb{R}^{N} \) aperto e \(f \in C^{1}{(\Omega;
    \mathbb{R}^{N})}\). Consideriamo il problema \(x' = f{(x)}\). Sia \(U
    \subseteq \Omega \) aperto e sia \(V :U \to \mathbb{R}\) differenziabile.
    Sia \(\varphi {(t, x)}\) il flusso associato all'equazione e per ogni \(x
    \in U\) sia 
    \[
        \dot{V}{(x)} := \frac{d}{dt} V{(\varphi{(t, x)})}|_{t=0}
    \] 
    Risulta allora 
    \[
      \dot{V}{(x)} = \nabla V{(\varphi {(t, x)})} \cdot \frac{d}{dt} \varphi
      {(t, x)}|_{t=0} = \nabla V{(x)} \cdot f{(x)}
    \]
    \begin{definition}{Derivata orbitale}
    Diciamo \textbf{derivata orbitale} di \(V\) in \(x \in U\) 
    \[
        \dot{V}{(x)} = \nabla V{(x)} \cdot f{(x)}
    \]
    allora \(\dot{V}{(x)}\) dà la velocità di variazione di \(V\)  in \(x\)
    lungo il flusso
\end{definition}
\begin{remark}
    Sia \(x\) fissato e valutiamo \(V\) lungo l'orbita per \(x\), cioè
    \[
        \frac{d}{dt} V{(\varphi{(t, x)})} = \nabla V{(\varphi{(t, x)})} \cdot
        \frac{d}{dt} \varphi {(t,x)} = \nabla V{(\varphi{(t, x)})} \cdot
        f{(\varphi{(t, x)})} = \dot{V}{(\varphi{(t, x)})}
    \]
\end{remark}

Supponiamo che \(\overline{x}\) sia un punto di equilibrio per il sistema \(x' =
f{(x)}\), \(U\) un intorno di \(\overline{x}\) e \(V: U\to \mathbb{R}\)
differenziabile. Supponiamo che \(\dot{V} \le 0\) in \(U\), \(V> 0\) in \(U
\sminus \{\overline{x}\}\) e \(V{(\overline{x})} = 0\). Mostriamo che
\(\overline{x}\) è stabile.

Fissiamo \(\delta > 0\) con \(\overline{B_\delta {(\overline{x})}} \subseteq U
\). Sia allora
\[
  \alpha := \min_{\partial B_\delta {(\overline{x})}} V > 0 \quad W := \{x \in
  B_\delta {(\overline{x})} : V{(x)} < \alpha\} \ni \overline{x}
\]
Sia ora \(x \in W\) e consideriamo \(\varphi {(t,x)}\). Si ha 
\[
  \frac{d}{dt} V{(\varphi {(t,x)})} = \dot{V}{(\varphi{(t,x)})} \le 0
\] finché \(\varphi {(t,x)} \in U\). Poiché \(V{(\varphi{(0, x)})} = V{(x)} <
\alpha\) allora \(\varphi {(t,x)} \in W \subseteq B_\delta {(\overline{x})} \).

\begin{example}
    \[
      \begin{cases}
          x_{1}' = x_{2}^{4} - x_{1} \\
          x_{2}' = x_{1}^{4} - x_{2}^{3}
      \end{cases}
    \]
    chiamiamo \(x_{1} = x\) e \(x_{2} = y\) allora abbiamo \(f{(x, y)} = \begin{pmatrix}
        y^{4}-x \\
        x^{4}-y^{3}
\end{pmatrix} \overset{\text{set}}{=} 0\) per i punti \((0, 0)\) e \(1, 1\).
Allora
\[
  Df{(x, y)} = \begin{pmatrix}
      -1 & 4y^{3} \\
      4x^{3} & -3y^{2}
  \end{pmatrix} \quad Df{(0, 0)} = \begin{pmatrix}
      -1 & 0 \\
      0 & 0
  \end{pmatrix} \quad Df{(1, 1)} = \begin{pmatrix}
      -1 & 4 \\
      4 & -3
  \end{pmatrix}
\]
Dove il secondo ha determinante -13 e traccia -4 quindi è instabile. Per il
primo invece non possiamo studiare la stabilità linearizzante in quanto ha
autovalori \(\lambda_{1} = -1\) e \(\lambda_{2} = 0\). Usiamo però la funzione
\(V{(x, y)} = \frac{1}{2}{(x^2 + y^2)}\) è sempre positiva e nulla solo in \(0,
0\). Inoltre
\begin{align*}
    \dot{V}{(x,y)} &= \nabla V{(x,y)} \cdot f{(x,y)} = \begin{pmatrix}
      x \\
      y
  \end{pmatrix} \cdot  \begin{pmatrix}
      y^{4} - x \\
      x^{4} - y^{3}
  \end{pmatrix} = xy^{4} - x^2 + yx^{4} - y^{4} = \\
                   &= -x^2{(1 - yx^2)} - y^{4}{(1 - x)} \overset{\text{in un intorno di \(0,0\) }}{\le } -\frac{1}{2}{(x^2 + y^{4})} \le 0
\end{align*}
\end{example}
\begin{theorem}
    Sia \(f \in C^1{(\Omega, \mathbb{R}^{N})} \) e \( \overline{x} \in \Omega\)
    con \(f{(\overline{x})} = 0\).

    Sia \(U\) intorno di \(\overline{x}\) e \(V : U \to \mathbb{R}\) tali che
\begin{itemize}[label = --]
    \item \(V\) è differenziabile in \(U \sminus \{\overline{x}\} \) 
    \item \(V > 0\) in \(U \sminus \{\overline{x}\} \), \(V{(\overline{x})} = 0\) 
    \item \(\dot{V} \le 0\) in \(U \sminus \{\overline{x}\} \) 
\end{itemize}
allora \(\overline{x}\) è \textbf{stabile}.

Se inoltre
\[
    \dot{V} < 0 \text{ in } U \sminus \{\overline{x}\}
\]
allora \(\overline{x}\) è \textbf{asintoticamente stabile}
\end{theorem}
\begin{example}[Punto mobile sotto l'azione di un campo
    conservativo]\label{ex:campo-conservativo}
    \[
      m\ddot{x} = -\nabla \varphi {(x)}
    \]
    dove \(\varphi \) è l'energia potenziale. Il sistema del primo ordine
    equivalente è
    \[
      \begin{cases}
          \overline{x} = v \\
          \dot{v} = -\frac{1}{m}\nabla \varphi {(x)}
      \end{cases}
    \]
    L'energia totale è \[V{(x, v)} = \frac{1}{2}m |v|^2 + \varphi {(x)}- \varphi {(\overline{x})}\] dove
    \(\overline{x}\) è punto di minimo stretto di \(\varphi \). Allora
    \({(\overline{x}, 0)}\) è punto di equilibrio. Abbiamo
    \[
      \dot{V}{(x, v)} = \begin{pmatrix}
           \nabla \varphi {(x)} \\
           mv
      \end{pmatrix} \cdot  \begin{pmatrix}
          v \\
          -\frac{1}{m}\nabla \varphi {(x)}
      \end{pmatrix} = 0
    \]
    Allora \({(\overline{x}, 0)}\) è stabile.
    \begin{remark}
        \(\dot{V}{(x,v)} = 0\) è la condizione di conservazione dell'energia
    \end{remark}
\end{example}

L'esempio~\ref{ex:campo-conservativo} rientra nella seguente tipologia:
\[
  {(p, q)} \in \mathbb{R}^{N} \times \mathbb{R}^{N} \quad H{(p, q)} \quad
  \begin{cases}
      \dot{p} = H_q{(p, q)}\\
      \dot{q} = -H_p{(p, q)}
  \end{cases}
\]
con \({(x,v)} = {(p, q)}\) e \(H{(p, q)} = \frac{1}{m}{(V{(x,v)})} =
\frac{1}{2}|v|^2 + \frac{1}{m}{(\varphi {(x)} - \varphi {(\overline{x})})}\).
Tali sistemi vengono chiamati \textbf{sistemi Hamiltoniani}.
\begin{remark}
    \[
      \frac{d}{dt} H{(p{(t)}, q{(t)})} = H_p \dot{p} + H_q \dot{q} = H_p H_q -
      H_q H_p = 0
    \]
    dunque \(H\) è costante lungo le soluzioni e le orbite soddisfano
    \(H{(p{(t)}, q{(t)})} = h\) costante.
\end{remark}
Nel caso del pendolo si può vedere come
\[
  \begin{cases}
      \dot{\theta} = v &= H_v \\
      \dot{v} = -\omega^2 \sin\theta &= -H_{\theta} 
  \end{cases}
\]
con \(H{(\theta, v)} = \frac{1}{2}v^2 + \omega^2{(1 - \cos \theta)}\) e inoltre
\({(0,0)}\) è punto di minimo stretto per \(H\) e quindi è stabile.

``Al contrario'', nei sistemi della forma
\[
  x' = -\nabla V{(x)}
\]
che sono detti \textbf{sistemi gradiente}, con \(V \in C^2\). Allora se
\(\overline{x}\) è punto di minimo stretto per \(V\) (sia \(V{(\overline{x})} =
0\)) si ha che 
\[
  \dot{V}{(x)} = \nabla V{(x)} \cdot {(-\nabla V{(x)})} = - \left| \nabla V{(x)}
  \right| ^2 \le 0
\]
se \(\overline{x}\) è isolato come punto critico allora \(\dot{V}{(x)} < 0\) in
un intorno di \(\overline{x}\) e dunque \(\overline{x}\) è asintoticamente
stabile.
\end{document}
